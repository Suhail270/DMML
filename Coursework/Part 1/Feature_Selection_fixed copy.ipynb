{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix,multilabel_confusion_matrix,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "# from sklearn.metrics._classification import _nanaverage\n",
    "\n",
    "def naive_bayes_search(df1, df2,seed_value=22):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(df1, df2, test_size=0.3,random_state=seed_value)\n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, Y_train)\n",
    "    \n",
    "    predicted = gnb.predict(X_test)\n",
    "    predicted_probs = gnb.predict_proba(X_test)\n",
    "    \n",
    "    # cross_val_scores = cross_val_score(gnb, X_train, Y_train, cv=5)  \n",
    "    # print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "    # print(\"Mean CV Score:\", cross_val_scores.mean())\n",
    "\n",
    "\n",
    "    # train_sizes, train_scores, test_scores = learning_curve(gnb, X_train, Y_train, cv=5)\n",
    "    # train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    # test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.title(\"Learning Curves\")\n",
    "    # plt.xlabel(\"Training examples\")\n",
    "    # plt.ylabel(\"Score\")\n",
    "    # plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    # plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    # plt.legend(loc=\"best\")\n",
    "    # plt.show()\n",
    "\n",
    "    accuracy = accuracy_score(Y_test,predicted )\n",
    "    f1 = f1_score(predicted, Y_test, average=\"weighted\")\n",
    "    conf_matrix = confusion_matrix(predicted, Y_test)\n",
    "    precision = precision_score(Y_test, predicted, average=\"weighted\",zero_division=1)\n",
    "    recall = recall_score(Y_test, predicted, average=\"weighted\")\n",
    "    # roc = roc_auc_score(Y_test, predicted_probs, multi_class=\"ovr\", average=\"weighted\")\n",
    "    conf_matrices = multilabel_confusion_matrix(Y_test, predicted)\n",
    "    tp = conf_matrices[:,1,1]\n",
    "    fp = conf_matrices[:,0,1]\n",
    "    tn = conf_matrices[:,0,0]\n",
    "    fn = conf_matrices[:,1,0]\n",
    "    # fpr = _nanaverage(fp/(tn + fp), tp + fn)\n",
    "    # tnr = _nanaverage(tn/(tn + fp), tp + fn)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall/Sensitivity/True Positive Rate:\", recall)\n",
    "    # print(\"Specificity:\", tnr)\n",
    "    # print(\"False Positive Rate:\", fpr)\n",
    "    # print(\"Area under ROC curve:\", roc)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "    return predicted\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "merged_data = pd.read_csv('processed_df_new.csv')\n",
    "# merged_data=pd.read_csv('Dataset/x_train_all.csv')\n",
    "ytrainall = pd.read_csv('Dataset/y_train_all.csv')\n",
    "merged_data = pd.concat([merged_data,ytrainall],axis = 1)\n",
    "merged_data=merged_data.rename(columns={merged_data.columns[-1]:'label'})\n",
    "# merged_data=merged_data.rename(columns={merged_data.columns[0]:'labels'})\n",
    "# merged_data=merged_data.drop(columns =['labels'])\n",
    "merged_data.columns.values[0] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2295</th>\n",
       "      <th>2296</th>\n",
       "      <th>2297</th>\n",
       "      <th>2298</th>\n",
       "      <th>2299</th>\n",
       "      <th>2300</th>\n",
       "      <th>2301</th>\n",
       "      <th>2302</th>\n",
       "      <th>2303</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113</td>\n",
       "      <td>99</td>\n",
       "      <td>92</td>\n",
       "      <td>106</td>\n",
       "      <td>114</td>\n",
       "      <td>123</td>\n",
       "      <td>148</td>\n",
       "      <td>182</td>\n",
       "      <td>190</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>177</td>\n",
       "      <td>106</td>\n",
       "      <td>71</td>\n",
       "      <td>68</td>\n",
       "      <td>120</td>\n",
       "      <td>197</td>\n",
       "      <td>234</td>\n",
       "      <td>220</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>113</td>\n",
       "      <td>120</td>\n",
       "      <td>110</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>120</td>\n",
       "      <td>141</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>135</td>\n",
       "      <td>105</td>\n",
       "      <td>144</td>\n",
       "      <td>159</td>\n",
       "      <td>151</td>\n",
       "      <td>171</td>\n",
       "      <td>205</td>\n",
       "      <td>170</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>92</td>\n",
       "      <td>128</td>\n",
       "      <td>142</td>\n",
       "      <td>166</td>\n",
       "      <td>189</td>\n",
       "      <td>166</td>\n",
       "      <td>141</td>\n",
       "      <td>131</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>135</td>\n",
       "      <td>121</td>\n",
       "      <td>144</td>\n",
       "      <td>128</td>\n",
       "      <td>85</td>\n",
       "      <td>71</td>\n",
       "      <td>85</td>\n",
       "      <td>142</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>78</td>\n",
       "      <td>106</td>\n",
       "      <td>128</td>\n",
       "      <td>165</td>\n",
       "      <td>138</td>\n",
       "      <td>76</td>\n",
       "      <td>69</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>67</td>\n",
       "      <td>97</td>\n",
       "      <td>138</td>\n",
       "      <td>160</td>\n",
       "      <td>147</td>\n",
       "      <td>106</td>\n",
       "      <td>71</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>113</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>115</td>\n",
       "      <td>123</td>\n",
       "      <td>128</td>\n",
       "      <td>106</td>\n",
       "      <td>105</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>112</td>\n",
       "      <td>127</td>\n",
       "      <td>148</td>\n",
       "      <td>158</td>\n",
       "      <td>154</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  2295  2296  2297  \\\n",
       "0  113   99   92  106  114  123  148  182  190  170  ...   177   106    71   \n",
       "1  106  106  113  120  110  114  114  120  141  120  ...   135   105   144   \n",
       "2   85   92  128  142  166  189  166  141  131  135  ...   135   121   144   \n",
       "3   57   64   78  106  128  165  138   76   69  120  ...    99    67    97   \n",
       "4  120  113   92   92  115  123  128  106  105  128  ...    99   112   127   \n",
       "\n",
       "   2298  2299  2300  2301  2302  2303  label  \n",
       "0    68   120   197   234   220   191      0  \n",
       "1   159   151   171   205   170   135      0  \n",
       "2   128    85    71    85   142   170      0  \n",
       "3   138   160   147   106    71    64      0  \n",
       "4   148   158   154   128   128   128      0  \n",
       "\n",
       "[5 rows x 2305 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "x = merged_data.drop('label',axis=1)\n",
    "y = merged_data['label']\n",
    "\n",
    "svm = SVC(kernel='linear', decision_function_shape='ovr')\n",
    "\n",
    "svm.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_weights = svm.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([ 375, 2259,  260, 1259, 2234,  621, 1373,  519, 1867, 1865,   24,\n",
      "       1461, 1728, 1114,  282,  278, 2175,  247, 2026,  360], dtype=int64), 1: array([ 461,  924, 2129,  692, 1734, 1773, 1255, 1401,  573, 1229, 1661,\n",
      "        401,  437,  299,  450, 1771, 1204,  298,  606, 1417], dtype=int64), 2: array([ 600, 1642,  352,   37,  957, 2184,  677,  508, 1982, 1865,  287,\n",
      "        711, 1434,  823,  118, 2069,  271, 1326, 1778,  800], dtype=int64), 3: array([1060, 1488, 1014, 1077,  946, 1715,  604, 1684,  356,  186,  472,\n",
      "       1170,  589, 2020,  390,  539, 1853, 1062, 2255, 1151], dtype=int64), 4: array([1855, 1052,  474,    3, 1323, 2303, 2292,  724, 1866, 1430,  929,\n",
      "        190,  265,  708, 2254,  296,  680,  649, 1880, 2007], dtype=int64), 5: array([1097, 2015, 2296, 1144,   75,  367,  724,  109,  318, 2206,  291,\n",
      "       1818, 2127, 1898,  290,  354,  135,  194, 2012,  269], dtype=int64), 6: array([1526,  839, 2177,  659, 1905,  398, 1990, 1913, 1580,  491, 1733,\n",
      "       1590, 1060,  366, 2220, 1096, 1247, 1357, 1191, 1922], dtype=int64), 7: array([2054, 1097, 1044,  291,  213, 1098, 2178,  102, 2202,  872, 1827,\n",
      "       1790,  190,  460, 2195,  662,  847, 2104,  814,  348], dtype=int64), 8: array([1761, 1536,  382, 1449, 1942, 1854, 1780, 1204, 2166, 2060, 2103,\n",
      "       2177,  798, 1064, 1820, 2165, 1639,  878,  850, 2081], dtype=int64), 9: array([2105,  917,  685, 1099,  593, 1734,  677, 2240,  647, 1161,  498,\n",
      "        740, 1437, 1670, 1951, 1222, 1563,  846, 1900,  672], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "k = 20\n",
    "selected_features_per_class = {}\n",
    "for class_label in range(10): \n",
    "    feature_ranking = np.argsort(np.abs(feature_weights[class_label]))\n",
    "    selected_features = feature_ranking[:k]\n",
    "    selected_features_per_class[class_label] = selected_features\n",
    "\n",
    "print(selected_features_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = pd.read_csv('processed_df_new.csv')\n",
    "# xtrain = pd.read_csv('Dataset/x_train_all.csv')\n",
    "# xtrain = xtrain.rename(columns={xtrain.columns[0]:'labels'})\n",
    "# xtrain = xtrain.drop(columns=['labels'])\n",
    "ytrain0 = pd.read_csv('y_train_0.csv')\n",
    "ytrain3 = pd.read_csv('y_train_3.csv')\n",
    "ytrain1 = pd.read_csv('y_train_1.csv')\n",
    "ytrain2 = pd.read_csv('y_train_2.csv')\n",
    "ytrain4 = pd.read_csv('y_train_4.csv')\n",
    "ytrain5 = pd.read_csv('y_train_5.csv')\n",
    "ytrain6 = pd.read_csv('y_train_6.csv')\n",
    "ytrain7 = pd.read_csv('y_train_7.csv')\n",
    "ytrain8 = pd.read_csv('y_train_8.csv')\n",
    "ytrain9 = pd.read_csv('y_train_9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2294</th>\n",
       "      <th>2295</th>\n",
       "      <th>2296</th>\n",
       "      <th>2297</th>\n",
       "      <th>2298</th>\n",
       "      <th>2299</th>\n",
       "      <th>2300</th>\n",
       "      <th>2301</th>\n",
       "      <th>2302</th>\n",
       "      <th>2303</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>113</td>\n",
       "      <td>99</td>\n",
       "      <td>92</td>\n",
       "      <td>106</td>\n",
       "      <td>114</td>\n",
       "      <td>123</td>\n",
       "      <td>148</td>\n",
       "      <td>182</td>\n",
       "      <td>190</td>\n",
       "      <td>170</td>\n",
       "      <td>...</td>\n",
       "      <td>182</td>\n",
       "      <td>177</td>\n",
       "      <td>106</td>\n",
       "      <td>71</td>\n",
       "      <td>68</td>\n",
       "      <td>120</td>\n",
       "      <td>197</td>\n",
       "      <td>234</td>\n",
       "      <td>220</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>113</td>\n",
       "      <td>120</td>\n",
       "      <td>110</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>120</td>\n",
       "      <td>141</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>142</td>\n",
       "      <td>135</td>\n",
       "      <td>105</td>\n",
       "      <td>144</td>\n",
       "      <td>159</td>\n",
       "      <td>151</td>\n",
       "      <td>171</td>\n",
       "      <td>205</td>\n",
       "      <td>170</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>92</td>\n",
       "      <td>128</td>\n",
       "      <td>142</td>\n",
       "      <td>166</td>\n",
       "      <td>189</td>\n",
       "      <td>166</td>\n",
       "      <td>141</td>\n",
       "      <td>131</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>171</td>\n",
       "      <td>135</td>\n",
       "      <td>121</td>\n",
       "      <td>144</td>\n",
       "      <td>128</td>\n",
       "      <td>85</td>\n",
       "      <td>71</td>\n",
       "      <td>85</td>\n",
       "      <td>142</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>78</td>\n",
       "      <td>106</td>\n",
       "      <td>128</td>\n",
       "      <td>165</td>\n",
       "      <td>138</td>\n",
       "      <td>76</td>\n",
       "      <td>69</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>176</td>\n",
       "      <td>99</td>\n",
       "      <td>67</td>\n",
       "      <td>97</td>\n",
       "      <td>138</td>\n",
       "      <td>160</td>\n",
       "      <td>147</td>\n",
       "      <td>106</td>\n",
       "      <td>71</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>113</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>115</td>\n",
       "      <td>123</td>\n",
       "      <td>128</td>\n",
       "      <td>106</td>\n",
       "      <td>105</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>99</td>\n",
       "      <td>112</td>\n",
       "      <td>127</td>\n",
       "      <td>148</td>\n",
       "      <td>158</td>\n",
       "      <td>154</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9685</th>\n",
       "      <td>227</td>\n",
       "      <td>220</td>\n",
       "      <td>198</td>\n",
       "      <td>191</td>\n",
       "      <td>211</td>\n",
       "      <td>232</td>\n",
       "      <td>224</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>198</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>50</td>\n",
       "      <td>42</td>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9686</th>\n",
       "      <td>92</td>\n",
       "      <td>120</td>\n",
       "      <td>170</td>\n",
       "      <td>198</td>\n",
       "      <td>164</td>\n",
       "      <td>120</td>\n",
       "      <td>110</td>\n",
       "      <td>116</td>\n",
       "      <td>138</td>\n",
       "      <td>156</td>\n",
       "      <td>...</td>\n",
       "      <td>147</td>\n",
       "      <td>120</td>\n",
       "      <td>98</td>\n",
       "      <td>66</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>86</td>\n",
       "      <td>135</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9687</th>\n",
       "      <td>255</td>\n",
       "      <td>248</td>\n",
       "      <td>227</td>\n",
       "      <td>198</td>\n",
       "      <td>194</td>\n",
       "      <td>205</td>\n",
       "      <td>202</td>\n",
       "      <td>205</td>\n",
       "      <td>222</td>\n",
       "      <td>234</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>71</td>\n",
       "      <td>81</td>\n",
       "      <td>90</td>\n",
       "      <td>106</td>\n",
       "      <td>139</td>\n",
       "      <td>166</td>\n",
       "      <td>184</td>\n",
       "      <td>177</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9688</th>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>243</td>\n",
       "      <td>250</td>\n",
       "      <td>238</td>\n",
       "      <td>215</td>\n",
       "      <td>214</td>\n",
       "      <td>227</td>\n",
       "      <td>...</td>\n",
       "      <td>87</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "      <td>81</td>\n",
       "      <td>124</td>\n",
       "      <td>132</td>\n",
       "      <td>108</td>\n",
       "      <td>57</td>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9689</th>\n",
       "      <td>255</td>\n",
       "      <td>248</td>\n",
       "      <td>241</td>\n",
       "      <td>248</td>\n",
       "      <td>242</td>\n",
       "      <td>212</td>\n",
       "      <td>170</td>\n",
       "      <td>125</td>\n",
       "      <td>76</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>79</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>69</td>\n",
       "      <td>114</td>\n",
       "      <td>154</td>\n",
       "      <td>143</td>\n",
       "      <td>92</td>\n",
       "      <td>57</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9690 rows × 2304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...  2294  2295  2296  \\\n",
       "0     113   99   92  106  114  123  148  182  190  170  ...   182   177   106   \n",
       "1     106  106  113  120  110  114  114  120  141  120  ...   142   135   105   \n",
       "2      85   92  128  142  166  189  166  141  131  135  ...   171   135   121   \n",
       "3      57   64   78  106  128  165  138   76   69  120  ...   176    99    67   \n",
       "4     120  113   92   92  115  123  128  106  105  128  ...   101    99   112   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   \n",
       "9685  227  220  198  191  211  232  224  207  206  198  ...   110    50    42   \n",
       "9686   92  120  170  198  164  120  110  116  138  156  ...   147   120    98   \n",
       "9687  255  248  227  198  194  205  202  205  222  234  ...    84    71    81   \n",
       "9688  212  212  227  227  243  250  238  215  214  227  ...    87    50    46   \n",
       "9689  255  248  241  248  242  212  170  125   76   35  ...    79    28    36   \n",
       "\n",
       "      2297  2298  2299  2300  2301  2302  2303  \n",
       "0       71    68   120   197   234   220   191  \n",
       "1      144   159   151   171   205   170   135  \n",
       "2      144   128    85    71    85   142   170  \n",
       "3       97   138   160   147   106    71    64  \n",
       "4      127   148   158   154   128   128   128  \n",
       "...    ...   ...   ...   ...   ...   ...   ...  \n",
       "9685    49    36    30    39    78    78    71  \n",
       "9686    66    50    59    86   135   156   156  \n",
       "9687    90   106   139   166   184   177   177  \n",
       "9688    81   124   132   108    57    42    50  \n",
       "9689    69   114   154   143    92    57    50  \n",
       "\n",
       "[9690 rows x 2304 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      375  2259  260  1259  2234  621  1373  519  1867  1865  ...  1461  1728  \\\n",
      "0      80    64  190    63   147   64   152  148   132   135  ...    85   124   \n",
      "1      66    92  193   153   221  124   118  213   189   180  ...    88   134   \n",
      "2     182    71  129   107   241   92   151  128   151   124  ...   124   145   \n",
      "3      94    50  116    66   191  128   160  107    96    72  ...   216   163   \n",
      "4      87    85  194    92   227   92   201  199   106    93  ...    71   248   \n",
      "...   ...   ...  ...   ...   ...  ...   ...  ...   ...   ...  ...   ...   ...   \n",
      "9685  163    28  230   140   189   82   236   87   195   165  ...    96   174   \n",
      "9686  106   142  160   107   191   88   210  148   146   143  ...   106   124   \n",
      "9687  196    78  180    99   197   46   216   69   175   134  ...    64   166   \n",
      "9688  116    99  181   159   208  212   187   96   166   121  ...    78   102   \n",
      "9689  167    50  147   128   207  106   177   31   177   137  ...    74   198   \n",
      "\n",
      "      1114  282  278  2175  247  2026  360  label  \n",
      "0      153  162  105    85  149   225  150      0  \n",
      "1      216  171  104   149  171   230  105      0  \n",
      "2      122  118   67   120   76   204   84      0  \n",
      "3      177  145   79   135   72   225   91      0  \n",
      "4      134  104  137   184  116   150  143      0  \n",
      "...    ...  ...  ...   ...  ...   ...  ...    ...  \n",
      "9685   230  236  196   170  228    83   92      1  \n",
      "9686   122   60   56   163  245    92   88      1  \n",
      "9687   104  124  130   170  194   110   80      1  \n",
      "9688   221   91  128   170  222    79   80      1  \n",
      "9689   222  209  194   177  232   124  105      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "      461  924  2129  692  1734  1773  1255  1401  573  1229  ...  401  437  \\\n",
      "0      71  100   132   42   161    88   190   175   71   194  ...  134  140   \n",
      "1      99  126   191   49    92   110   144   170   90   235  ...  101  184   \n",
      "2     189   79   130  115   124   128   147   199   92   239  ...   53  128   \n",
      "3     217   93   161  141    85   120   139   177  114   242  ...  124  156   \n",
      "4      83   98   147   71   246    78    71   180   99   200  ...  124   61   \n",
      "...   ...  ...   ...  ...   ...   ...   ...   ...  ...   ...  ...  ...  ...   \n",
      "9685  163  223   150   68   117   100   183   125   78   155  ...  170  193   \n",
      "9686  246  162   163   64   156   106   148   104  104   158  ...  243  255   \n",
      "9687  168  183   145   43   140   120   158   111   33   183  ...  105  132   \n",
      "9688  179  231   138   42   140    64   204   173  222   187  ...  255  210   \n",
      "9689  182  136   108   64   161    74   247   165   99   198  ...  184  215   \n",
      "\n",
      "      299  450  1771  1204  298  606  1417  label  \n",
      "0     233   74    97    98  219  150   167      1  \n",
      "1     207   99   156   133  178  158   133      1  \n",
      "2     205  110   146   126  207  159   139      1  \n",
      "3     160  160   149    93  152   55   175      1  \n",
      "4     233   46    67   155  233  156   200      1  \n",
      "...   ...  ...   ...   ...  ...  ...   ...    ...  \n",
      "9685  213  162   130   195  220  124   100      1  \n",
      "9686  211  202   104   200  233  223   112      1  \n",
      "9687  148  162   185   207  155  241   120      1  \n",
      "9688  232  192    72   205  226  161   161      1  \n",
      "9689  171  177   143   215  195  158   116      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "      600  1642  352   37  957  2184  677  508  1982  1865  ...  711  1434  \\\n",
      "0     108    87  177  120   95   238  182  163   180   135  ...   77   168   \n",
      "1     115   148  150   75   76   145  229  150   188   180  ...   76   152   \n",
      "2      53   142   74  125  151   202  240  168   184   124  ...  105   162   \n",
      "3     122   166   89  170  120   227  213  168   147    72  ...  200   104   \n",
      "4     160   189  160  109  113   209  185  141    84    93  ...   94   146   \n",
      "...   ...   ...  ...  ...  ...   ...  ...  ...   ...   ...  ...  ...   ...   \n",
      "9685   19    58  176   33  168   149  236  162    32   165  ...   79   165   \n",
      "9686   69    35  247  255  158   163  205  202    27   143  ...  106   118   \n",
      "9687   64    41  106  170  123   188  197  238    36   134  ...  128   100   \n",
      "9688   90    44  236  227  151   120   82  156    31   121  ...  127   117   \n",
      "9689   67    45  128   94   40   152  208  166    54   137  ...  188    83   \n",
      "\n",
      "      823  118  2069  271  1326  1778  800  label  \n",
      "0     138  101   165  230   146   132  130      1  \n",
      "1     157  143   203  194   230   137  123      1  \n",
      "2     190  233   154  115   174   149   99      1  \n",
      "3     159  241   152   67   156   139  148      1  \n",
      "4     227  154    85  201   248   215   86      1  \n",
      "...   ...  ...   ...  ...   ...   ...  ...    ...  \n",
      "9685  230  118   194  209   184   151   86      1  \n",
      "9686  133  136   184  118   206   153  118      1  \n",
      "9687  233  226   168  166   195   123  131      1  \n",
      "9688  195  192   174  235   226   111  121      1  \n",
      "9689  154   48   164  236   184   174   90      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "      1060  1488  1014  1077  946  1715  604  1684  356  186  ...  1170  589  \\\n",
      "0       97   241   188    96  101    90  189   124  155  145  ...   234  100   \n",
      "1      130   191    60   154  103   131  145   151  117  174  ...   255  181   \n",
      "2       90   215    74   152  104   130  133   167   82  170  ...   248  211   \n",
      "3      150   189    64   138  138   136   78   110   85  212  ...   246  215   \n",
      "4      111    57   117   112  137    93  168   232  159  142  ...   196  144   \n",
      "...    ...   ...   ...   ...  ...   ...  ...   ...  ...  ...  ...   ...  ...   \n",
      "9685   208   220   212   241  106   156  152    75  173  188  ...   136  243   \n",
      "9686   174   160   212   241  146   186  173   125  172  142  ...   149  220   \n",
      "9687   216   180   174   225  131   181  233    94  144  174  ...   181  221   \n",
      "9688   211   153   216   242  155   176  161   100  154  113  ...   150  129   \n",
      "9689   128   248    54   216   97   188  161   185  154  184  ...   184  235   \n",
      "\n",
      "      2020  390  539  1853  1062  2255  1151  label  \n",
      "0      126   83   85   183   204   163   210      1  \n",
      "1      181  171  178    98    63   142   213      1  \n",
      "2      167   77  157   146    66   177   179      1  \n",
      "3      139   87  193   155    65    78   200      1  \n",
      "4       98   90   57   164    71   106   144      1  \n",
      "...    ...  ...  ...   ...   ...   ...   ...    ...  \n",
      "9685   192  210  243   122   199    71    92      1  \n",
      "9686   189  252  220   124   214   149   106      1  \n",
      "9687   181   80  217   143   176   142    45      1  \n",
      "9688   161  208  200   156   209    64   201      1  \n",
      "9689   139  255  214   127   140    71   215      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "      1855  1052  474    3  1323  2303  2292  724  1866  1430  ...  190  265  \\\n",
      "0      177    96  170  106   184   191   152  147   137   175  ...   92  189   \n",
      "1      130   157  202  120   135   135   148  195   203    87  ...  106  207   \n",
      "2      168   191   78  142   120   170   206  242   139   133  ...   99  132   \n",
      "3      161   147  110  106    78    64   227  218    83   154  ...   71   80   \n",
      "4      155   127  146   92    85   128   128  179    96    80  ...  113  236   \n",
      "...    ...   ...  ...  ...   ...   ...   ...  ...   ...   ...  ...  ...  ...   \n",
      "9685   130   119  131  191    92    71   181  224   211   148  ...   57  222   \n",
      "9686   136    87  177  198    78   156   195  238   176   156  ...  234  101   \n",
      "9687   153    92  113  198    85   177   181  206   182   158  ...  113  123   \n",
      "9688   146   151   60  227    42    50   181   55   168   174  ...   85  165   \n",
      "9689   122   124   85  248    50    50   198  203   178   102  ...  128  205   \n",
      "\n",
      "      708  2254  296  680  649  1880  2007  label  \n",
      "0     154   205  142  146   65   198    78      1  \n",
      "1     173   177   99  211   57   114    90      1  \n",
      "2     169   156  104  165  106   116    97      1  \n",
      "3     160    85   72  197  148    65   170      1  \n",
      "4     171   106  178  150   54    96   123      1  \n",
      "...   ...   ...  ...  ...  ...   ...   ...    ...  \n",
      "9685  123    71  247  244   38    65    82      1  \n",
      "9686  190   142  248  194   65    28    50      1  \n",
      "9687  178   156  159  230   50    65    92      1  \n",
      "9688  105    50  230   93   72    65   104      1  \n",
      "9689   86    78  231  174   60    26   113      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "      1097  2015  2296  1144   75  367  724  109  318  2206  ...  1818  2127  \\\n",
      "0      126   167   106   129  227  154  147  194  176   170  ...   122   144   \n",
      "1      181    62   105   151  135  121  195  177  147   198  ...   200   219   \n",
      "2      182    97   121   174  198   69  242  232   66   170  ...   155   180   \n",
      "3       99   198    67   185  177   94  218  250   44   142  ...   118   158   \n",
      "4      188   135   112   153  149  135  179  250  166    78  ...    86   154   \n",
      "...    ...   ...   ...   ...  ...  ...  ...  ...  ...   ...  ...   ...   ...   \n",
      "9685   138    47    42   129   92  151  224  222  166    64  ...   200   144   \n",
      "9686   140    80    98   116  205  208  238  101  175   106  ...   149   115   \n",
      "9687   134   118    81   112  241  139  206  203  161    92  ...   202   119   \n",
      "9688   208    90    46   224   92  239   55  163  230    71  ...   145   124   \n",
      "9689   239    66    36   248   57  244  203  177  252   106  ...   188   132   \n",
      "\n",
      "      1898  290  354  135  194  2012  269  label  \n",
      "0      151  128  145  149  112   112  225      1  \n",
      "1      170   60  124   78   80    78  149      1  \n",
      "2      132  103   98  106   99   114  123      1  \n",
      "3      160  142   96   64  131    91   83      1  \n",
      "4       71  138  137  106  108   114  194      1  \n",
      "...    ...  ...  ...  ...  ...   ...  ...    ...  \n",
      "9685   104  238  217  113  224   166  207      1  \n",
      "9686   102  248  248  149  224   156  140      1  \n",
      "9687   101  146  143  241  213   166  191      1  \n",
      "9688    77  216  248  120  190   152  232      1  \n",
      "9689   100  248  201   50  138   138  241      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "      1526  839  2177  659  1905  398  1990  1913  1580  491  ...  1590  1060  \\\n",
      "0      152  241   125   85   149  163   162   137   139   85  ...   202    97   \n",
      "1      126  246   151  162   149   90   176   158   122  132  ...   220   130   \n",
      "2      147  250   101  165   205   68   197    99   138  141  ...   198    90   \n",
      "3      101  238   116  141   184   73   200    80   110  204  ...   184   150   \n",
      "4      120  227   168  175   120  159   194   104   126   68  ...   166   111   \n",
      "...    ...  ...   ...  ...   ...  ...   ...   ...   ...  ...  ...   ...   ...   \n",
      "9685   160  243   175  157   113  223    43   137   147  254  ...    74   208   \n",
      "9686   103  220   184  211    92  241    36   128   175  234  ...   188   174   \n",
      "9687   159  206   182  213   120   44    26   111   100  185  ...   114   216   \n",
      "9688   144  206   170  136    92  202    38    87    74  211  ...   160   211   \n",
      "9689   123  225   161   86   120  166    39    94   133  223  ...   216   128   \n",
      "\n",
      "      366  2220  1096  1247  1357  1191  1922  label  \n",
      "0     146   117   149   172    92   166   152      1  \n",
      "1     111    74   152   208   112   128   183      1  \n",
      "2      70    78   181   182    68   138   211      1  \n",
      "3     110   132   180   200    81   205   162      1  \n",
      "4     131   230   179   170    98   113   123      1  \n",
      "...   ...   ...   ...   ...   ...   ...   ...    ...  \n",
      "9685  154   188   155    76    35   103   138      1  \n",
      "9686  215   192   169    80    31    85    98      1  \n",
      "9687  134   202    88    83    39   152   117      1  \n",
      "9688  221   181   199   130    39   230    72      1  \n",
      "9689  240   181   224   241    21   238    83      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "      2054  1097  1044  291  213  1098  2178  102  2202  872  ...  1790  190  \\\n",
      "0       85   126   106  138  185   102   117  128   110  155  ...   142   92   \n",
      "1      135   181   110  103  171   195   160  142   124  144  ...   134  106   \n",
      "2      135   182   100  124  200   171    99  114   117  184  ...   102   99   \n",
      "3      164    99   100  134  133    96   114  156    88  161  ...    87   71   \n",
      "4      164   188    67  160  200   176   188  156   131  232  ...   164  113   \n",
      "...    ...   ...   ...  ...  ...   ...   ...  ...   ...  ...  ...   ...  ...   \n",
      "9685   124   138   188  255  241   129   184  230    92  249  ...   237   57   \n",
      "9686    74   140   160  241   97    79   177  152    71  134  ...   244  234   \n",
      "9687   150   134   163  132  167   169   180  230    70  186  ...   232  113   \n",
      "9688   159   208   145  216  161   195   170  223   128  211  ...   236   85   \n",
      "9689   147   239    78  244   79   230   166   56   149  127  ...   228  128   \n",
      "\n",
      "      460  2195  662  847  2104  814  348  label  \n",
      "0     109    95  120  119    76  157  214      1  \n",
      "1      83   219   99  166   102  118  200      1  \n",
      "2     144   198  124  160    80  166  146      1  \n",
      "3     229   172  200  190   143  155   85      1  \n",
      "4      73   186   91  158   150  120  208      1  \n",
      "...   ...   ...  ...  ...   ...  ...  ...    ...  \n",
      "9685  186   182   90  104   172  101  233      1  \n",
      "9686  238   168  132  115   161  180  211      1  \n",
      "9687  189   173  147  130   174   96   66      1  \n",
      "9688  169   168  133  127   132  165  247      1  \n",
      "9689  186   165   83  113   160   72  151      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "      1761  1536  382  1449  1942  1854  1780  1204  2166  2060  ...  2177  \\\n",
      "0      110   241  191   191   139   177    60    98    74   116  ...   125   \n",
      "1      177   224   73   198   171   115    95   133   120    70  ...   151   \n",
      "2      180   242  156   212   193   144   122   126   135    81  ...   101   \n",
      "3      192   218  130   192   188   161   131    93   114   112  ...   116   \n",
      "4       85    77  205   166   160   170   205   155   106    99  ...   168   \n",
      "...    ...   ...  ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "9685   241   252   85   142    66   119   128   195   114   155  ...   175   \n",
      "9686   241   130   30   110    59   129    86   200   124   156  ...   184   \n",
      "9687   248   194  158   106    19   141    68   207    92   108  ...   182   \n",
      "9688   216   133   36   159    49   157   111   205   156   123  ...   170   \n",
      "9689   238   220  151   142    21   122   166   215    99   138  ...   161   \n",
      "\n",
      "      798  1064  1820  2165  1639  878  850  2081  label  \n",
      "0     135   203   105   104   189  103  124   192      1  \n",
      "1     172   144   141   137   207  120   69   216      1  \n",
      "2     160   138   136   123   192   94   63   168      1  \n",
      "3     183   182   122   120   136  104   86   200      1  \n",
      "4     127   125    76   125   184   92   60   103      1  \n",
      "...   ...   ...   ...   ...   ...  ...  ...   ...    ...  \n",
      "9685  124   217   108    99   134  175  106   115      1  \n",
      "9686  118   229   105   147   186  202  130   105      1  \n",
      "9687  144   121   138    87   137  193  120   109      1  \n",
      "9688  150   254    67   170   154  212   31   101      1  \n",
      "9689  103   212   107    92   164  157  182    88      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "      2105  917  685  1099  593  1734  677  2240  647  1161  ...  740  1437  \\\n",
      "0      104  114   82    91  180   161  182   247   78   212  ...   77   158   \n",
      "1       92   76   87   181  194    92  229   137  122   227  ...   75   120   \n",
      "2       76   76  143   167  156   124  240   136   87   205  ...  158   118   \n",
      "3      126   82  130   143   97    85  213   105  157   234  ...  165    94   \n",
      "4      117  208  204   153  118   246  185   124  109   156  ...   43    92   \n",
      "...    ...  ...  ...   ...  ...   ...  ...   ...  ...   ...  ...  ...   ...   \n",
      "9685   171  231  236   118  177   117  236   222   65   202  ...   78    99   \n",
      "9686   172  212  188    66  156   156  205   184  137   156  ...   80    94   \n",
      "9687   165  191  232   165  208   140  197   220  140    96  ...   59   111   \n",
      "9688   161  212   37   178  172   140   82   216  153   238  ...   81    90   \n",
      "9689   174   74  247   200  182   161  208   233  140   216  ...   74   118   \n",
      "\n",
      "      1670  1951  1222  1563  846  1900  672  label  \n",
      "0      127   205   147   218  158   175  243      1  \n",
      "1      175   183   139   207  192    95  232      1  \n",
      "2      113   223   165   255  176   141  189      1  \n",
      "3      133   151   199   232  183   190  243      1  \n",
      "4      131   117   131   170  159    71  117      1  \n",
      "...    ...   ...   ...   ...  ...   ...  ...    ...  \n",
      "9685   102    39   225    96  107    97  240      0  \n",
      "9686    88    44   170    98   90    87  205      0  \n",
      "9687    74    43   164    63  109   129  221      0  \n",
      "9688    66    52   139    52  116   101   91      0  \n",
      "9689    84    18   152    86  100    92  249      0  \n",
      "\n",
      "[9690 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "xy0_20 = None\n",
    "for i in selected_features_per_class[0]:\n",
    "    xy0_20 = pd.concat([xy0_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy0_20 = pd.concat([xy0_20,ytrain0],axis=1)\n",
    "xy0_20 = xy0_20.rename(columns={xy0_20.columns[-1]:'label'})\n",
    "print(xy0_20)\n",
    "    \n",
    "xy1_20 = None\n",
    "for i in selected_features_per_class[1]:\n",
    "    xy1_20 = pd.concat([xy1_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy1_20 = pd.concat([xy1_20,ytrain1],axis=1)\n",
    "xy1_20 = xy1_20.rename(columns={xy1_20.columns[-1]:'label'})\n",
    "print(xy1_20)\n",
    "\n",
    "xy2_20 = None\n",
    "for i in selected_features_per_class[2]:\n",
    "    xy2_20 = pd.concat([xy2_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy2_20 = pd.concat([xy2_20,ytrain2],axis=1)\n",
    "xy2_20 = xy2_20.rename(columns={xy2_20.columns[-1]:'label'})\n",
    "print(xy2_20)\n",
    "\n",
    "xy3_20 = None\n",
    "for i in selected_features_per_class[3]:\n",
    "    xy3_20 = pd.concat([xy3_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy3_20 = pd.concat([xy3_20,ytrain3],axis=1)\n",
    "xy3_20 = xy3_20.rename(columns={xy3_20.columns[-1]:'label'})\n",
    "print(xy3_20)\n",
    "\n",
    "xy4_20 = None\n",
    "for i in selected_features_per_class[4]:\n",
    "    xy4_20 = pd.concat([xy4_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy4_20 = pd.concat([xy4_20,ytrain4],axis=1)\n",
    "xy4_20 = xy4_20.rename(columns={xy4_20.columns[-1]:'label'})\n",
    "print(xy4_20)\n",
    "\n",
    "xy5_20 = None\n",
    "for i in selected_features_per_class[5]:\n",
    "    xy5_20 = pd.concat([xy5_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy5_20 = pd.concat([xy5_20,ytrain5],axis=1)\n",
    "xy5_20 = xy5_20.rename(columns={xy5_20.columns[-1]:'label'})\n",
    "print(xy5_20)\n",
    "\n",
    "xy6_20 = None\n",
    "for i in selected_features_per_class[6]:\n",
    "    xy6_20 = pd.concat([xy6_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy6_20 = pd.concat([xy6_20,ytrain6],axis=1)\n",
    "xy6_20 = xy6_20.rename(columns={xy6_20.columns[-1]:'label'})\n",
    "print(xy6_20)\n",
    "\n",
    "xy7_20 = None\n",
    "for i in selected_features_per_class[7]:\n",
    "    xy7_20 = pd.concat([xy7_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy7_20 = pd.concat([xy7_20,ytrain7],axis=1)\n",
    "xy7_20 = xy7_20.rename(columns={xy7_20.columns[-1]:'label'})\n",
    "print(xy7_20)\n",
    "\n",
    "xy8_20 = None\n",
    "for i in selected_features_per_class[8]:\n",
    "    xy8_20 = pd.concat([xy8_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy8_20 = pd.concat([xy8_20,ytrain8],axis=1)\n",
    "xy8_20 = xy8_20.rename(columns={xy8_20.columns[-1]:'label'})\n",
    "print(xy8_20)\n",
    "\n",
    "xy9_20 = None\n",
    "for i in selected_features_per_class[9]:\n",
    "    xy9_20 = pd.concat([xy9_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy9_20 = pd.concat([xy9_20,ytrain9],axis=1)\n",
    "xy9_20 = xy9_20.rename(columns={xy9_20.columns[-1]:'label'})\n",
    "print(xy9_20)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      375  2259  260  1259  2234  621  1373  519  1867  1865  label\n",
      "0      80    64  190    63   147   64   152  148   132   135      0\n",
      "1      66    92  193   153   221  124   118  213   189   180      0\n",
      "2     182    71  129   107   241   92   151  128   151   124      0\n",
      "3      94    50  116    66   191  128   160  107    96    72      0\n",
      "4      87    85  194    92   227   92   201  199   106    93      0\n",
      "...   ...   ...  ...   ...   ...  ...   ...  ...   ...   ...    ...\n",
      "9685  163    28  230   140   189   82   236   87   195   165      1\n",
      "9686  106   142  160   107   191   88   210  148   146   143      1\n",
      "9687  196    78  180    99   197   46   216   69   175   134      1\n",
      "9688  116    99  181   159   208  212   187   96   166   121      1\n",
      "9689  167    50  147   128   207  106   177   31   177   137      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "      461  924  2129  692  1734  1773  1255  1401  573  1229  label\n",
      "0      71  100   132   42   161    88   190   175   71   194      1\n",
      "1      99  126   191   49    92   110   144   170   90   235      1\n",
      "2     189   79   130  115   124   128   147   199   92   239      1\n",
      "3     217   93   161  141    85   120   139   177  114   242      1\n",
      "4      83   98   147   71   246    78    71   180   99   200      1\n",
      "...   ...  ...   ...  ...   ...   ...   ...   ...  ...   ...    ...\n",
      "9685  163  223   150   68   117   100   183   125   78   155      1\n",
      "9686  246  162   163   64   156   106   148   104  104   158      1\n",
      "9687  168  183   145   43   140   120   158   111   33   183      1\n",
      "9688  179  231   138   42   140    64   204   173  222   187      1\n",
      "9689  182  136   108   64   161    74   247   165   99   198      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "      600  1642  352   37  957  2184  677  508  1982  1865  label\n",
      "0     108    87  177  120   95   238  182  163   180   135      1\n",
      "1     115   148  150   75   76   145  229  150   188   180      1\n",
      "2      53   142   74  125  151   202  240  168   184   124      1\n",
      "3     122   166   89  170  120   227  213  168   147    72      1\n",
      "4     160   189  160  109  113   209  185  141    84    93      1\n",
      "...   ...   ...  ...  ...  ...   ...  ...  ...   ...   ...    ...\n",
      "9685   19    58  176   33  168   149  236  162    32   165      1\n",
      "9686   69    35  247  255  158   163  205  202    27   143      1\n",
      "9687   64    41  106  170  123   188  197  238    36   134      1\n",
      "9688   90    44  236  227  151   120   82  156    31   121      1\n",
      "9689   67    45  128   94   40   152  208  166    54   137      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "      1060  1488  1014  1077  946  1715  604  1684  356  186  label\n",
      "0       97   241   188    96  101    90  189   124  155  145      1\n",
      "1      130   191    60   154  103   131  145   151  117  174      1\n",
      "2       90   215    74   152  104   130  133   167   82  170      1\n",
      "3      150   189    64   138  138   136   78   110   85  212      1\n",
      "4      111    57   117   112  137    93  168   232  159  142      1\n",
      "...    ...   ...   ...   ...  ...   ...  ...   ...  ...  ...    ...\n",
      "9685   208   220   212   241  106   156  152    75  173  188      1\n",
      "9686   174   160   212   241  146   186  173   125  172  142      1\n",
      "9687   216   180   174   225  131   181  233    94  144  174      1\n",
      "9688   211   153   216   242  155   176  161   100  154  113      1\n",
      "9689   128   248    54   216   97   188  161   185  154  184      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "      1855  1052  474    3  1323  2303  2292  724  1866  1430  label\n",
      "0      177    96  170  106   184   191   152  147   137   175      1\n",
      "1      130   157  202  120   135   135   148  195   203    87      1\n",
      "2      168   191   78  142   120   170   206  242   139   133      1\n",
      "3      161   147  110  106    78    64   227  218    83   154      1\n",
      "4      155   127  146   92    85   128   128  179    96    80      1\n",
      "...    ...   ...  ...  ...   ...   ...   ...  ...   ...   ...    ...\n",
      "9685   130   119  131  191    92    71   181  224   211   148      1\n",
      "9686   136    87  177  198    78   156   195  238   176   156      1\n",
      "9687   153    92  113  198    85   177   181  206   182   158      1\n",
      "9688   146   151   60  227    42    50   181   55   168   174      1\n",
      "9689   122   124   85  248    50    50   198  203   178   102      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "      1097  2015  2296  1144   75  367  724  109  318  2206  label\n",
      "0      126   167   106   129  227  154  147  194  176   170      1\n",
      "1      181    62   105   151  135  121  195  177  147   198      1\n",
      "2      182    97   121   174  198   69  242  232   66   170      1\n",
      "3       99   198    67   185  177   94  218  250   44   142      1\n",
      "4      188   135   112   153  149  135  179  250  166    78      1\n",
      "...    ...   ...   ...   ...  ...  ...  ...  ...  ...   ...    ...\n",
      "9685   138    47    42   129   92  151  224  222  166    64      1\n",
      "9686   140    80    98   116  205  208  238  101  175   106      1\n",
      "9687   134   118    81   112  241  139  206  203  161    92      1\n",
      "9688   208    90    46   224   92  239   55  163  230    71      1\n",
      "9689   239    66    36   248   57  244  203  177  252   106      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "      1526  839  2177  659  1905  398  1990  1913  1580  491  label\n",
      "0      152  241   125   85   149  163   162   137   139   85      1\n",
      "1      126  246   151  162   149   90   176   158   122  132      1\n",
      "2      147  250   101  165   205   68   197    99   138  141      1\n",
      "3      101  238   116  141   184   73   200    80   110  204      1\n",
      "4      120  227   168  175   120  159   194   104   126   68      1\n",
      "...    ...  ...   ...  ...   ...  ...   ...   ...   ...  ...    ...\n",
      "9685   160  243   175  157   113  223    43   137   147  254      1\n",
      "9686   103  220   184  211    92  241    36   128   175  234      1\n",
      "9687   159  206   182  213   120   44    26   111   100  185      1\n",
      "9688   144  206   170  136    92  202    38    87    74  211      1\n",
      "9689   123  225   161   86   120  166    39    94   133  223      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "      2054  1097  1044  291  213  1098  2178  102  2202  872  label\n",
      "0       85   126   106  138  185   102   117  128   110  155      1\n",
      "1      135   181   110  103  171   195   160  142   124  144      1\n",
      "2      135   182   100  124  200   171    99  114   117  184      1\n",
      "3      164    99   100  134  133    96   114  156    88  161      1\n",
      "4      164   188    67  160  200   176   188  156   131  232      1\n",
      "...    ...   ...   ...  ...  ...   ...   ...  ...   ...  ...    ...\n",
      "9685   124   138   188  255  241   129   184  230    92  249      1\n",
      "9686    74   140   160  241   97    79   177  152    71  134      1\n",
      "9687   150   134   163  132  167   169   180  230    70  186      1\n",
      "9688   159   208   145  216  161   195   170  223   128  211      1\n",
      "9689   147   239    78  244   79   230   166   56   149  127      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "      1761  1536  382  1449  1942  1854  1780  1204  2166  2060  label\n",
      "0      110   241  191   191   139   177    60    98    74   116      1\n",
      "1      177   224   73   198   171   115    95   133   120    70      1\n",
      "2      180   242  156   212   193   144   122   126   135    81      1\n",
      "3      192   218  130   192   188   161   131    93   114   112      1\n",
      "4       85    77  205   166   160   170   205   155   106    99      1\n",
      "...    ...   ...  ...   ...   ...   ...   ...   ...   ...   ...    ...\n",
      "9685   241   252   85   142    66   119   128   195   114   155      1\n",
      "9686   241   130   30   110    59   129    86   200   124   156      1\n",
      "9687   248   194  158   106    19   141    68   207    92   108      1\n",
      "9688   216   133   36   159    49   157   111   205   156   123      1\n",
      "9689   238   220  151   142    21   122   166   215    99   138      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "      2105  917  685  1099  593  1734  677  2240  647  1161  label\n",
      "0      104  114   82    91  180   161  182   247   78   212      1\n",
      "1       92   76   87   181  194    92  229   137  122   227      1\n",
      "2       76   76  143   167  156   124  240   136   87   205      1\n",
      "3      126   82  130   143   97    85  213   105  157   234      1\n",
      "4      117  208  204   153  118   246  185   124  109   156      1\n",
      "...    ...  ...  ...   ...  ...   ...  ...   ...  ...   ...    ...\n",
      "9685   171  231  236   118  177   117  236   222   65   202      0\n",
      "9686   172  212  188    66  156   156  205   184  137   156      0\n",
      "9687   165  191  232   165  208   140  197   220  140    96      0\n",
      "9688   161  212   37   178  172   140   82   216  153   238      0\n",
      "9689   174   74  247   200  182   161  208   233  140   216      0\n",
      "\n",
      "[9690 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "xy0_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[0]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy0_10 = pd.concat([xy0_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy0_10 = pd.concat([xy0_10,ytrain0],axis=1)\n",
    "xy0_10 = xy0_10.rename(columns={xy0_10.columns[-1]:'label'})\n",
    "print(xy0_10)\n",
    "    \n",
    "xy1_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[1]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy1_10 = pd.concat([xy1_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy1_10 = pd.concat([xy1_10,ytrain1],axis=1)\n",
    "xy1_10 = xy1_10.rename(columns={xy1_10.columns[-1]:'label'})\n",
    "print(xy1_10)\n",
    "\n",
    "xy2_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[2]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy2_10 = pd.concat([xy2_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy2_10 = pd.concat([xy2_10,ytrain2],axis=1)\n",
    "xy2_10 = xy2_10.rename(columns={xy2_10.columns[-1]:'label'})\n",
    "print(xy2_10)\n",
    "\n",
    "xy3_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[3]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy3_10 = pd.concat([xy3_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy3_10 = pd.concat([xy3_10,ytrain3],axis=1)\n",
    "xy3_10 = xy3_10.rename(columns={xy3_10.columns[-1]:'label'})\n",
    "print(xy3_10)\n",
    "\n",
    "xy4_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[4]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy4_10 = pd.concat([xy4_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy4_10 = pd.concat([xy4_10,ytrain4],axis=1)\n",
    "xy4_10 = xy4_10.rename(columns={xy4_10.columns[-1]:'label'})\n",
    "print(xy4_10)\n",
    "\n",
    "xy5_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[5]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy5_10 = pd.concat([xy5_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy5_10 = pd.concat([xy5_10,ytrain5],axis=1)\n",
    "xy5_10 = xy5_10.rename(columns={xy5_10.columns[-1]:'label'})\n",
    "print(xy5_10)\n",
    "\n",
    "xy6_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[6]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy6_10 = pd.concat([xy6_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy6_10 = pd.concat([xy6_10,ytrain6],axis=1)\n",
    "xy6_10 = xy6_10.rename(columns={xy6_10.columns[-1]:'label'})\n",
    "print(xy6_10)\n",
    "\n",
    "xy7_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[7]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy7_10 = pd.concat([xy7_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy7_10 = pd.concat([xy7_10,ytrain7],axis=1)\n",
    "xy7_10 = xy7_10.rename(columns={xy7_10.columns[-1]:'label'})\n",
    "print(xy7_10)\n",
    "\n",
    "xy8_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[8]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy8_10 = pd.concat([xy8_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy8_10 = pd.concat([xy8_10,ytrain8],axis=1)\n",
    "xy8_10 = xy8_10.rename(columns={xy8_10.columns[-1]:'label'})\n",
    "print(xy8_10)\n",
    "\n",
    "xy9_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[9]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy9_10 = pd.concat([xy9_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy9_10 = pd.concat([xy9_10,ytrain9],axis=1)\n",
    "xy9_10 = xy9_10.rename(columns={xy9_10.columns[-1]:'label'})\n",
    "print(xy9_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      375  2259  260  1259  2234  label\n",
      "0      80    64  190    63   147      0\n",
      "1      66    92  193   153   221      0\n",
      "2     182    71  129   107   241      0\n",
      "3      94    50  116    66   191      0\n",
      "4      87    85  194    92   227      0\n",
      "...   ...   ...  ...   ...   ...    ...\n",
      "9685  163    28  230   140   189      1\n",
      "9686  106   142  160   107   191      1\n",
      "9687  196    78  180    99   197      1\n",
      "9688  116    99  181   159   208      1\n",
      "9689  167    50  147   128   207      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "      461  924  2129  692  1734  label\n",
      "0      71  100   132   42   161      1\n",
      "1      99  126   191   49    92      1\n",
      "2     189   79   130  115   124      1\n",
      "3     217   93   161  141    85      1\n",
      "4      83   98   147   71   246      1\n",
      "...   ...  ...   ...  ...   ...    ...\n",
      "9685  163  223   150   68   117      1\n",
      "9686  246  162   163   64   156      1\n",
      "9687  168  183   145   43   140      1\n",
      "9688  179  231   138   42   140      1\n",
      "9689  182  136   108   64   161      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "      600  1642  352   37  957  label\n",
      "0     108    87  177  120   95      1\n",
      "1     115   148  150   75   76      1\n",
      "2      53   142   74  125  151      1\n",
      "3     122   166   89  170  120      1\n",
      "4     160   189  160  109  113      1\n",
      "...   ...   ...  ...  ...  ...    ...\n",
      "9685   19    58  176   33  168      1\n",
      "9686   69    35  247  255  158      1\n",
      "9687   64    41  106  170  123      1\n",
      "9688   90    44  236  227  151      1\n",
      "9689   67    45  128   94   40      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "      1060  1488  1014  1077  946  label\n",
      "0       97   241   188    96  101      1\n",
      "1      130   191    60   154  103      1\n",
      "2       90   215    74   152  104      1\n",
      "3      150   189    64   138  138      1\n",
      "4      111    57   117   112  137      1\n",
      "...    ...   ...   ...   ...  ...    ...\n",
      "9685   208   220   212   241  106      1\n",
      "9686   174   160   212   241  146      1\n",
      "9687   216   180   174   225  131      1\n",
      "9688   211   153   216   242  155      1\n",
      "9689   128   248    54   216   97      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "      1855  1052  474    3  1323  label\n",
      "0      177    96  170  106   184      1\n",
      "1      130   157  202  120   135      1\n",
      "2      168   191   78  142   120      1\n",
      "3      161   147  110  106    78      1\n",
      "4      155   127  146   92    85      1\n",
      "...    ...   ...  ...  ...   ...    ...\n",
      "9685   130   119  131  191    92      1\n",
      "9686   136    87  177  198    78      1\n",
      "9687   153    92  113  198    85      1\n",
      "9688   146   151   60  227    42      1\n",
      "9689   122   124   85  248    50      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "      1097  2015  2296  1144   75  label\n",
      "0      126   167   106   129  227      1\n",
      "1      181    62   105   151  135      1\n",
      "2      182    97   121   174  198      1\n",
      "3       99   198    67   185  177      1\n",
      "4      188   135   112   153  149      1\n",
      "...    ...   ...   ...   ...  ...    ...\n",
      "9685   138    47    42   129   92      1\n",
      "9686   140    80    98   116  205      1\n",
      "9687   134   118    81   112  241      1\n",
      "9688   208    90    46   224   92      1\n",
      "9689   239    66    36   248   57      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "      1526  839  2177  659  1905  label\n",
      "0      152  241   125   85   149      1\n",
      "1      126  246   151  162   149      1\n",
      "2      147  250   101  165   205      1\n",
      "3      101  238   116  141   184      1\n",
      "4      120  227   168  175   120      1\n",
      "...    ...  ...   ...  ...   ...    ...\n",
      "9685   160  243   175  157   113      1\n",
      "9686   103  220   184  211    92      1\n",
      "9687   159  206   182  213   120      1\n",
      "9688   144  206   170  136    92      1\n",
      "9689   123  225   161   86   120      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "      2054  1097  1044  291  213  label\n",
      "0       85   126   106  138  185      1\n",
      "1      135   181   110  103  171      1\n",
      "2      135   182   100  124  200      1\n",
      "3      164    99   100  134  133      1\n",
      "4      164   188    67  160  200      1\n",
      "...    ...   ...   ...  ...  ...    ...\n",
      "9685   124   138   188  255  241      1\n",
      "9686    74   140   160  241   97      1\n",
      "9687   150   134   163  132  167      1\n",
      "9688   159   208   145  216  161      1\n",
      "9689   147   239    78  244   79      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "      1761  1536  382  1449  1942  label\n",
      "0      110   241  191   191   139      1\n",
      "1      177   224   73   198   171      1\n",
      "2      180   242  156   212   193      1\n",
      "3      192   218  130   192   188      1\n",
      "4       85    77  205   166   160      1\n",
      "...    ...   ...  ...   ...   ...    ...\n",
      "9685   241   252   85   142    66      1\n",
      "9686   241   130   30   110    59      1\n",
      "9687   248   194  158   106    19      1\n",
      "9688   216   133   36   159    49      1\n",
      "9689   238   220  151   142    21      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "      2105  917  685  1099  593  label\n",
      "0      104  114   82    91  180      1\n",
      "1       92   76   87   181  194      1\n",
      "2       76   76  143   167  156      1\n",
      "3      126   82  130   143   97      1\n",
      "4      117  208  204   153  118      1\n",
      "...    ...  ...  ...   ...  ...    ...\n",
      "9685   171  231  236   118  177      0\n",
      "9686   172  212  188    66  156      0\n",
      "9687   165  191  232   165  208      0\n",
      "9688   161  212   37   178  172      0\n",
      "9689   174   74  247   200  182      0\n",
      "\n",
      "[9690 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "xy0_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[0]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy0_5 = pd.concat([xy0_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy0_5 = pd.concat([xy0_5,ytrain0],axis=1)\n",
    "xy0_5 = xy0_5.rename(columns={xy0_5.columns[-1]:'label'})\n",
    "print(xy0_5)\n",
    "    \n",
    "xy1_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[1]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy1_5 = pd.concat([xy1_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy1_5 = pd.concat([xy1_5,ytrain1],axis=1)\n",
    "xy1_5 = xy1_5.rename(columns={xy1_5.columns[-1]:'label'})\n",
    "print(xy1_5)\n",
    "\n",
    "xy2_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[2]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy2_5 = pd.concat([xy2_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy2_5 = pd.concat([xy2_5,ytrain2],axis=1)\n",
    "xy2_5 = xy2_5.rename(columns={xy2_5.columns[-1]:'label'})\n",
    "print(xy2_5)\n",
    "\n",
    "xy3_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[3]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy3_5 = pd.concat([xy3_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy3_5 = pd.concat([xy3_5,ytrain3],axis=1)\n",
    "xy3_5 = xy3_5.rename(columns={xy3_5.columns[-1]:'label'})\n",
    "print(xy3_5)\n",
    "\n",
    "xy4_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[4]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy4_5 = pd.concat([xy4_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy4_5 = pd.concat([xy4_5,ytrain4],axis=1)\n",
    "xy4_5 = xy4_5.rename(columns={xy4_5.columns[-1]:'label'})\n",
    "print(xy4_5)\n",
    "\n",
    "xy5_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[5]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy5_5 = pd.concat([xy5_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy5_5 = pd.concat([xy5_5,ytrain5],axis=1)\n",
    "xy5_5 = xy5_5.rename(columns={xy5_5.columns[-1]:'label'})\n",
    "print(xy5_5)\n",
    "\n",
    "xy6_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[6]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy6_5 = pd.concat([xy6_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy6_5 = pd.concat([xy6_5,ytrain6],axis=1)\n",
    "xy6_5 = xy6_5.rename(columns={xy6_5.columns[-1]:'label'})\n",
    "print(xy6_5)\n",
    "\n",
    "xy7_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[7]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy7_5 = pd.concat([xy7_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy7_5 = pd.concat([xy7_5,ytrain7],axis=1)\n",
    "xy7_5 = xy7_5.rename(columns={xy7_5.columns[-1]:'label'})\n",
    "print(xy7_5)\n",
    "\n",
    "xy8_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[8]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy8_5 = pd.concat([xy8_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy8_5 = pd.concat([xy8_5,ytrain8],axis=1)\n",
    "xy8_5 = xy8_5.rename(columns={xy8_5.columns[-1]:'label'})\n",
    "print(xy8_5)\n",
    "\n",
    "xy9_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[9]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy9_5 = pd.concat([xy9_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy9_5 = pd.concat([xy9_5,ytrain9],axis=1)\n",
    "xy9_5 = xy9_5.rename(columns={xy9_5.columns[-1]:'label'})\n",
    "print(xy9_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9685    1\n",
       "9686    1\n",
       "9687    1\n",
       "9688    1\n",
       "9689    1\n",
       "Name: label, Length: 9690, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=xy0_5['label']\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>375</th>\n",
       "      <th>2259</th>\n",
       "      <th>260</th>\n",
       "      <th>1259</th>\n",
       "      <th>2234</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>64</td>\n",
       "      <td>190</td>\n",
       "      <td>63</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>92</td>\n",
       "      <td>193</td>\n",
       "      <td>153</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>182</td>\n",
       "      <td>71</td>\n",
       "      <td>129</td>\n",
       "      <td>107</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "      <td>50</td>\n",
       "      <td>116</td>\n",
       "      <td>66</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>85</td>\n",
       "      <td>194</td>\n",
       "      <td>92</td>\n",
       "      <td>227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9685</th>\n",
       "      <td>163</td>\n",
       "      <td>28</td>\n",
       "      <td>230</td>\n",
       "      <td>140</td>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9686</th>\n",
       "      <td>106</td>\n",
       "      <td>142</td>\n",
       "      <td>160</td>\n",
       "      <td>107</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9687</th>\n",
       "      <td>196</td>\n",
       "      <td>78</td>\n",
       "      <td>180</td>\n",
       "      <td>99</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9688</th>\n",
       "      <td>116</td>\n",
       "      <td>99</td>\n",
       "      <td>181</td>\n",
       "      <td>159</td>\n",
       "      <td>208</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9689</th>\n",
       "      <td>167</td>\n",
       "      <td>50</td>\n",
       "      <td>147</td>\n",
       "      <td>128</td>\n",
       "      <td>207</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9690 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      375  2259  260  1259  2234  label\n",
       "0      80    64  190    63   147      0\n",
       "1      66    92  193   153   221      0\n",
       "2     182    71  129   107   241      0\n",
       "3      94    50  116    66   191      0\n",
       "4      87    85  194    92   227      0\n",
       "...   ...   ...  ...   ...   ...    ...\n",
       "9685  163    28  230   140   189      1\n",
       "9686  106   142  160   107   191      1\n",
       "9687  196    78  180    99   197      1\n",
       "9688  116    99  181   159   208      1\n",
       "9689  167    50  147   128   207      1\n",
       "\n",
       "[9690 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy0_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "seed_value = 22\n",
    "processed_df = xy9_20.drop(columns=['label'])\n",
    "y_train = xy9_20['label']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(processed_df, y_train, test_size=0.3, random_state=seed_value)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train, Y_train)\n",
    "\n",
    "predicted = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9594083247334021\n",
      "F1 Score: 0.9589088595511027\n",
      "Confusion Matrix:\n",
      " [[  20   61]\n",
      " [  57 2769]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(predicted, Y_test)\n",
    "f1 = f1_score(predicted, Y_test, average=\"weighted\")\n",
    "conf_matrix = confusion_matrix(predicted, Y_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=xy0_5['label']\n",
    "processed_df=xy0_5.drop(columns=['label'])\n",
    "naive_bayes_search(processed_df,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current Data frame is:  0\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "The current Data frame is:  1\n",
      "Accuracy: 0.7564499484004128\n",
      "F1 Score: 0.8214138268047296\n",
      "Precision: 0.6923353894561662\n",
      "Recall/Sensitivity/True Positive Rate: 0.7564499484004128\n",
      "Confusion Matrix:\n",
      " [[  64   86]\n",
      " [ 622 2135]]\n",
      "\n",
      "\n",
      "The current Data frame is:  2\n",
      "Accuracy: 0.7715858273133815\n",
      "F1 Score: 0.8710679611650485\n",
      "Precision: 0.8237588615974939\n",
      "Recall/Sensitivity/True Positive Rate: 0.7715858273133815\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [ 664 2243]]\n",
      "\n",
      "\n",
      "The current Data frame is:  3\n",
      "Accuracy: 0.8555211558307534\n",
      "F1 Score: 0.9221357063403782\n",
      "Precision: 0.8763952922432349\n",
      "Recall/Sensitivity/True Positive Rate: 0.8555211558307534\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [ 420 2487]]\n",
      "\n",
      "\n",
      "The current Data frame is:  4\n",
      "Accuracy: 0.7994496044031648\n",
      "F1 Score: 0.8885490346014147\n",
      "Precision: 0.839670065577212\n",
      "Recall/Sensitivity/True Positive Rate: 0.7994496044031648\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [ 583 2324]]\n",
      "\n",
      "\n",
      "The current Data frame is:  5\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "The current Data frame is:  6\n",
      "Accuracy: 0.9635362917096664\n",
      "F1 Score: 0.9794659761808988\n",
      "Precision: 0.9422471190378701\n",
      "Recall/Sensitivity/True Positive Rate: 0.9635362917096664\n",
      "Confusion Matrix:\n",
      " [[   2    4]\n",
      " [ 102 2799]]\n",
      "\n",
      "\n",
      "The current Data frame is:  7\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "The current Data frame is:  8\n",
      "Accuracy: 0.9380804953560371\n",
      "F1 Score: 0.9486640182730443\n",
      "Precision: 0.9230969267472822\n",
      "Recall/Sensitivity/True Positive Rate: 0.9380804953560371\n",
      "Confusion Matrix:\n",
      " [[  41   43]\n",
      " [ 137 2686]]\n",
      "\n",
      "\n",
      "The current Data frame is:  9\n",
      "Accuracy: 0.9735122119023047\n",
      "F1 Score: 0.9865783510545582\n",
      "Precision: 0.9742138148206131\n",
      "Recall/Sensitivity/True Positive Rate: 0.9735122119023047\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  77 2830]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    strings=globals()[\"xy{}_5\".format(i)]\n",
    "    print(\"The current Data frame is: \",i)\n",
    "    y_train=strings['label']\n",
    "    processed_df=strings.drop(columns=['label'])\n",
    "    naive_bayes_search(processed_df,y_train)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current Data frame is:  0\n",
      "Accuracy: 0.9762641898864809\n",
      "F1 Score: 0.986004328380703\n",
      "Precision: 0.9597987456017623\n",
      "Recall/Sensitivity/True Positive Rate: 0.9762641898864809\n",
      "Confusion Matrix:\n",
      " [[   1    5]\n",
      " [  64 2837]]\n",
      "\n",
      "\n",
      "The current Data frame is:  1\n",
      "Accuracy: 0.7492260061919505\n",
      "F1 Score: 0.788748706594703\n",
      "Precision: 0.7012915812614519\n",
      "Recall/Sensitivity/True Positive Rate: 0.7492260061919505\n",
      "Confusion Matrix:\n",
      " [[ 127  170]\n",
      " [ 559 2051]]\n",
      "\n",
      "\n",
      "The current Data frame is:  2\n",
      "Accuracy: 0.7719298245614035\n",
      "F1 Score: 0.8702942302431761\n",
      "Precision: 0.7479701319414238\n",
      "Recall/Sensitivity/True Positive Rate: 0.7719298245614035\n",
      "Confusion Matrix:\n",
      " [[   2    1]\n",
      " [ 662 2242]]\n",
      "\n",
      "\n",
      "The current Data frame is:  3\n",
      "Accuracy: 0.8575851393188855\n",
      "F1 Score: 0.9135574565567034\n",
      "Precision: 0.8219788666038499\n",
      "Recall/Sensitivity/True Positive Rate: 0.8575851393188855\n",
      "Confusion Matrix:\n",
      " [[  19   13]\n",
      " [ 401 2474]]\n",
      "\n",
      "\n",
      "The current Data frame is:  4\n",
      "Accuracy: 0.7960096319229446\n",
      "F1 Score: 0.8754016437218146\n",
      "Precision: 0.7131501784628007\n",
      "Recall/Sensitivity/True Positive Rate: 0.7960096319229446\n",
      "Confusion Matrix:\n",
      " [[  13   23]\n",
      " [ 570 2301]]\n",
      "\n",
      "\n",
      "The current Data frame is:  5\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "The current Data frame is:  6\n",
      "Accuracy: 0.9638802889576883\n",
      "F1 Score: 0.9793551521499824\n",
      "Precision: 0.945975130524079\n",
      "Recall/Sensitivity/True Positive Rate: 0.9638802889576883\n",
      "Confusion Matrix:\n",
      " [[   3    4]\n",
      " [ 101 2799]]\n",
      "\n",
      "\n",
      "The current Data frame is:  7\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "The current Data frame is:  8\n",
      "Accuracy: 0.9370485036119711\n",
      "F1 Score: 0.9422514561943578\n",
      "Precision: 0.9283412531837056\n",
      "Recall/Sensitivity/True Positive Rate: 0.9370485036119711\n",
      "Confusion Matrix:\n",
      " [[  60   65]\n",
      " [ 118 2664]]\n",
      "\n",
      "\n",
      "The current Data frame is:  9\n",
      "Accuracy: 0.9735122119023047\n",
      "F1 Score: 0.9865783510545582\n",
      "Precision: 0.9742138148206131\n",
      "Recall/Sensitivity/True Positive Rate: 0.9735122119023047\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  77 2830]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    strings=globals()[\"xy{}_10\".format(i)]\n",
    "    print(\"The current Data frame is: \",i)\n",
    "    y_train=strings['label']\n",
    "    processed_df=strings.drop(columns=['label'])\n",
    "    naive_bayes_search(processed_df,y_train)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current Data frame is:  0\n",
      "Accuracy: 0.9408324733402132\n",
      "F1 Score: 0.9298227331223108\n",
      "Precision: 0.9647425458869029\n",
      "Recall/Sensitivity/True Positive Rate: 0.9408324733402132\n",
      "Confusion Matrix:\n",
      " [[  20  127]\n",
      " [  45 2715]]\n",
      "\n",
      "\n",
      "The current Data frame is:  1\n",
      "Accuracy: 0.7227382180942552\n",
      "F1 Score: 0.7358196617245677\n",
      "Precision: 0.7006904522628736\n",
      "Recall/Sensitivity/True Positive Rate: 0.7227382180942552\n",
      "Confusion Matrix:\n",
      " [[ 205  325]\n",
      " [ 481 1896]]\n",
      "\n",
      "\n",
      "The current Data frame is:  2\n",
      "Accuracy: 0.7757137942896457\n",
      "F1 Score: 0.8409554094212244\n",
      "Precision: 0.7316272094422238\n",
      "Recall/Sensitivity/True Positive Rate: 0.7757137942896457\n",
      "Confusion Matrix:\n",
      " [[  67   55]\n",
      " [ 597 2188]]\n",
      "\n",
      "\n",
      "The current Data frame is:  3\n",
      "Accuracy: 0.8634330925352597\n",
      "F1 Score: 0.8759573623682619\n",
      "Precision: 0.8455012941638187\n",
      "Recall/Sensitivity/True Positive Rate: 0.8634330925352597\n",
      "Confusion Matrix:\n",
      " [[ 148  125]\n",
      " [ 272 2362]]\n",
      "\n",
      "\n",
      "The current Data frame is:  4\n",
      "Accuracy: 0.7574819401444789\n",
      "F1 Score: 0.7699371669873262\n",
      "Precision: 0.7358708143420892\n",
      "Recall/Sensitivity/True Positive Rate: 0.7574819401444789\n",
      "Confusion Matrix:\n",
      " [[ 163  285]\n",
      " [ 420 2039]]\n",
      "\n",
      "\n",
      "The current Data frame is:  5\n",
      "Accuracy: 0.9742002063983488\n",
      "F1 Score: 0.9781695948293543\n",
      "Precision: 0.9674967501060548\n",
      "Recall/Sensitivity/True Positive Rate: 0.9742002063983488\n",
      "Confusion Matrix:\n",
      " [[  12   22]\n",
      " [  53 2820]]\n",
      "\n",
      "\n",
      "The current Data frame is:  6\n",
      "Accuracy: 0.9625042999656003\n",
      "F1 Score: 0.9773596651145311\n",
      "Precision: 0.9403533111765242\n",
      "Recall/Sensitivity/True Positive Rate: 0.9625042999656003\n",
      "Confusion Matrix:\n",
      " [[   3    8]\n",
      " [ 101 2795]]\n",
      "\n",
      "\n",
      "The current Data frame is:  7\n",
      "Accuracy: 0.978328173374613\n",
      "F1 Score: 0.9883983805945102\n",
      "Precision: 0.9787981647954045\n",
      "Recall/Sensitivity/True Positive Rate: 0.978328173374613\n",
      "Confusion Matrix:\n",
      " [[   2    0]\n",
      " [  63 2842]]\n",
      "\n",
      "\n",
      "The current Data frame is:  8\n",
      "Accuracy: 0.9339525283797729\n",
      "F1 Score: 0.937892488111229\n",
      "Precision: 0.9269510525247937\n",
      "Recall/Sensitivity/True Positive Rate: 0.9339525283797729\n",
      "Confusion Matrix:\n",
      " [[  62   76]\n",
      " [ 116 2653]]\n",
      "\n",
      "\n",
      "The current Data frame is:  9\n",
      "Accuracy: 0.9594083247334021\n",
      "F1 Score: 0.9589088595511027\n",
      "Precision: 0.9604168098636024\n",
      "Recall/Sensitivity/True Positive Rate: 0.9594083247334021\n",
      "Confusion Matrix:\n",
      " [[  20   61]\n",
      " [  57 2769]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    strings=globals()[\"xy{}_20\".format(i)]\n",
    "    print(\"The current Data frame is: \",i)\n",
    "    y_train=strings['label']\n",
    "    processed_df=strings.drop(columns=['label'])\n",
    "    naive_bayes_search(processed_df,y_train)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Victor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3',\n",
       " '24',\n",
       " '37',\n",
       " '75',\n",
       " '102',\n",
       " '109',\n",
       " '118',\n",
       " '135',\n",
       " '186',\n",
       " '190',\n",
       " '194',\n",
       " '213',\n",
       " '247',\n",
       " '260',\n",
       " '265',\n",
       " '269',\n",
       " '271',\n",
       " '278',\n",
       " '282',\n",
       " '287',\n",
       " '290',\n",
       " '291',\n",
       " '296',\n",
       " '298',\n",
       " '299',\n",
       " '318',\n",
       " '348',\n",
       " '352',\n",
       " '354',\n",
       " '356',\n",
       " '360',\n",
       " '366',\n",
       " '367',\n",
       " '375',\n",
       " '382',\n",
       " '390',\n",
       " '398',\n",
       " '401',\n",
       " '437',\n",
       " '450',\n",
       " '460',\n",
       " '461',\n",
       " '472',\n",
       " '474',\n",
       " '491',\n",
       " '498',\n",
       " '508',\n",
       " '519',\n",
       " '539',\n",
       " '573',\n",
       " '589',\n",
       " '593',\n",
       " '600',\n",
       " '604',\n",
       " '606',\n",
       " '621',\n",
       " '647',\n",
       " '649',\n",
       " '659',\n",
       " '662',\n",
       " '672',\n",
       " '677',\n",
       " '680',\n",
       " '685',\n",
       " '692',\n",
       " '708',\n",
       " '711',\n",
       " '724',\n",
       " '740',\n",
       " '798',\n",
       " '800',\n",
       " '814',\n",
       " '823',\n",
       " '839',\n",
       " '846',\n",
       " '847',\n",
       " '850',\n",
       " '872',\n",
       " '878',\n",
       " '917',\n",
       " '924',\n",
       " '929',\n",
       " '946',\n",
       " '957',\n",
       " '1014',\n",
       " '1044',\n",
       " '1052',\n",
       " '1060',\n",
       " '1062',\n",
       " '1064',\n",
       " '1077',\n",
       " '1096',\n",
       " '1097',\n",
       " '1098',\n",
       " '1099',\n",
       " '1114',\n",
       " '1144',\n",
       " '1151',\n",
       " '1161',\n",
       " '1170',\n",
       " '1191',\n",
       " '1204',\n",
       " '1222',\n",
       " '1229',\n",
       " '1247',\n",
       " '1255',\n",
       " '1259',\n",
       " '1323',\n",
       " '1326',\n",
       " '1357',\n",
       " '1373',\n",
       " '1401',\n",
       " '1417',\n",
       " '1430',\n",
       " '1434',\n",
       " '1437',\n",
       " '1449',\n",
       " '1461',\n",
       " '1488',\n",
       " '1526',\n",
       " '1536',\n",
       " '1563',\n",
       " '1580',\n",
       " '1590',\n",
       " '1639',\n",
       " '1642',\n",
       " '1661',\n",
       " '1670',\n",
       " '1684',\n",
       " '1715',\n",
       " '1728',\n",
       " '1733',\n",
       " '1734',\n",
       " '1761',\n",
       " '1771',\n",
       " '1773',\n",
       " '1778',\n",
       " '1780',\n",
       " '1790',\n",
       " '1818',\n",
       " '1820',\n",
       " '1827',\n",
       " '1853',\n",
       " '1854',\n",
       " '1855',\n",
       " '1865',\n",
       " '1866',\n",
       " '1867',\n",
       " '1880',\n",
       " '1898',\n",
       " '1900',\n",
       " '1905',\n",
       " '1913',\n",
       " '1922',\n",
       " '1942',\n",
       " '1951',\n",
       " '1982',\n",
       " '1990',\n",
       " '2007',\n",
       " '2012',\n",
       " '2015',\n",
       " '2020',\n",
       " '2026',\n",
       " '2054',\n",
       " '2060',\n",
       " '2069',\n",
       " '2081',\n",
       " '2103',\n",
       " '2104',\n",
       " '2105',\n",
       " '2127',\n",
       " '2129',\n",
       " '2165',\n",
       " '2166',\n",
       " '2175',\n",
       " '2177',\n",
       " '2178',\n",
       " '2184',\n",
       " '2195',\n",
       " '2202',\n",
       " '2206',\n",
       " '2220',\n",
       " '2234',\n",
       " '2240',\n",
       " '2254',\n",
       " '2255',\n",
       " '2259',\n",
       " '2292',\n",
       " '2296',\n",
       " '2303']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = []\n",
    "for i in range(len(selected_features_per_class)):\n",
    "    features.append(selected_features_per_class[i][0:20])\n",
    "features = np.concatenate(features)\n",
    "features = np.unique(features)\n",
    "features = features.tolist()\n",
    "for i in range(len(features)):\n",
    "    features[i] = str(features[i])\n",
    "features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2294</th>\n",
       "      <th>2295</th>\n",
       "      <th>2296</th>\n",
       "      <th>2297</th>\n",
       "      <th>2298</th>\n",
       "      <th>2299</th>\n",
       "      <th>2300</th>\n",
       "      <th>2301</th>\n",
       "      <th>2302</th>\n",
       "      <th>2303</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>112.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9685</th>\n",
       "      <td>247.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9686</th>\n",
       "      <td>151.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9687</th>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9688</th>\n",
       "      <td>255.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9689</th>\n",
       "      <td>252.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9690 rows × 2304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2      3      4      5      6      7      8      9  \\\n",
       "0      78.0   77.0   76.0   82.0   87.0   92.0  104.0  119.0  117.0  120.0   \n",
       "1      73.0   75.0   79.0   78.0   76.0   75.0   89.0  107.0  133.0  125.0   \n",
       "2      72.0   75.0   79.0   77.0   81.0   89.0  105.0  109.0   86.0   90.0   \n",
       "3      67.0   70.0   74.0   80.0   93.0  107.0  110.0   96.0   69.0  100.0   \n",
       "4      74.0   74.0   73.0   72.0   77.0   87.0  104.0  109.0   84.0   83.0   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "9685  247.0  220.0  254.0  213.0  129.0  208.0  254.0  255.0  255.0  255.0   \n",
       "9686  151.0  118.0  254.0  255.0  255.0  255.0  254.0  254.0  254.0  252.0   \n",
       "9687  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "9688  255.0  253.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "9689  252.0  189.0  238.0  255.0  255.0  245.0  219.0  212.0  140.0   40.0   \n",
       "\n",
       "      ...   2294  2295  2296   2297  2298  2299  2300   2301   2302   2303  \n",
       "0     ...   87.0  79.0  72.0   76.0  83.0  95.0  99.0   98.0   95.0   94.0  \n",
       "1     ...   96.0  93.0  85.0   77.0  69.0  73.0  83.0  100.0  101.0  101.0  \n",
       "2     ...   98.0  95.0  88.0   80.0  73.0  71.0  74.0   80.0   89.0   95.0  \n",
       "3     ...  112.0  92.0  87.0   82.0  77.0  72.0  70.0   72.0   81.0   88.0  \n",
       "4     ...  100.0  98.0  99.0  100.0  99.0  89.0  78.0   66.0   68.0   72.0  \n",
       "...   ...    ...   ...   ...    ...   ...   ...   ...    ...    ...    ...  \n",
       "9685  ...   35.0  29.0  27.0   26.0  25.0  23.0  22.0   26.0   26.0   27.0  \n",
       "9686  ...   37.0  31.0  30.0   30.0  30.0  30.0  29.0   26.0   28.0   27.0  \n",
       "9687  ...   41.0  49.0  42.0   36.0  33.0  36.0  39.0   31.0   39.0   43.0  \n",
       "9688  ...   38.0  27.0  26.0   27.0  35.0  28.0  27.0   26.0   26.0   24.0  \n",
       "9689  ...   34.0  23.0  23.0   30.0  32.0  23.0  23.0   26.0   20.0   17.0  \n",
       "\n",
       "[9690 rows x 2304 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pd.read_csv('Dataset/x_train_all.csv')\n",
    "y_train = pd.read_csv('Dataset/y_train_all.csv')\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>24</th>\n",
       "      <th>37</th>\n",
       "      <th>75</th>\n",
       "      <th>102</th>\n",
       "      <th>109</th>\n",
       "      <th>118</th>\n",
       "      <th>135</th>\n",
       "      <th>186</th>\n",
       "      <th>190</th>\n",
       "      <th>...</th>\n",
       "      <th>2206</th>\n",
       "      <th>2220</th>\n",
       "      <th>2234</th>\n",
       "      <th>2240</th>\n",
       "      <th>2254</th>\n",
       "      <th>2255</th>\n",
       "      <th>2259</th>\n",
       "      <th>2292</th>\n",
       "      <th>2296</th>\n",
       "      <th>2303</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106</td>\n",
       "      <td>110</td>\n",
       "      <td>120</td>\n",
       "      <td>227</td>\n",
       "      <td>128</td>\n",
       "      <td>194</td>\n",
       "      <td>101</td>\n",
       "      <td>149</td>\n",
       "      <td>145</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>170</td>\n",
       "      <td>117</td>\n",
       "      <td>147</td>\n",
       "      <td>247</td>\n",
       "      <td>205</td>\n",
       "      <td>163</td>\n",
       "      <td>64</td>\n",
       "      <td>152</td>\n",
       "      <td>106</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>113</td>\n",
       "      <td>75</td>\n",
       "      <td>135</td>\n",
       "      <td>142</td>\n",
       "      <td>177</td>\n",
       "      <td>143</td>\n",
       "      <td>78</td>\n",
       "      <td>174</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>74</td>\n",
       "      <td>221</td>\n",
       "      <td>137</td>\n",
       "      <td>177</td>\n",
       "      <td>142</td>\n",
       "      <td>92</td>\n",
       "      <td>148</td>\n",
       "      <td>105</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142</td>\n",
       "      <td>166</td>\n",
       "      <td>125</td>\n",
       "      <td>198</td>\n",
       "      <td>114</td>\n",
       "      <td>232</td>\n",
       "      <td>233</td>\n",
       "      <td>106</td>\n",
       "      <td>170</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>170</td>\n",
       "      <td>78</td>\n",
       "      <td>241</td>\n",
       "      <td>136</td>\n",
       "      <td>156</td>\n",
       "      <td>177</td>\n",
       "      <td>71</td>\n",
       "      <td>206</td>\n",
       "      <td>121</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106</td>\n",
       "      <td>220</td>\n",
       "      <td>170</td>\n",
       "      <td>177</td>\n",
       "      <td>156</td>\n",
       "      <td>250</td>\n",
       "      <td>241</td>\n",
       "      <td>64</td>\n",
       "      <td>212</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>142</td>\n",
       "      <td>132</td>\n",
       "      <td>191</td>\n",
       "      <td>105</td>\n",
       "      <td>85</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>227</td>\n",
       "      <td>67</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92</td>\n",
       "      <td>57</td>\n",
       "      <td>109</td>\n",
       "      <td>149</td>\n",
       "      <td>156</td>\n",
       "      <td>250</td>\n",
       "      <td>154</td>\n",
       "      <td>106</td>\n",
       "      <td>142</td>\n",
       "      <td>113</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>230</td>\n",
       "      <td>227</td>\n",
       "      <td>124</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>85</td>\n",
       "      <td>128</td>\n",
       "      <td>112</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9685</th>\n",
       "      <td>191</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>92</td>\n",
       "      <td>230</td>\n",
       "      <td>222</td>\n",
       "      <td>118</td>\n",
       "      <td>113</td>\n",
       "      <td>188</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>188</td>\n",
       "      <td>189</td>\n",
       "      <td>222</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>28</td>\n",
       "      <td>181</td>\n",
       "      <td>42</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9686</th>\n",
       "      <td>198</td>\n",
       "      <td>234</td>\n",
       "      <td>255</td>\n",
       "      <td>205</td>\n",
       "      <td>152</td>\n",
       "      <td>101</td>\n",
       "      <td>136</td>\n",
       "      <td>149</td>\n",
       "      <td>142</td>\n",
       "      <td>234</td>\n",
       "      <td>...</td>\n",
       "      <td>106</td>\n",
       "      <td>192</td>\n",
       "      <td>191</td>\n",
       "      <td>184</td>\n",
       "      <td>142</td>\n",
       "      <td>149</td>\n",
       "      <td>142</td>\n",
       "      <td>195</td>\n",
       "      <td>98</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9687</th>\n",
       "      <td>198</td>\n",
       "      <td>209</td>\n",
       "      <td>170</td>\n",
       "      <td>241</td>\n",
       "      <td>230</td>\n",
       "      <td>203</td>\n",
       "      <td>226</td>\n",
       "      <td>241</td>\n",
       "      <td>174</td>\n",
       "      <td>113</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>202</td>\n",
       "      <td>197</td>\n",
       "      <td>220</td>\n",
       "      <td>156</td>\n",
       "      <td>142</td>\n",
       "      <td>78</td>\n",
       "      <td>181</td>\n",
       "      <td>81</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9688</th>\n",
       "      <td>227</td>\n",
       "      <td>170</td>\n",
       "      <td>227</td>\n",
       "      <td>92</td>\n",
       "      <td>223</td>\n",
       "      <td>163</td>\n",
       "      <td>192</td>\n",
       "      <td>120</td>\n",
       "      <td>113</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>181</td>\n",
       "      <td>208</td>\n",
       "      <td>216</td>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>99</td>\n",
       "      <td>181</td>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9689</th>\n",
       "      <td>248</td>\n",
       "      <td>96</td>\n",
       "      <td>94</td>\n",
       "      <td>57</td>\n",
       "      <td>56</td>\n",
       "      <td>177</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>184</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>106</td>\n",
       "      <td>181</td>\n",
       "      <td>207</td>\n",
       "      <td>233</td>\n",
       "      <td>78</td>\n",
       "      <td>71</td>\n",
       "      <td>50</td>\n",
       "      <td>198</td>\n",
       "      <td>36</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9690 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        3   24   37   75  102  109  118  135  186  190  ...  2206  2220  2234  \\\n",
       "0     106  110  120  227  128  194  101  149  145   92  ...   170   117   147   \n",
       "1     120  113   75  135  142  177  143   78  174  106  ...   198    74   221   \n",
       "2     142  166  125  198  114  232  233  106  170   99  ...   170    78   241   \n",
       "3     106  220  170  177  156  250  241   64  212   71  ...   142   132   191   \n",
       "4      92   57  109  149  156  250  154  106  142  113  ...    78   230   227   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   \n",
       "9685  191   24   33   92  230  222  118  113  188   57  ...    64   188   189   \n",
       "9686  198  234  255  205  152  101  136  149  142  234  ...   106   192   191   \n",
       "9687  198  209  170  241  230  203  226  241  174  113  ...    92   202   197   \n",
       "9688  227  170  227   92  223  163  192  120  113   85  ...    71   181   208   \n",
       "9689  248   96   94   57   56  177   48   50  184  128  ...   106   181   207   \n",
       "\n",
       "      2240  2254  2255  2259  2292  2296  2303  \n",
       "0      247   205   163    64   152   106   191  \n",
       "1      137   177   142    92   148   105   135  \n",
       "2      136   156   177    71   206   121   170  \n",
       "3      105    85    78    50   227    67    64  \n",
       "4      124   106   106    85   128   112   128  \n",
       "...    ...   ...   ...   ...   ...   ...   ...  \n",
       "9685   222    71    71    28   181    42    71  \n",
       "9686   184   142   149   142   195    98   156  \n",
       "9687   220   156   142    78   181    81   177  \n",
       "9688   216    50    64    99   181    46    50  \n",
       "9689   233    78    71    50   198    36    50  \n",
       "\n",
       "[9690 rows x 190 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_x_train = xtrain[features]\n",
    "reduced_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anshu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43171654626762984\n",
      "F1 Score: 0.4230720103662578\n",
      "Precision: 0.49625079756666496\n",
      "Recall/Sensitivity/True Positive Rate: 0.43171654626762984\n",
      "Confusion Matrix:\n",
      " [[ 37 157  65  49  39   0   0   0   1   1]\n",
      " [ 11 223 130  29  43   0   3   0   3   0]\n",
      " [  7  57 214  66  31   0   1   1   2   3]\n",
      " [  2  57  61 144  50   0   3   3   0   1]\n",
      " [  4 143 139  66 351   2   4   1   2   3]\n",
      " [  0   1   8  26  19  49   1   9  16  11]\n",
      " [  2  17  27  22  27   2  67   1  23   8]\n",
      " [  0   4   4   0   4   3   2  43  22   6]\n",
      " [  1   4   3   0   2   2   7   1  92   9]\n",
      " [  1  23  13  18  17   7  16   6  17  35]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 4, ..., 3, 6, 1], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes_search(reduced_x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_image = reduced_x_train.iloc[0].values.reshape(14, 14)\n",
    "# plt.imshow(original_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d080205970>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_image = xtrain.iloc[0].values.reshape(48, 48)\n",
    "plt.imshow(original_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d08143bc40>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAGiCAYAAABkuvUyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgr0lEQVR4nO3df0xV9/3H8dedysVNuEYtCBMVY8sQi22hq9eorTqxsBHtzOKyxh+b7cKCOr0h7dBuXbsZms001LRCXf0xa63+cbV10TLJWsBG2UQhJZ0ym1ph5FKrXS/K5kXgfP/otze5A+Fjx7nXcp+P5CQ9h8+5vrkx5em5514clmVZAgAAGMDXIj0AAAD4aiAaAACAEaIBAAAYIRoAAIARogEAABghGgAAgBGiAQAAGCEaAACAEaIBAAAYIRoAAIARW6PhX//6l5YvXy6XyyWXy6Xly5frs88+6/ecVatWyeFwhGwzZ860c0wAAGBguJ0P/qMf/Uj//Oc/VVFRIUn66U9/quXLl+tPf/pTv+c9/PDD2rVrV3A/JibGzjEBAIAB26Lh7NmzqqioUG1trR544AFJ0h/+8Ae53W41NTUpLS3tpuc6nU6NHz/ertEAAMCXYFs0nDx5Ui6XKxgMkjRz5ky5XC6dOHGi32ioqqpSQkKCRo8erQcffFCbN29WQkJCn2sDgYACgUBwv6enR59++qnGjh0rh8MxeN8QAABDkGVZunr1qpKTk/W1r/V/14Jt0dDW1tbnD/qEhAS1tbXd9Lzc3Fz94Ac/0KRJk3ThwgX98pe/1Pz583X69Gk5nc5e60tKSvTMM88M6uwAAESblpYWTZgwod81txwNv/71rwf8IX3q1ClJ6vNf+pZl9XsFYNmyZcH/nj59urKzszVp0iQdOXJE3//+93utLy4ulsfjCe77/X5NnDhRZ86c0ahRowb8fvC/y8zMjPQIUeeVV16J9AhRZfPmzZEeIar09PREeoSo0t3drQ8++EBxcXEDrr3laFizZo1++MMf9rtm8uTJeu+99/Txxx/3+tonn3yixMRE4z8vKSlJkyZN0vnz5/v8utPp7PMKxKhRo4yeAPzveBko/L7+9a9HeoSoMmzYsEiPEFX4f0pkmDzvtxwN48aN07hx4wZc53a75ff79be//U3f/va3JUl//etf5ff7NWvWLOM/78qVK2ppaVFSUtKtjgoAAAaRbZ/TkJ6erocffliPP/64amtrVVtbq8cff1zf+973Qm6C/Na3vqVDhw5Jkq5du6aioiKdPHlSH330kaqqqpSfn69x48bpkUcesWtUAABgwNYPd3rttdd09913KycnRzk5OcrMzNSrr74asqapqUl+v1/S55cAGxsbtXjxYt11111auXKl7rrrLp08eZKXGgAAiDBbP9xpzJgx2rt3b79rLMsK/vfIkSP15z//2c6RAADAl8TvngAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGwhIN27ZtU2pqqmJjY5WVlaXjx4/3u766ulpZWVmKjY3VlClTVF5eHo4xAQBAP2yPhgMHDmj9+vXatGmT6uvrNWfOHOXm5qq5ubnP9RcuXFBeXp7mzJmj+vp6bdy4UevWrZPX67V7VAAA0A/bo+H555/X6tWr9dhjjyk9PV2lpaVKSUlRWVlZn+vLy8s1ceJElZaWKj09XY899ph+8pOfaMuWLXaPCgAA+mFrNHR2dur06dPKyckJOZ6Tk6MTJ070ec7Jkyd7rV+0aJHq6up048aNXusDgYDa29tDNgAAMPhsjYbLly+ru7tbiYmJIccTExPV1tbW5zltbW19ru/q6tLly5d7rS8pKZHL5QpuKSkpg/cNAACAoLDcCOlwOEL2LcvqdWyg9X0dl6Ti4mL5/f7g1tLSMggTAwCA/zbczgcfN26chg0b1uuqwqVLl3pdTfjC+PHj+1w/fPhwjR07ttd6p9Mpp9M5eEMDAIA+2XqlISYmRllZWaqsrAw5XllZqVmzZvV5jtvt7rX+2LFjys7O1ogRI2ybFQAA9M/2lyc8Ho9eeeUV7dy5U2fPntWGDRvU3NysgoICSZ+/vLBixYrg+oKCAl28eFEej0dnz57Vzp07tWPHDhUVFdk9KgAA6IetL09I0rJly3TlyhU9++yz8vl8mj59uo4ePapJkyZJknw+X8hnNqSmpuro0aPasGGDXnrpJSUnJ2vr1q1aunSp3aMCAIB+OKwv7jIcItrb2+VyufSPf/xDcXFxkR4nKkyZMiXSI0Sd1157LdIjRJVf/epXkR4hqvT09ER6hKjS3d2tpqYm+f1+xcfH97uW3z0BAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjIQlGrZt26bU1FTFxsYqKytLx48fv+naqqoqORyOXtu5c+fCMSoAALgJ26PhwIEDWr9+vTZt2qT6+nrNmTNHubm5am5u7ve8pqYm+Xy+4HbnnXfaPSoAAOiH7dHw/PPPa/Xq1XrssceUnp6u0tJSpaSkqKysrN/zEhISNH78+OA2bNgwu0cFAAD9GG7ng3d2dur06dP6xS9+EXI8JydHJ06c6Pfce++9V9evX9e0adP01FNPad68eX2uCwQCCgQCwf329nZJ0t133y2Hw/E/fgcwsWjRokiPEHWKiooiPUJU+fDDDyM9QlThH4nhZVmW8VpbrzRcvnxZ3d3dSkxMDDmemJiotra2Ps9JSkrS9u3b5fV6dfDgQaWlpWnBggWqqanpc31JSYlcLldwS0lJGfTvAwAA2Hyl4Qv//S9+y7JuehUgLS1NaWlpwX23262WlhZt2bJFc+fO7bW+uLhYHo8nuN/e3k44AABgA1uvNIwbN07Dhg3rdVXh0qVLva4+9GfmzJk6f/58n19zOp2Kj48P2QAAwOCzNRpiYmKUlZWlysrKkOOVlZWaNWuW8ePU19crKSlpsMcDAAC3wPaXJzwej5YvX67s7Gy53W5t375dzc3NKigokPT5ywutra3as2ePJKm0tFSTJ09WRkaGOjs7tXfvXnm9Xnm9XrtHBQAA/bA9GpYtW6YrV67o2Weflc/n0/Tp03X06FFNmjRJkuTz+UI+s6Gzs1NFRUVqbW3VyJEjlZGRoSNHjigvL8/uUQEAQD8c1q281+IroL29XS6XS06nk7dchglvuQy/xsbGSI8QVXjLZXjxlsvwsixLPT098vv9A94XyO+eAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYMTWaKipqVF+fr6Sk5PlcDj0xhtvDHhOdXW1srKyFBsbqylTpqi8vNzOEQEAgCFbo6Gjo0MzZszQiy++aLT+woULysvL05w5c1RfX6+NGzdq3bp18nq9do4JAAAMDLfzwXNzc5Wbm2u8vry8XBMnTlRpaakkKT09XXV1ddqyZYuWLl3a5zmBQECBQCC4397e/j/NDAAA+nZb3dNw8uRJ5eTkhBxbtGiR6urqdOPGjT7PKSkpkcvlCm4pKSnhGBUAgKhzW0VDW1ubEhMTQ44lJiaqq6tLly9f7vOc4uJi+f3+4NbS0hKOUQEAiDq2vjzxZTgcjpB9y7L6PP4Fp9Mpp9Np+1wAAES72+pKw/jx49XW1hZy7NKlSxo+fLjGjh0boakAAIB0m0WD2+1WZWVlyLFjx44pOztbI0aMiNBUAABAsjkarl27poaGBjU0NEj6/C2VDQ0Nam5ulvT5/QgrVqwIri8oKNDFixfl8Xh09uxZ7dy5Uzt27FBRUZGdYwIAAAO23tNQV1enefPmBfc9Ho8kaeXKldq9e7d8Pl8wICQpNTVVR48e1YYNG/TSSy8pOTlZW7duvenbLQEAQPg4rC/uNBwi2tvb5XK55HQ6b3rzJAbXokWLIj1C1GlsbIz0CFHlww8/jPQIUWXYsGGRHiGqWJalnp4e+f1+xcfH97v2trqnAQAA3L6IBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGbI2Gmpoa5efnKzk5WQ6HQ2+88Ua/66uqquRwOHpt586ds3NMAABgYLidD97R0aEZM2boxz/+sZYuXWp8XlNTk+Lj44P7d9xxhx3jAQCAW2BrNOTm5io3N/eWz0tISNDo0aON1gYCAQUCgeB+e3v7Lf95AABgYLZGw5d177336vr165o2bZqeeuopzZs376ZrS0pK9Mwzz/Q6npeXpxEjRtg5Jv7fgQMHIj1C1Fm4cGGkR4gqn376aaRHiCr//ve/Iz1CVLEsSz09PUZrb6sbIZOSkrR9+3Z5vV4dPHhQaWlpWrBggWpqam56TnFxsfx+f3BraWkJ48QAAESP2+pKQ1pamtLS0oL7brdbLS0t2rJli+bOndvnOU6nU06nM1wjAgAQtW6rKw19mTlzps6fPx/pMQAAiHq3fTTU19crKSkp0mMAABD1bH154tq1a/rggw+C+xcuXFBDQ4PGjBmjiRMnqri4WK2trdqzZ48kqbS0VJMnT1ZGRoY6Ozu1d+9eeb1eeb1eO8cEAAAGbI2Gurq6kHc+eDweSdLKlSu1e/du+Xw+NTc3B7/e2dmpoqIitba2auTIkcrIyNCRI0eUl5dn55gAAMCAw7IsK9JDDKb29na5XC498sgjvOUyTHjLZfjxlsvwqquri/QIUYW3XIaXZVm6ceOG/H5/yAcr9uW2v6cBAADcHogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEZsjYaSkhLdf//9iouLU0JCgpYsWaKmpqYBz6uurlZWVpZiY2M1ZcoUlZeX2zkmAAAwYGs0VFdXq7CwULW1taqsrFRXV5dycnLU0dFx03MuXLigvLw8zZkzR/X19dq4caPWrVsnr9dr56gAAGAAw+188IqKipD9Xbt2KSEhQadPn9bcuXP7PKe8vFwTJ05UaWmpJCk9PV11dXXasmWLli5daue4AACgH2G9p8Hv90uSxowZc9M1J0+eVE5OTsixRYsWqa6uTjdu3Oi1PhAIqL29PWQDAACDL2zRYFmWPB6PZs+erenTp990XVtbmxITE0OOJSYmqqurS5cvX+61vqSkRC6XK7ilpKQM+uwAACCM0bBmzRq99957ev311wdc63A4QvYty+rzuCQVFxfL7/cHt5aWlsEZGAAAhLD1noYvrF27VocPH1ZNTY0mTJjQ79rx48erra0t5NilS5c0fPhwjR07ttd6p9Mpp9M5qPMCAIDebL3SYFmW1qxZo4MHD+rtt99WamrqgOe43W5VVlaGHDt27Jiys7M1YsQIu0YFAAADsDUaCgsLtXfvXu3bt09xcXFqa2tTW1ub/vOf/wTXFBcXa8WKFcH9goICXbx4UR6PR2fPntXOnTu1Y8cOFRUV2TkqAAAYgK3RUFZWJr/fr4ceekhJSUnB7cCBA8E1Pp9Pzc3Nwf3U1FQdPXpUVVVVuueee/Sb3/xGW7du5e2WAABEmK33NHxxA2N/du/e3evYgw8+qDNnztgwEQAA+LL43RMAAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADAiK3RUFJSovvvv19xcXFKSEjQkiVL1NTU1O85VVVVcjgcvbZz587ZOSoAABiArdFQXV2twsJC1dbWqrKyUl1dXcrJyVFHR8eA5zY1Ncnn8wW3O++8085RAQDAAIbb+eAVFRUh+7t27VJCQoJOnz6tuXPn9ntuQkKCRo8ebeN0AADgVtgaDf/N7/dLksaMGTPg2nvvvVfXr1/XtGnT9NRTT2nevHl9rgsEAgoEAsH99vZ2SVJlZaUcDscgTI2BpKenR3qEqGNytQ6DJzc3N9IjRJWZM2dGeoSocv36dT355JNGa8N2I6RlWfJ4PJo9e7amT59+03VJSUnavn27vF6vDh48qLS0NC1YsEA1NTV9ri8pKZHL5QpuKSkpdn0LAABENYdlWVY4/qDCwkIdOXJE7777riZMmHBL5+bn58vhcOjw4cO9vtbXlYaUlBSNGjWKKw1h8s1vfjPSI0QdrjSE1+zZsyM9QlThSkN4fXGlwe/3Kz4+vt+1YbnSsHbtWh0+fFjvvPPOLQeD9PlfoPPnz/f5NafTqfj4+JANAAAMPlvvabAsS2vXrtWhQ4dUVVWl1NTUL/U49fX1SkpKGuTpAADArbA1GgoLC7Vv3z69+eabiouLU1tbmyTJ5XJp5MiRkqTi4mK1trZqz549kqTS0lJNnjxZGRkZ6uzs1N69e+X1euX1eu0cFQAADMDWaCgrK5MkPfTQQyHHd+3apVWrVkmSfD6fmpubg1/r7OxUUVGRWltbNXLkSGVkZOjIkSPKy8uzc1QAADAA21+eGMju3btD9p944gk98cQTNk0EAAC+LH73BAAAMEI0AAAAI0QDAAAwQjQAAAAjRAMAADBCNAAAACNEAwAAMEI0AAAAI0QDAAAwQjQAAAAjRAMAADBCNAAAACNEAwAAMEI0AAAAI0QDAAAwQjQAAAAjRAMAADBCNAAAACNEAwAAMEI0AAAAI0QDAAAwQjQAAAAjRAMAADBCNAAAACNEAwAAMEI0AAAAI0QDAAAwQjQAAAAjRAMAADBCNAAAACNEAwAAMEI0AAAAI0QDAAAwQjQAAAAjRAMAADBiazSUlZUpMzNT8fHxio+Pl9vt1ltvvdXvOdXV1crKylJsbKymTJmi8vJyO0cEAACGbI2GCRMm6LnnnlNdXZ3q6uo0f/58LV68WO+//36f6y9cuKC8vDzNmTNH9fX12rhxo9atWyev12vnmAAAwMBwOx88Pz8/ZH/z5s0qKytTbW2tMjIyeq0vLy/XxIkTVVpaKklKT09XXV2dtmzZoqVLl9o5KgAAGEDY7mno7u7W/v371dHRIbfb3eeakydPKicnJ+TYokWLVFdXpxs3bvR5TiAQUHt7e8gGAAAGn+3R0NjYqFGjRsnpdKqgoECHDh3StGnT+lzb1tamxMTEkGOJiYnq6urS5cuX+zynpKRELpcruKWkpAz69wAAAMIQDWlpaWpoaFBtba1+9rOfaeXKlfr73/9+0/UOhyNk37KsPo9/obi4WH6/P7i1tLQM3vAAACDI1nsaJCkmJkZTp06VJGVnZ+vUqVN64YUX9PLLL/daO378eLW1tYUcu3TpkoYPH66xY8f2+fhOp1NOp3PwBwcAACHC/jkNlmUpEAj0+TW3263KysqQY8eOHVN2drZGjBgRjvEAAMBN2BoNGzdu1PHjx/XRRx+psbFRmzZtUlVVlR599FFJn7+0sGLFiuD6goICXbx4UR6PR2fPntXOnTu1Y8cOFRUV2TkmAAAwYOvLEx9//LGWL18un88nl8ulzMxMVVRUaOHChZIkn8+n5ubm4PrU1FQdPXpUGzZs0EsvvaTk5GRt3bqVt1sCAHAbsDUaduzY0e/Xd+/e3evYgw8+qDNnztg0EQAA+LL43RMAAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACM2BoNZWVlyszMVHx8vOLj4+V2u/XWW2/ddH1VVZUcDkev7dy5c3aOCQAADAy388EnTJig5557TlOnTpUk/fGPf9TixYtVX1+vjIyMm57X1NSk+Pj44P4dd9xh55gAAMCArdGQn58fsr9582aVlZWptra232hISEjQ6NGjjf6MQCCgQCAQ3Pf7/ZIky7JufWB8Kd3d3ZEeIer09PREeoSocuPGjUiPEFWuX78e6RGiyhfPt9HPTStMurq6rNdff92KiYmx3n///T7XvPPOO5Yka/Lkydb48eOt+fPnW2+//Xa/j/v0009bktjY2NjY2Nj+h62lpWXAn+UOy7L3n+SNjY1yu926fv26Ro0apX379ikvL6/PtU1NTaqpqVFWVpYCgYBeffVVlZeXq6qqSnPnzu3znP++0tDT06NPP/1UY8eOlcPhsOV7skt7e7tSUlLU0tIS8vIM7MHzHV483+HHcx5eX9Xn27IsXb16VcnJyfra1/q/1dH2aOjs7FRzc7M+++wzeb1evfLKK6qurta0adOMzs/Pz5fD4dDhw4ftHPO20N7eLpfLJb/f/5X6C/dVxfMdXjzf4cdzHl7R8Hzb/pbLmJgYTZ06VdnZ2SopKdGMGTP0wgsvGJ8/c+ZMnT9/3sYJAQCAibB/ToNlWSEvJwykvr5eSUlJNk4EAABM2PruiY0bNyo3N1cpKSm6evWq9u/fr6qqKlVUVEiSiouL1draqj179kiSSktLNXnyZGVkZKizs1N79+6V1+uV1+u1c8zbhtPp1NNPPy2n0xnpUaICz3d48XyHH895eEXD823rPQ2rV6/WX/7yF/l8PrlcLmVmZurJJ5/UwoULJUmrVq3SRx99pKqqKknS7373O23fvl2tra0aOXKkMjIyVFxcfNMbJwEAQPjYfiMkAAAYGvjdEwAAwAjRAAAAjBANAADACNEAAACMEA23iW3btik1NVWxsbHKysrS8ePHIz3SkFVTU6P8/HwlJyfL4XDojTfeiPRIQ1pJSYnuv/9+xcXFKSEhQUuWLFFTU1OkxxqyysrKlJmZqfj4eMXHx8vtduutt96K9FhRpaSkRA6HQ+vXr4/0KIOOaLgNHDhwQOvXr9emTZtUX1+vOXPmKDc3V83NzZEebUjq6OjQjBkz9OKLL0Z6lKhQXV2twsJC1dbWqrKyUl1dXcrJyVFHR0ekRxuSJkyYoOeee051dXWqq6vT/PnztXjxYr3//vuRHi0qnDp1Stu3b1dmZmakR7EFb7m8DTzwwAO67777VFZWFjyWnp6uJUuWqKSkJIKTDX0Oh0OHDh3SkiVLIj1K1Pjkk0+UkJCg6urqm/4iOgyuMWPG6Pe//71Wr14d6VGGtGvXrum+++7Ttm3b9Nvf/lb33HOPSktLIz3WoOJKQ4R1dnbq9OnTysnJCTmek5OjEydORGgqwD5+v1/S5z/IYK/u7m7t379fHR0dcrvdkR5nyCssLNR3v/tdfec734n0KLax9WOkMbDLly+ru7tbiYmJIccTExPV1tYWoakAe1iWJY/Ho9mzZ2v69OmRHmfIamxslNvt1vXr1zVq1CgdOnTI+DcL48vZv3+/zpw5o1OnTkV6FFsRDbcJh8MRsm9ZVq9jwFfdmjVr9N577+ndd9+N9ChDWlpamhoaGvTZZ5/J6/Vq5cqVqq6uJhxs0tLSop///Oc6duyYYmNjIz2OrYiGCBs3bpyGDRvW66rCpUuXel19AL7K1q5dq8OHD6umpkYTJkyI9DhDWkxMjKZOnSpJys7O1qlTp/TCCy/o5ZdfjvBkQ9Pp06d16dIlZWVlBY91d3erpqZGL774ogKBgIYNGxbBCQcP9zREWExMjLKyslRZWRlyvLKyUrNmzYrQVMDgsSxLa9as0cGDB/X2228rNTU10iNFHcuyFAgEIj3GkLVgwQI1NjaqoaEhuGVnZ+vRRx9VQ0PDkAkGiSsNtwWPx6Ply5crOztbbrdb27dvV3NzswoKCiI92pB07do1ffDBB8H9CxcuqKGhQWPGjNHEiRMjONnQVFhYqH379unNN99UXFxc8Kqay+XSyJEjIzzd0LNx40bl5uYqJSVFV69e1f79+1VVVaWKiopIjzZkxcXF9bpH5xvf+IbGjh075O7dIRpuA8uWLdOVK1f07LPPyufzafr06Tp69KgmTZoU6dGGpLq6Os2bNy+47/F4JEkrV67U7t27IzTV0PXFW4kfeuihkOO7du3SqlWrwj/QEPfxxx9r+fLl8vl8crlcyszMVEVFhRYuXBjp0TAE8DkNAADACPc0AAAAI0QDAAAwQjQAAAAjRAMAADBCNAAAACNEAwAAMEI0AAAAI0QDAAAwQjQAAAAjRAMAADBCNAAAACP/B8lpQzuElxPWAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new = xy0_20.drop(columns=[\"label\"])\n",
    "\n",
    "original_image = new.iloc[0].values.reshape(4, 5)\n",
    "plt.imshow(original_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23976608187134502\n",
      "F1 Score: 0.19900257318936587\n",
      "Precision: 0.4054842109770383\n",
      "Recall/Sensitivity/True Positive Rate: 0.23976608187134502\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "classifiers = [GaussianNB() for i in range(10)]\n",
    "ovr = OneVsRestClassifier(GaussianNB())\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(reduced_x_train, ytrainall, test_size=0.3,random_state=seed_value)\n",
    "\n",
    "ovr.fit(X_train, Y_train)\n",
    "predicted = ovr.predict(X_test)\n",
    "predicted_probs = ovr.predict_proba(X_test)\n",
    "\n",
    "# cross_val_scores = cross_val_score(gnb, X_train, Y_train, cv=5)  \n",
    "# print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "# print(\"Mean CV Score:\", cross_val_scores.mean())\n",
    "\n",
    "\n",
    "# train_sizes, train_scores, test_scores = learning_curve(gnb, X_train, Y_train, cv=5)\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Learning Curves\")\n",
    "# plt.xlabel(\"Training examples\")\n",
    "# plt.ylabel(\"Score\")\n",
    "# plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "# plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()\n",
    "\n",
    "accuracy = accuracy_score(Y_test,predicted )\n",
    "f1 = f1_score(predicted, Y_test, average=\"weighted\")\n",
    "conf_matrix = confusion_matrix(predicted, Y_test)\n",
    "precision = precision_score(Y_test, predicted, average=\"weighted\",zero_division=1)\n",
    "recall = recall_score(Y_test, predicted, average=\"weighted\")\n",
    "# roc = roc_auc_score(Y_test, predicted_probs, multi_class=\"ovr\", average=\"weighted\")\n",
    "# conf_matrices = multilabel_confusion_matrix(Y_test, predicted)\n",
    "# tp = conf_matrices[:,1,1]\n",
    "# fp = conf_matrices[:,0,1]\n",
    "# tn = conf_matrices[:,0,0]\n",
    "# fn = conf_matrices[:,1,0]\n",
    "# fpr = _nanaverage(fp/(tn + fp), tp + fn)\n",
    "# tnr = _nanaverage(tn/(tn + fp), tp + fn)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall/Sensitivity/True Positive Rate:\", recall)\n",
    "# print(\"Specificity:\", tnr)\n",
    "# print(\"False Positive Rate:\", fpr)\n",
    "# print(\"Area under ROC curve:\", roc)\n",
    "# print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anshu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23598211214310286\n",
      "F1 Score: 0.2134281917582327\n",
      "Precision: 0.4017743659066427\n",
      "Recall/Sensitivity/True Positive Rate: 0.23598211214310286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "classifiers = [GaussianNB() for i in range(5)]\n",
    "ovr = OneVsOneClassifier(GaussianNB(), n_jobs=45)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(reduced_x_train, ytrainall, test_size=0.3,random_state=seed_value)\n",
    "\n",
    "ovr.fit(X_train, Y_train)\n",
    "predicted = ovr.predict(X_test)\n",
    "# predicted_probs = ovr.predict_proba(X_test)\n",
    "\n",
    "# cross_val_scores = cross_val_score(gnb, X_train, Y_train, cv=5)  \n",
    "# print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "# print(\"Mean CV Score:\", cross_val_scores.mean())\n",
    "\n",
    "\n",
    "# train_sizes, train_scores, test_scores = learning_curve(gnb, X_train, Y_train, cv=5)\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Learning Curves\")\n",
    "# plt.xlabel(\"Training examples\")\n",
    "# plt.ylabel(\"Score\")\n",
    "# plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "# plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()\n",
    "\n",
    "accuracy = accuracy_score(Y_test,predicted )\n",
    "f1 = f1_score(predicted, Y_test, average=\"weighted\")\n",
    "conf_matrix = confusion_matrix(predicted, Y_test)\n",
    "precision = precision_score(Y_test, predicted, average=\"weighted\",zero_division=1)\n",
    "recall = recall_score(Y_test, predicted, average=\"weighted\")\n",
    "# roc = roc_auc_score(Y_test, predicted_probs, multi_class=\"ovr\", average=\"weighted\")\n",
    "# conf_matrices = multilabel_confusion_matrix(Y_test, predicted)\n",
    "# tp = conf_matrices[:,1,1]\n",
    "# fp = conf_matrices[:,0,1]\n",
    "# tn = conf_matrices[:,0,0]\n",
    "# fn = conf_matrices[:,1,0]\n",
    "# fpr = _nanaverage(fp/(tn + fp), tp + fn)\n",
    "# tnr = _nanaverage(tn/(tn + fp), tp + fn)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall/Sensitivity/True Positive Rate:\", recall)\n",
    "# print(\"Specificity:\", tnr)\n",
    "# print(\"False Positive Rate:\", fpr)\n",
    "# print(\"Area under ROC curve:\", roc)\n",
    "# print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1605    490   1536    927    742  label\n",
      "0     219.0   83.0  184.0  105.0  103.0      0\n",
      "1     185.0   97.0  187.0   80.0  123.0      0\n",
      "2     204.0  129.0  182.0  110.0  196.0      0\n",
      "3     185.0  148.0  184.0  135.0  235.0      0\n",
      "4     175.0   80.0  107.0   81.0   78.0      0\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685   54.0  255.0  222.0  161.0   96.0      1\n",
      "9686   55.0  255.0   92.0  104.0  104.0      1\n",
      "9687   53.0  254.0  109.0   75.0  101.0      1\n",
      "9688   53.0  255.0  113.0   86.0   94.0      1\n",
      "9689   41.0  248.0  255.0   70.0   91.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  0\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "       1432     52   1733    637   1262  label\n",
      "0      89.0   89.0   94.0  115.0  176.0      1\n",
      "1      91.0   79.0  111.0  110.0  100.0      1\n",
      "2      87.0   88.0  120.0  119.0  153.0      1\n",
      "3      82.0   98.0  105.0  129.0  142.0      1\n",
      "4     116.0   84.0  179.0  131.0  158.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685   42.0  199.0   43.0  255.0   20.0      1\n",
      "9686   52.0  205.0   47.0  206.0   19.0      1\n",
      "9687   37.0  255.0   38.0  255.0   17.0      1\n",
      "9688   38.0  255.0   55.0   76.0   16.0      1\n",
      "9689   25.0  255.0   82.0  254.0   15.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  1\n",
      "Accuracy: 0.7206742346061231\n",
      "F1 Score: 0.7282272614049545\n",
      "Precision: 0.7071068742350334\n",
      "Recall/Sensitivity/True Positive Rate: 0.7206742346061231\n",
      "Confusion Matrix:\n",
      " [[ 232  358]\n",
      " [ 454 1863]]\n",
      "\n",
      "\n",
      "       1997    166   335   1765   1780  label\n",
      "0     126.0  215.0  85.0   81.0   74.0      1\n",
      "1     119.0  183.0  76.0   81.0  149.0      1\n",
      "2     116.0  221.0  70.0   82.0  134.0      1\n",
      "3     119.0  225.0  64.0   94.0  142.0      1\n",
      "4     126.0  214.0  91.0  121.0  177.0      1\n",
      "...     ...    ...   ...    ...    ...    ...\n",
      "9685   17.0  250.0  68.0   22.0   62.0      1\n",
      "9686   16.0   26.0  17.0   21.0   48.0      1\n",
      "9687   17.0  246.0  68.0   27.0   37.0      1\n",
      "9688   16.0  220.0  74.0   25.0   45.0      1\n",
      "9689   14.0   61.0  42.0   23.0   94.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  2\n",
      "Accuracy: 0.760921912624699\n",
      "F1 Score: 0.8204924612426809\n",
      "Precision: 0.696758798358478\n",
      "Recall/Sensitivity/True Positive Rate: 0.760921912624699\n",
      "Confusion Matrix:\n",
      " [[  68   99]\n",
      " [ 596 2144]]\n",
      "\n",
      "\n",
      "      1772    481   670   1212   2245  label\n",
      "0     80.0  112.0  72.0   74.0   91.0      1\n",
      "1     87.0  112.0  72.0  120.0  100.0      1\n",
      "2     85.0  125.0  71.0   81.0  103.0      1\n",
      "3     83.0  127.0  65.0   79.0  126.0      1\n",
      "4     77.0  109.0  65.0   79.0   97.0      1\n",
      "...    ...    ...   ...    ...    ...    ...\n",
      "9685  36.0  255.0  38.0  102.0   52.0      1\n",
      "9686  37.0  255.0  27.0   93.0   56.0      1\n",
      "9687  29.0  255.0  30.0   88.0   42.0      1\n",
      "9688  24.0  255.0  20.0  142.0   39.0      1\n",
      "9689  34.0  226.0  28.0   72.0   33.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  3\n",
      "Accuracy: 0.8582731338149295\n",
      "F1 Score: 0.8878519519945112\n",
      "Precision: 0.8259810945105907\n",
      "Recall/Sensitivity/True Positive Rate: 0.8582731338149295\n",
      "Confusion Matrix:\n",
      " [[  80   72]\n",
      " [ 340 2415]]\n",
      "\n",
      "\n",
      "      1676   2039   2051    581   2272  label\n",
      "0     83.0  135.0  108.0  143.0   95.0      1\n",
      "1     91.0  137.0  113.0  170.0   84.0      1\n",
      "2     88.0  123.0  112.0  164.0   82.0      1\n",
      "3     84.0  147.0   98.0  164.0   78.0      1\n",
      "4     76.0  114.0  126.0  116.0  125.0      1\n",
      "...    ...    ...    ...    ...    ...    ...\n",
      "9685  39.0   33.0   62.0  255.0  104.0      1\n",
      "9686  39.0   18.0   23.0  255.0  102.0      1\n",
      "9687  36.0   27.0   65.0  253.0  101.0      1\n",
      "9688  23.0   25.0   51.0  255.0   96.0      1\n",
      "9689  45.0   31.0   60.0  254.0   90.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  4\n",
      "Accuracy: 0.6130030959752322\n",
      "F1 Score: 0.5745084899556268\n",
      "Precision: 0.7621563059023773\n",
      "Recall/Sensitivity/True Positive Rate: 0.6130030959752322\n",
      "Confusion Matrix:\n",
      " [[ 392  934]\n",
      " [ 191 1390]]\n",
      "\n",
      "\n",
      "        464     74   1739   1361   1756  label\n",
      "0      89.0  208.0   91.0  198.0  149.0      1\n",
      "1     106.0  176.0  124.0  204.0  111.0      1\n",
      "2     123.0  162.0  114.0  197.0  122.0      1\n",
      "3     113.0  164.0  132.0  173.0   96.0      1\n",
      "4      82.0  144.0  154.0  226.0  200.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685  158.0   23.0   21.0  115.0   71.0      1\n",
      "9686  203.0  255.0   29.0  111.0   80.0      1\n",
      "9687   17.0  255.0   53.0  107.0   54.0      1\n",
      "9688  119.0  103.0   23.0   99.0   42.0      1\n",
      "9689  172.0   48.0   40.0   95.0   39.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  5\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "       2216   1948   1778    966    935  label\n",
      "0      75.0  132.0  125.0  135.0  228.0      1\n",
      "1      76.0  119.0  166.0   92.0  197.0      1\n",
      "2      82.0  115.0  141.0   94.0  204.0      1\n",
      "3      77.0  110.0  155.0   80.0  179.0      1\n",
      "4     106.0  107.0  180.0  161.0  236.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685   40.0   18.0   78.0  191.0  112.0      1\n",
      "9686   29.0   17.0   76.0  227.0  107.0      1\n",
      "9687   31.0   16.0   58.0  154.0  102.0      1\n",
      "9688   33.0   15.0   40.0  255.0   98.0      1\n",
      "9689   32.0   13.0  143.0   17.0   93.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  6\n",
      "Accuracy: 0.9642242862057103\n",
      "F1 Score: 0.9817863397548159\n",
      "Precision: 0.9655041879032012\n",
      "Recall/Sensitivity/True Positive Rate: 0.9642242862057103\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [ 104 2803]]\n",
      "\n",
      "\n",
      "       1382   1564   2290    314   2163  label\n",
      "0     107.0  230.0  105.0  188.0   92.0      1\n",
      "1      95.0  235.0  142.0  177.0  103.0      1\n",
      "2     104.0  235.0  144.0   98.0  112.0      1\n",
      "3     104.0  233.0  114.0   77.0  106.0      1\n",
      "4      73.0  164.0  108.0  196.0  143.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685   41.0   68.0  101.0  205.0   45.0      1\n",
      "9686   40.0   61.0   98.0  191.0   36.0      1\n",
      "9687   41.0   72.0   96.0   53.0   36.0      1\n",
      "9688   35.0   76.0   90.0  253.0   38.0      1\n",
      "9689   33.0   65.0   86.0  254.0   31.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  7\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "        425    237   2084    129   1491  label\n",
      "0      98.0   72.0   97.0  166.0  181.0      1\n",
      "1     107.0   75.0  117.0  229.0  182.0      1\n",
      "2      96.0   74.0  124.0  230.0  176.0      1\n",
      "3      76.0   81.0  122.0  215.0  174.0      1\n",
      "4      70.0   91.0  103.0  226.0  114.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685  130.0  133.0  101.0   31.0   68.0      1\n",
      "9686   69.0  225.0   64.0   30.0   79.0      1\n",
      "9687   90.0  124.0   97.0  244.0   71.0      1\n",
      "9688   27.0   25.0   96.0  255.0  116.0      1\n",
      "9689   56.0   36.0   89.0  108.0  255.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  8\n",
      "Accuracy: 0.9215686274509803\n",
      "F1 Score: 0.9411570087091911\n",
      "Precision: 0.8844252888808979\n",
      "Recall/Sensitivity/True Positive Rate: 0.9215686274509803\n",
      "Confusion Matrix:\n",
      " [[   3   53]\n",
      " [ 175 2676]]\n",
      "\n",
      "\n",
      "       1109    346     42    646    798  label\n",
      "0     124.0  170.0   78.0   90.0   95.0      1\n",
      "1      90.0  127.0   96.0   80.0  139.0      1\n",
      "2      79.0  131.0   95.0   83.0  149.0      1\n",
      "3      99.0   84.0   95.0  124.0  172.0      1\n",
      "4     108.0  201.0   87.0  101.0   90.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685  241.0  255.0   40.0   26.0   57.0      0\n",
      "9686  169.0  254.0  104.0   62.0   80.0      0\n",
      "9687  224.0   40.0  246.0   65.0   99.0      0\n",
      "9688  255.0  254.0  189.0   71.0   61.0      0\n",
      "9689  150.0  139.0   61.0   59.0   52.0      0\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  9\n",
      "Accuracy: 0.9594083247334021\n",
      "F1 Score: 0.9638186016874735\n",
      "Precision: 0.9508087030375234\n",
      "Recall/Sensitivity/True Positive Rate: 0.9594083247334021\n",
      "Confusion Matrix:\n",
      " [[   4   45]\n",
      " [  73 2785]]\n",
      "\n",
      "\n",
      "       1605    490   1536    927    742  1966   2066   2235    239  1869  \\\n",
      "0     219.0   83.0  184.0  105.0  103.0  82.0  126.0   98.0   77.0  79.0   \n",
      "1     185.0   97.0  187.0   80.0  123.0  80.0  136.0  125.0   71.0  79.0   \n",
      "2     204.0  129.0  182.0  110.0  196.0  76.0  124.0  109.0   68.0  79.0   \n",
      "3     185.0  148.0  184.0  135.0  235.0  77.0  128.0  111.0   64.0  80.0   \n",
      "4     175.0   80.0  107.0   81.0   78.0  77.0  153.0  119.0   83.0  75.0   \n",
      "...     ...    ...    ...    ...    ...   ...    ...    ...    ...   ...   \n",
      "9685   54.0  255.0  222.0  161.0   96.0  29.0   60.0   92.0   36.0  30.0   \n",
      "9686   55.0  255.0   92.0  104.0  104.0  29.0   38.0  100.0  122.0  36.0   \n",
      "9687   53.0  254.0  109.0   75.0  101.0  31.0   41.0   93.0   60.0  32.0   \n",
      "9688   53.0  255.0  113.0   86.0   94.0  23.0   38.0   91.0   33.0  27.0   \n",
      "9689   41.0  248.0  255.0   70.0   91.0  36.0   34.0   82.0  214.0  28.0   \n",
      "\n",
      "      label  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  0\n",
      "Accuracy: 0.8885448916408669\n",
      "F1 Score: 0.8546058025000232\n",
      "Precision: 0.9648222903099499\n",
      "Recall/Sensitivity/True Positive Rate: 0.8885448916408669\n",
      "Confusion Matrix:\n",
      " [[  26  285]\n",
      " [  39 2557]]\n",
      "\n",
      "\n",
      "       1432     52   1733    637   1262    829  1388    280    635   1423  \\\n",
      "0      89.0   89.0   94.0  115.0  176.0  100.0  89.0  111.0  115.0  178.0   \n",
      "1      91.0   79.0  111.0  110.0  100.0  117.0  85.0   78.0  119.0  147.0   \n",
      "2      87.0   88.0  120.0  119.0  153.0   97.0  83.0   70.0  115.0  152.0   \n",
      "3      82.0   98.0  105.0  129.0  142.0   81.0  78.0   71.0  122.0  197.0   \n",
      "4     116.0   84.0  179.0  131.0  158.0  128.0  76.0   68.0  127.0  157.0   \n",
      "...     ...    ...    ...    ...    ...    ...   ...    ...    ...    ...   \n",
      "9685   42.0  199.0   43.0  255.0   20.0  208.0  38.0  232.0  201.0  102.0   \n",
      "9686   52.0  205.0   47.0  206.0   19.0  217.0  37.0   19.0  170.0   95.0   \n",
      "9687   37.0  255.0   38.0  255.0   17.0  251.0  31.0  105.0  255.0   87.0   \n",
      "9688   38.0  255.0   55.0   76.0   16.0   99.0  26.0   96.0  221.0   80.0   \n",
      "9689   25.0  255.0   82.0  254.0   15.0  102.0  85.0  169.0  255.0   80.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  1\n",
      "Accuracy: 0.6917784657722739\n",
      "F1 Score: 0.6820846329363506\n",
      "Precision: 0.7144587872674384\n",
      "Recall/Sensitivity/True Positive Rate: 0.6917784657722739\n",
      "Confusion Matrix:\n",
      " [[ 312  522]\n",
      " [ 374 1699]]\n",
      "\n",
      "\n",
      "       1997    166   335   1765   1780    845    281    638   1561    148  \\\n",
      "0     126.0  215.0  85.0   81.0   74.0  141.0  103.0  120.0  225.0   96.0   \n",
      "1     119.0  183.0  76.0   81.0  149.0  191.0   89.0  110.0  231.0   83.0   \n",
      "2     116.0  221.0  70.0   82.0  134.0  169.0   81.0  127.0  234.0  108.0   \n",
      "3     119.0  225.0  64.0   94.0  142.0  139.0   77.0  132.0  237.0  109.0   \n",
      "4     126.0  214.0  91.0  121.0  177.0  148.0   73.0  132.0  152.0  107.0   \n",
      "...     ...    ...   ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685   17.0  250.0  68.0   22.0   62.0   39.0  255.0  253.0   50.0  255.0   \n",
      "9686   16.0   26.0  17.0   21.0   48.0   24.0   21.0  153.0   41.0  255.0   \n",
      "9687   17.0  246.0  68.0   27.0   37.0   23.0  189.0  255.0   48.0  255.0   \n",
      "9688   16.0  220.0  74.0   25.0   45.0   18.0   80.0   31.0   36.0  255.0   \n",
      "9689   14.0   61.0  42.0   23.0   94.0   19.0  189.0  217.0   36.0   19.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  2\n",
      "Accuracy: 0.7351221190230478\n",
      "F1 Score: 0.7448278768406621\n",
      "Precision: 0.7182343362243369\n",
      "Recall/Sensitivity/True Positive Rate: 0.7351221190230478\n",
      "Confusion Matrix:\n",
      " [[ 219  325]\n",
      " [ 445 1918]]\n",
      "\n",
      "\n",
      "      1772    481   670   1212   2245   1465   2023   2246  1389    274  label\n",
      "0     80.0  112.0  72.0   74.0   91.0  172.0  132.0   83.0  91.0  204.0      1\n",
      "1     87.0  112.0  72.0  120.0  100.0  168.0  100.0   95.0  84.0  166.0      1\n",
      "2     85.0  125.0  71.0   81.0  103.0  171.0   93.0   97.0  83.0   88.0      1\n",
      "3     83.0  127.0  65.0   79.0  126.0  190.0   90.0  109.0  78.0   64.0      1\n",
      "4     77.0  109.0  65.0   79.0   97.0  176.0   85.0   96.0  77.0  208.0      1\n",
      "...    ...    ...   ...    ...    ...    ...    ...    ...   ...    ...    ...\n",
      "9685  36.0  255.0  38.0  102.0   52.0   85.0   19.0   37.0  35.0  226.0      1\n",
      "9686  37.0  255.0  27.0   93.0   56.0   69.0   18.0   36.0  34.0  215.0      1\n",
      "9687  29.0  255.0  30.0   88.0   42.0   59.0   18.0   41.0  30.0  133.0      1\n",
      "9688  24.0  255.0  20.0  142.0   39.0   64.0   17.0   39.0  30.0  238.0      1\n",
      "9689  34.0  226.0  28.0   72.0   33.0   52.0   17.0   34.0  67.0  239.0      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  3\n",
      "Accuracy: 0.7925696594427245\n",
      "F1 Score: 0.7808256892588054\n",
      "Precision: 0.8195796333773478\n",
      "Recall/Sensitivity/True Positive Rate: 0.7925696594427245\n",
      "Confusion Matrix:\n",
      " [[ 188  371]\n",
      " [ 232 2116]]\n",
      "\n",
      "\n",
      "      1676   2039   2051    581   2272    491  1677  1674   1921   1148  label\n",
      "0     83.0  135.0  108.0  143.0   95.0   84.0  80.0  89.0  125.0   85.0      1\n",
      "1     91.0  137.0  113.0  170.0   84.0   99.0  90.0  86.0  142.0   93.0      1\n",
      "2     88.0  123.0  112.0  164.0   82.0  133.0  90.0  80.0  146.0  101.0      1\n",
      "3     84.0  147.0   98.0  164.0   78.0  151.0  88.0  76.0  143.0   92.0      1\n",
      "4     76.0  114.0  126.0  116.0  125.0   81.0  79.0  75.0  144.0   76.0      1\n",
      "...    ...    ...    ...    ...    ...    ...   ...   ...    ...    ...    ...\n",
      "9685  39.0   33.0   62.0  255.0  104.0  255.0  40.0  33.0  101.0   32.0      1\n",
      "9686  39.0   18.0   23.0  255.0  102.0  255.0  36.0  47.0   41.0   41.0      1\n",
      "9687  36.0   27.0   65.0  253.0  101.0  168.0  31.0  36.0   54.0   36.0      1\n",
      "9688  23.0   25.0   51.0  255.0   96.0  255.0  28.0  26.0   45.0   94.0      1\n",
      "9689  45.0   31.0   60.0  254.0   90.0  224.0  53.0  43.0   56.0   35.0      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  4\n",
      "Accuracy: 0.5366357069143447\n",
      "F1 Score: 0.49532723738210094\n",
      "Precision: 0.7675844066171659\n",
      "Recall/Sensitivity/True Positive Rate: 0.5366357069143447\n",
      "Confusion Matrix:\n",
      " [[ 449 1213]\n",
      " [ 134 1111]]\n",
      "\n",
      "\n",
      "        464     74   1739   1361   1756    445   1874   1928    774     58  \\\n",
      "0      89.0  208.0   91.0  198.0  149.0  109.0  152.0  144.0  153.0  113.0   \n",
      "1     106.0  176.0  124.0  204.0  111.0   89.0  150.0  100.0  165.0   92.0   \n",
      "2     123.0  162.0  114.0  197.0  122.0  103.0  177.0  105.0  165.0  121.0   \n",
      "3     113.0  164.0  132.0  173.0   96.0  111.0  137.0   70.0  169.0  162.0   \n",
      "4      82.0  144.0  154.0  226.0  200.0   98.0  122.0   83.0  161.0  103.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  158.0   23.0   21.0  115.0   71.0  255.0   67.0   19.0  227.0  255.0   \n",
      "9686  203.0  255.0   29.0  111.0   80.0  255.0   58.0   18.0  228.0  134.0   \n",
      "9687   17.0  255.0   53.0  107.0   54.0   83.0   42.0   18.0  255.0  255.0   \n",
      "9688  119.0  103.0   23.0   99.0   42.0  253.0   47.0   16.0  253.0  236.0   \n",
      "9689  172.0   48.0   40.0   95.0   39.0  198.0   60.0   16.0  124.0   15.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  5\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "       2216   1948   1778    966    935   1063    963   956    830    374  \\\n",
      "0      75.0  132.0  125.0  135.0  228.0  139.0   88.0  78.0   92.0   68.0   \n",
      "1      76.0  119.0  166.0   92.0  197.0  107.0  165.0  83.0  108.0   79.0   \n",
      "2      82.0  115.0  141.0   94.0  204.0  126.0  140.0  79.0   85.0   89.0   \n",
      "3      77.0  110.0  155.0   80.0  179.0   93.0  159.0  76.0   76.0  101.0   \n",
      "4     106.0  107.0  180.0  161.0  236.0   98.0  166.0  76.0  110.0   76.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...   ...    ...    ...   \n",
      "9685   40.0   18.0   78.0  191.0  112.0  150.0  185.0  42.0  172.0  109.0   \n",
      "9686   29.0   17.0   76.0  227.0  107.0  211.0  228.0  40.0  244.0  217.0   \n",
      "9687   31.0   16.0   58.0  154.0  102.0  109.0  221.0  39.0  255.0  240.0   \n",
      "9688   33.0   15.0   40.0  255.0   98.0  255.0  255.0  35.0  148.0  160.0   \n",
      "9689   32.0   13.0  143.0   17.0   93.0  243.0   20.0  17.0  208.0   60.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  6\n",
      "Accuracy: 0.7616099071207431\n",
      "F1 Score: 0.6874428655278926\n",
      "Precision: 0.9456411632248648\n",
      "Recall/Sensitivity/True Positive Rate: 0.7616099071207431\n",
      "Confusion Matrix:\n",
      " [[  55  644]\n",
      " [  49 2159]]\n",
      "\n",
      "\n",
      "       1382   1564   2290    314   2163   1948   1883   1013   1241   1835  \\\n",
      "0     107.0  230.0  105.0  188.0   92.0  132.0  104.0  125.0   91.0   99.0   \n",
      "1      95.0  235.0  142.0  177.0  103.0  119.0  127.0   83.0   95.0  125.0   \n",
      "2     104.0  235.0  144.0   98.0  112.0  115.0  120.0   76.0   88.0  117.0   \n",
      "3     104.0  233.0  114.0   77.0  106.0  110.0  139.0   90.0   80.0  136.0   \n",
      "4      73.0  164.0  108.0  196.0  143.0  107.0  145.0  108.0  106.0  149.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685   41.0   68.0  101.0  205.0   45.0   18.0   46.0  221.0   34.0   87.0   \n",
      "9686   40.0   61.0   98.0  191.0   36.0   17.0   80.0  229.0   39.0   89.0   \n",
      "9687   41.0   72.0   96.0   53.0   36.0   16.0   29.0  225.0   49.0  104.0   \n",
      "9688   35.0   76.0   90.0  253.0   38.0   15.0   32.0  255.0   99.0   89.0   \n",
      "9689   33.0   65.0   86.0  254.0   31.0   13.0   20.0   24.0   33.0   91.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  7\n",
      "Accuracy: 0.9656002751977985\n",
      "F1 Score: 0.9698219226855641\n",
      "Precision: 0.9573114767940992\n",
      "Recall/Sensitivity/True Positive Rate: 0.9656002751977985\n",
      "Confusion Matrix:\n",
      " [[   2   37]\n",
      " [  63 2805]]\n",
      "\n",
      "\n",
      "        425    237   2084    129   1491    461   1322    218   2192    884  \\\n",
      "0      98.0   72.0   97.0  166.0  181.0   89.0  148.0  179.0  155.0  228.0   \n",
      "1     107.0   75.0  117.0  229.0  182.0   96.0  169.0  200.0  119.0  207.0   \n",
      "2      96.0   74.0  124.0  230.0  176.0  132.0  126.0  186.0  115.0  195.0   \n",
      "3      76.0   81.0  122.0  215.0  174.0  128.0  133.0  143.0   99.0  146.0   \n",
      "4      70.0   91.0  103.0  226.0  114.0   76.0  137.0  190.0  116.0  182.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  130.0  133.0  101.0   31.0   68.0  173.0   45.0  255.0  100.0   56.0   \n",
      "9686   69.0  225.0   64.0   30.0   79.0  239.0   36.0   20.0   71.0   91.0   \n",
      "9687   90.0  124.0   97.0  244.0   71.0   64.0   21.0  159.0   94.0   90.0   \n",
      "9688   27.0   25.0   96.0  255.0  116.0  124.0   17.0  255.0   89.0   84.0   \n",
      "9689   56.0   36.0   89.0  108.0  255.0  103.0   16.0  104.0   86.0   82.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  8\n",
      "Accuracy: 0.8964568283453732\n",
      "F1 Score: 0.8921566765829845\n",
      "Precision: 0.9053586927829773\n",
      "Recall/Sensitivity/True Positive Rate: 0.8964568283453732\n",
      "Confusion Matrix:\n",
      " [[  45  168]\n",
      " [ 133 2561]]\n",
      "\n",
      "\n",
      "       1109    346     42    646    798   2256    492   1934   2170   1402  \\\n",
      "0     124.0  170.0   78.0   90.0   95.0   85.0   86.0  111.0   84.0  120.0   \n",
      "1      90.0  127.0   96.0   80.0  139.0   74.0  102.0  108.0   82.0  136.0   \n",
      "2      79.0  131.0   95.0   83.0  149.0   77.0  134.0   99.0   96.0  122.0   \n",
      "3      99.0   84.0   95.0  124.0  172.0   75.0  135.0  102.0   89.0  139.0   \n",
      "4     108.0  201.0   87.0  101.0   90.0  129.0   81.0   98.0  120.0  130.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  241.0  255.0   40.0   26.0   57.0   50.0  255.0   19.0   58.0  100.0   \n",
      "9686  169.0  254.0  104.0   62.0   80.0   43.0  255.0   19.0   53.0   87.0   \n",
      "9687  224.0   40.0  246.0   65.0   99.0   35.0  134.0   18.0   63.0   87.0   \n",
      "9688  255.0  254.0  189.0   71.0   61.0   33.0  214.0   16.0   58.0  130.0   \n",
      "9689  150.0  139.0   61.0   59.0   52.0   37.0  166.0   15.0   65.0   98.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      0  \n",
      "9686      0  \n",
      "9687      0  \n",
      "9688      0  \n",
      "9689      0  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  9\n",
      "Accuracy: 0.9484004127966976\n",
      "F1 Score: 0.9460453359604873\n",
      "Precision: 0.9531814989719715\n",
      "Recall/Sensitivity/True Positive Rate: 0.9484004127966976\n",
      "Confusion Matrix:\n",
      " [[  10   83]\n",
      " [  67 2747]]\n",
      "\n",
      "\n",
      "       1605    490   1536    927    742  1966   2066   2235    239  1869  ...  \\\n",
      "0     219.0   83.0  184.0  105.0  103.0  82.0  126.0   98.0   77.0  79.0  ...   \n",
      "1     185.0   97.0  187.0   80.0  123.0  80.0  136.0  125.0   71.0  79.0  ...   \n",
      "2     204.0  129.0  182.0  110.0  196.0  76.0  124.0  109.0   68.0  79.0  ...   \n",
      "3     185.0  148.0  184.0  135.0  235.0  77.0  128.0  111.0   64.0  80.0  ...   \n",
      "4     175.0   80.0  107.0   81.0   78.0  77.0  153.0  119.0   83.0  75.0  ...   \n",
      "...     ...    ...    ...    ...    ...   ...    ...    ...    ...   ...  ...   \n",
      "9685   54.0  255.0  222.0  161.0   96.0  29.0   60.0   92.0   36.0  30.0  ...   \n",
      "9686   55.0  255.0   92.0  104.0  104.0  29.0   38.0  100.0  122.0  36.0  ...   \n",
      "9687   53.0  254.0  109.0   75.0  101.0  31.0   41.0   93.0   60.0  32.0  ...   \n",
      "9688   53.0  255.0  113.0   86.0   94.0  23.0   38.0   91.0   33.0  27.0  ...   \n",
      "9689   41.0  248.0  255.0   70.0   91.0  36.0   34.0   82.0  214.0  28.0  ...   \n",
      "\n",
      "       1264   2090  1815   1766    661   2122    409   1497    628  label  \n",
      "0     234.0  119.0  87.0   81.0   85.0  102.0   95.0  132.0  166.0      0  \n",
      "1     194.0  137.0  75.0   77.0   88.0  111.0   83.0  167.0  182.0      0  \n",
      "2     227.0  128.0  72.0   75.0   87.0  131.0  102.0  167.0  173.0      0  \n",
      "3     225.0  123.0  72.0   82.0   85.0  118.0  135.0  165.0  175.0      0  \n",
      "4     224.0  116.0  85.0  105.0   75.0  118.0   79.0  126.0  127.0      0  \n",
      "...     ...    ...   ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "9685   38.0   97.0  18.0   17.0   57.0   53.0  104.0   76.0  255.0      1  \n",
      "9686   60.0   81.0  17.0   17.0  119.0   77.0   98.0  109.0  255.0      1  \n",
      "9687   80.0   92.0  16.0   17.0   83.0   52.0   63.0   87.0  255.0      1  \n",
      "9688   58.0   89.0  15.0   15.0   22.0   47.0   83.0  118.0  192.0      1  \n",
      "9689   66.0   83.0  14.0   13.0   29.0   45.0  134.0  144.0  255.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  0\n",
      "Accuracy: 0.8796009631922944\n",
      "F1 Score: 0.840835167070912\n",
      "Precision: 0.9713255757983613\n",
      "Recall/Sensitivity/True Positive Rate: 0.8796009631922944\n",
      "Confusion Matrix:\n",
      " [[  42  327]\n",
      " [  23 2515]]\n",
      "\n",
      "\n",
      "       1432     52   1733    637   1262    829  1388    280    635   1423  \\\n",
      "0      89.0   89.0   94.0  115.0  176.0  100.0  89.0  111.0  115.0  178.0   \n",
      "1      91.0   79.0  111.0  110.0  100.0  117.0  85.0   78.0  119.0  147.0   \n",
      "2      87.0   88.0  120.0  119.0  153.0   97.0  83.0   70.0  115.0  152.0   \n",
      "3      82.0   98.0  105.0  129.0  142.0   81.0  78.0   71.0  122.0  197.0   \n",
      "4     116.0   84.0  179.0  131.0  158.0  128.0  76.0   68.0  127.0  157.0   \n",
      "...     ...    ...    ...    ...    ...    ...   ...    ...    ...    ...   \n",
      "9685   42.0  199.0   43.0  255.0   20.0  208.0  38.0  232.0  201.0  102.0   \n",
      "9686   52.0  205.0   47.0  206.0   19.0  217.0  37.0   19.0  170.0   95.0   \n",
      "9687   37.0  255.0   38.0  255.0   17.0  251.0  31.0  105.0  255.0   87.0   \n",
      "9688   38.0  255.0   55.0   76.0   16.0   99.0  26.0   96.0  221.0   80.0   \n",
      "9689   25.0  255.0   82.0  254.0   15.0  102.0  85.0  169.0  255.0   80.0   \n",
      "\n",
      "      ...   2221  1773  1868    739    828   2022   1876   1609   1377  label  \n",
      "0     ...   88.0  77.0  80.0   83.0  109.0  117.0   83.0  234.0  151.0      1  \n",
      "1     ...   93.0  83.0  83.0   80.0  112.0  111.0  131.0  236.0  158.0      1  \n",
      "2     ...   88.0  81.0  85.0  115.0  112.0  104.0  118.0  234.0  153.0      1  \n",
      "3     ...   73.0  84.0  84.0  154.0  100.0   95.0  178.0  221.0  180.0      1  \n",
      "4     ...  139.0  77.0  72.0   77.0  131.0  114.0  121.0  209.0  132.0      1  \n",
      "...   ...    ...   ...   ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "9685  ...  104.0  35.0  37.0   19.0  226.0   30.0   57.0   37.0   19.0      1  \n",
      "9686  ...   99.0  40.0  39.0   18.0  165.0   21.0   57.0   46.0   20.0      1  \n",
      "9687  ...  101.0  33.0  30.0   17.0  212.0   20.0   32.0   38.0   21.0      1  \n",
      "9688  ...   95.0  37.0  34.0   16.0  226.0   22.0   37.0   26.0   20.0      1  \n",
      "9689  ...   91.0  23.0  39.0   15.0   81.0   21.0   59.0   40.0   17.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  1\n",
      "Accuracy: 0.6824905400756794\n",
      "F1 Score: 0.6659160189027782\n",
      "Precision: 0.7279689983916663\n",
      "Recall/Sensitivity/True Positive Rate: 0.6824905400756794\n",
      "Confusion Matrix:\n",
      " [[ 369  606]\n",
      " [ 317 1615]]\n",
      "\n",
      "\n",
      "       1997    166   335   1765   1780    845    281    638   1561    148  \\\n",
      "0     126.0  215.0  85.0   81.0   74.0  141.0  103.0  120.0  225.0   96.0   \n",
      "1     119.0  183.0  76.0   81.0  149.0  191.0   89.0  110.0  231.0   83.0   \n",
      "2     116.0  221.0  70.0   82.0  134.0  169.0   81.0  127.0  234.0  108.0   \n",
      "3     119.0  225.0  64.0   94.0  142.0  139.0   77.0  132.0  237.0  109.0   \n",
      "4     126.0  214.0  91.0  121.0  177.0  148.0   73.0  132.0  152.0  107.0   \n",
      "...     ...    ...   ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685   17.0  250.0  68.0   22.0   62.0   39.0  255.0  253.0   50.0  255.0   \n",
      "9686   16.0   26.0  17.0   21.0   48.0   24.0   21.0  153.0   41.0  255.0   \n",
      "9687   17.0  246.0  68.0   27.0   37.0   23.0  189.0  255.0   48.0  255.0   \n",
      "9688   16.0  220.0  74.0   25.0   45.0   18.0   80.0   31.0   36.0  255.0   \n",
      "9689   14.0   61.0  42.0   23.0   94.0   19.0  189.0  217.0   36.0   19.0   \n",
      "\n",
      "      ...    487    537   2293   1699   1023    136   284   1185    391  label  \n",
      "0     ...   80.0  109.0   94.0  101.0  153.0   98.0  71.0  168.0   81.0      1  \n",
      "1     ...  120.0  144.0   99.0   85.0   97.0   92.0  91.0  162.0   81.0      1  \n",
      "2     ...  118.0  143.0  103.0   95.0  156.0   89.0  90.0  175.0   73.0      1  \n",
      "3     ...  145.0  143.0  133.0   97.0  176.0   90.0  84.0  191.0   72.0      1  \n",
      "4     ...   75.0   81.0  103.0  164.0  110.0   84.0  97.0  144.0   92.0      1  \n",
      "...   ...    ...    ...    ...    ...    ...    ...   ...    ...    ...    ...  \n",
      "9685  ...  255.0  255.0   52.0  112.0   61.0  102.0  67.0   40.0  255.0      1  \n",
      "9686  ...  255.0  255.0   55.0  110.0   23.0   88.0  41.0   31.0  255.0      1  \n",
      "9687  ...  255.0  255.0   41.0  106.0   21.0  151.0  65.0   21.0   28.0      1  \n",
      "9688  ...  255.0  255.0   37.0   98.0   21.0  251.0  34.0   17.0  255.0      1  \n",
      "9689  ...  255.0  255.0   32.0   93.0   18.0   25.0  29.0   17.0  255.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  2\n",
      "Accuracy: 0.7003783969728242\n",
      "F1 Score: 0.68695212853178\n",
      "Precision: 0.7344234619779695\n",
      "Recall/Sensitivity/True Positive Rate: 0.7003783969728242\n",
      "Confusion Matrix:\n",
      " [[ 337  544]\n",
      " [ 327 1699]]\n",
      "\n",
      "\n",
      "      1772    481   670   1212   2245   1465   2023   2246  1389    274  ...  \\\n",
      "0     80.0  112.0  72.0   74.0   91.0  172.0  132.0   83.0  91.0  204.0  ...   \n",
      "1     87.0  112.0  72.0  120.0  100.0  168.0  100.0   95.0  84.0  166.0  ...   \n",
      "2     85.0  125.0  71.0   81.0  103.0  171.0   93.0   97.0  83.0   88.0  ...   \n",
      "3     83.0  127.0  65.0   79.0  126.0  190.0   90.0  109.0  78.0   64.0  ...   \n",
      "4     77.0  109.0  65.0   79.0   97.0  176.0   85.0   96.0  77.0  208.0  ...   \n",
      "...    ...    ...   ...    ...    ...    ...    ...    ...   ...    ...  ...   \n",
      "9685  36.0  255.0  38.0  102.0   52.0   85.0   19.0   37.0  35.0  226.0  ...   \n",
      "9686  37.0  255.0  27.0   93.0   56.0   69.0   18.0   36.0  34.0  215.0  ...   \n",
      "9687  29.0  255.0  30.0   88.0   42.0   59.0   18.0   41.0  30.0  133.0  ...   \n",
      "9688  24.0  255.0  20.0  142.0   39.0   64.0   17.0   39.0  30.0  238.0  ...   \n",
      "9689  34.0  226.0  28.0   72.0   33.0   52.0   17.0   34.0  67.0  239.0  ...   \n",
      "\n",
      "      1243    777   2204  2156    684  1677    314  2011    541  label  \n",
      "0     87.0  107.0  103.0  97.0  105.0  80.0  188.0  79.0  121.0      1  \n",
      "1     90.0  137.0   84.0  80.0  107.0  90.0  177.0  79.0  145.0      1  \n",
      "2     89.0  126.0   75.0  75.0  117.0  90.0   98.0  79.0  139.0      1  \n",
      "3     86.0  140.0   68.0  71.0  128.0  88.0   77.0  76.0  141.0      1  \n",
      "4     79.0  145.0   71.0  70.0  133.0  79.0  196.0  71.0   89.0      1  \n",
      "...    ...    ...    ...   ...    ...   ...    ...   ...    ...    ...  \n",
      "9685  34.0  255.0   26.0  29.0  238.0  40.0  205.0  50.0  255.0      1  \n",
      "9686  39.0  202.0   29.0  30.0  204.0  36.0  191.0  54.0  255.0      1  \n",
      "9687  38.0  255.0   34.0  30.0  255.0  31.0   53.0  65.0  255.0      1  \n",
      "9688  47.0   58.0   23.0  24.0   24.0  28.0  253.0  65.0  164.0      1  \n",
      "9689  68.0  251.0   35.0  29.0  255.0  53.0  254.0  65.0  158.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  3\n",
      "Accuracy: 0.7296181630546955\n",
      "F1 Score: 0.6925545518773143\n",
      "Precision: 0.8519568209571109\n",
      "Recall/Sensitivity/True Positive Rate: 0.7296181630546955\n",
      "Confusion Matrix:\n",
      " [[ 310  676]\n",
      " [ 110 1811]]\n",
      "\n",
      "\n",
      "      1676   2039   2051    581   2272    491  1677  1674   1921   1148  ...  \\\n",
      "0     83.0  135.0  108.0  143.0   95.0   84.0  80.0  89.0  125.0   85.0  ...   \n",
      "1     91.0  137.0  113.0  170.0   84.0   99.0  90.0  86.0  142.0   93.0  ...   \n",
      "2     88.0  123.0  112.0  164.0   82.0  133.0  90.0  80.0  146.0  101.0  ...   \n",
      "3     84.0  147.0   98.0  164.0   78.0  151.0  88.0  76.0  143.0   92.0  ...   \n",
      "4     76.0  114.0  126.0  116.0  125.0   81.0  79.0  75.0  144.0   76.0  ...   \n",
      "...    ...    ...    ...    ...    ...    ...   ...   ...    ...    ...  ...   \n",
      "9685  39.0   33.0   62.0  255.0  104.0  255.0  40.0  33.0  101.0   32.0  ...   \n",
      "9686  39.0   18.0   23.0  255.0  102.0  255.0  36.0  47.0   41.0   41.0  ...   \n",
      "9687  36.0   27.0   65.0  253.0  101.0  168.0  31.0  36.0   54.0   36.0  ...   \n",
      "9688  23.0   25.0   51.0  255.0   96.0  255.0  28.0  26.0   45.0   94.0  ...   \n",
      "9689  45.0   31.0   60.0  254.0   90.0  224.0  53.0  43.0   56.0   35.0  ...   \n",
      "\n",
      "        348   910   2182    470   1474   1103    921   2066      7  label  \n",
      "0     225.0  82.0   90.0   95.0   90.0   94.0  109.0  126.0  119.0      1  \n",
      "1     168.0  73.0   84.0   97.0  141.0   80.0  137.0  136.0  107.0      1  \n",
      "2     106.0  72.0  103.0   94.0  104.0   84.0  137.0  124.0  109.0      1  \n",
      "3      86.0  73.0   96.0   76.0   84.0   87.0  147.0  128.0   96.0      1  \n",
      "4     212.0  69.0  134.0   97.0  193.0   73.0  157.0  153.0  109.0      1  \n",
      "...     ...   ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "9685  255.0  48.0   96.0  103.0   20.0   36.0  252.0   60.0  255.0      1  \n",
      "9686  255.0  47.0   49.0  170.0   20.0   49.0  207.0   38.0  254.0      1  \n",
      "9687   40.0  39.0   92.0  199.0   23.0   33.0  107.0   41.0  255.0      1  \n",
      "9688  255.0  35.0   88.0   35.0   21.0   70.0  255.0   38.0  255.0      1  \n",
      "9689  155.0  17.0   85.0   33.0   18.0  137.0   26.0   34.0  212.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  4\n",
      "Accuracy: 0.52046783625731\n",
      "F1 Score: 0.48000633242161717\n",
      "Precision: 0.7679480647713061\n",
      "Recall/Sensitivity/True Positive Rate: 0.52046783625731\n",
      "Confusion Matrix:\n",
      " [[ 458 1269]\n",
      " [ 125 1055]]\n",
      "\n",
      "\n",
      "        464     74   1739   1361   1756    445   1874   1928    774     58  \\\n",
      "0      89.0  208.0   91.0  198.0  149.0  109.0  152.0  144.0  153.0  113.0   \n",
      "1     106.0  176.0  124.0  204.0  111.0   89.0  150.0  100.0  165.0   92.0   \n",
      "2     123.0  162.0  114.0  197.0  122.0  103.0  177.0  105.0  165.0  121.0   \n",
      "3     113.0  164.0  132.0  173.0   96.0  111.0  137.0   70.0  169.0  162.0   \n",
      "4      82.0  144.0  154.0  226.0  200.0   98.0  122.0   83.0  161.0  103.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  158.0   23.0   21.0  115.0   71.0  255.0   67.0   19.0  227.0  255.0   \n",
      "9686  203.0  255.0   29.0  111.0   80.0  255.0   58.0   18.0  228.0  134.0   \n",
      "9687   17.0  255.0   53.0  107.0   54.0   83.0   42.0   18.0  255.0  255.0   \n",
      "9688  119.0  103.0   23.0   99.0   42.0  253.0   47.0   16.0  253.0  236.0   \n",
      "9689  172.0   48.0   40.0   95.0   39.0  198.0   60.0   16.0  124.0   15.0   \n",
      "\n",
      "      ...   1921   1617  1865   1018   1909   811   1056   2054   615  label  \n",
      "0     ...  125.0  105.0  85.0  124.0   77.0  75.0  171.0   74.0  79.0      1  \n",
      "1     ...  142.0  106.0  84.0  114.0   91.0  77.0  118.0   94.0  78.0      1  \n",
      "2     ...  146.0   95.0  76.0  131.0   95.0  76.0  138.0   94.0  73.0      1  \n",
      "3     ...  143.0   95.0  73.0  139.0   99.0  76.0  136.0   95.0  76.0      1  \n",
      "4     ...  144.0  158.0  72.0  144.0  115.0  70.0  122.0  109.0  73.0      1  \n",
      "...   ...    ...    ...   ...    ...    ...   ...    ...    ...   ...    ...  \n",
      "9685  ...  101.0   93.0  55.0  246.0   16.0  46.0  108.0   67.0  60.0      1  \n",
      "9686  ...   41.0   89.0  58.0  144.0   16.0  44.0  255.0   26.0  57.0      1  \n",
      "9687  ...   54.0   84.0  26.0  113.0   16.0  21.0  202.0   77.0  27.0      1  \n",
      "9688  ...   45.0   77.0  24.0  252.0   15.0  19.0  255.0   59.0  28.0      1  \n",
      "9689  ...   56.0   77.0  21.0   28.0   13.0  18.0   98.0   65.0  28.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  5\n",
      "Accuracy: 0.5576195390436877\n",
      "F1 Score: 0.4186555600505352\n",
      "Precision: 0.9612976878531656\n",
      "Recall/Sensitivity/True Positive Rate: 0.5576195390436877\n",
      "Confusion Matrix:\n",
      " [[  37 1258]\n",
      " [  28 1584]]\n",
      "\n",
      "\n",
      "       2216   1948   1778    966    935   1063    963   956    830    374  \\\n",
      "0      75.0  132.0  125.0  135.0  228.0  139.0   88.0  78.0   92.0   68.0   \n",
      "1      76.0  119.0  166.0   92.0  197.0  107.0  165.0  83.0  108.0   79.0   \n",
      "2      82.0  115.0  141.0   94.0  204.0  126.0  140.0  79.0   85.0   89.0   \n",
      "3      77.0  110.0  155.0   80.0  179.0   93.0  159.0  76.0   76.0  101.0   \n",
      "4     106.0  107.0  180.0  161.0  236.0   98.0  166.0  76.0  110.0   76.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...   ...    ...    ...   \n",
      "9685   40.0   18.0   78.0  191.0  112.0  150.0  185.0  42.0  172.0  109.0   \n",
      "9686   29.0   17.0   76.0  227.0  107.0  211.0  228.0  40.0  244.0  217.0   \n",
      "9687   31.0   16.0   58.0  154.0  102.0  109.0  221.0  39.0  255.0  240.0   \n",
      "9688   33.0   15.0   40.0  255.0   98.0  255.0  255.0  35.0  148.0  160.0   \n",
      "9689   32.0   13.0  143.0   17.0   93.0  243.0   20.0  17.0  208.0   60.0   \n",
      "\n",
      "      ...    965   1433   1734     41    972   1049   1095   719    967  label  \n",
      "0     ...  129.0   88.0  119.0   85.0  104.0  102.0  106.0  75.0  128.0      1  \n",
      "1     ...   78.0   89.0  102.0  103.0  120.0   93.0  101.0  73.0  116.0      1  \n",
      "2     ...   73.0   84.0  110.0  104.0   98.0   84.0   96.0  70.0  120.0      1  \n",
      "3     ...   83.0   78.0   87.0   94.0   86.0   83.0  116.0  67.0  102.0      1  \n",
      "4     ...  160.0  106.0  177.0  103.0   98.0   91.0   99.0  65.0  162.0      1  \n",
      "...   ...    ...    ...    ...    ...    ...    ...    ...   ...    ...    ...  \n",
      "9685  ...  185.0   36.0   42.0   28.0  255.0   40.0   48.0  28.0  185.0      1  \n",
      "9686  ...  220.0   34.0   60.0  100.0  176.0   48.0   43.0  44.0  171.0      1  \n",
      "9687  ...  173.0   36.0   60.0  253.0  115.0   50.0   37.0  32.0  142.0      1  \n",
      "9688  ...  255.0   54.0   56.0  242.0  222.0  100.0   93.0  13.0  255.0      1  \n",
      "9689  ...   17.0   21.0   99.0   97.0   43.0   50.0   62.0  52.0   14.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  6\n",
      "Accuracy: 0.6487788097695218\n",
      "F1 Score: 0.5406714335178404\n",
      "Precision: 0.9499374305065909\n",
      "Recall/Sensitivity/True Positive Rate: 0.648778809769522\n",
      "Confusion Matrix:\n",
      " [[  72  989]\n",
      " [  32 1814]]\n",
      "\n",
      "\n",
      "       1382   1564   2290    314   2163   1948   1883   1013   1241   1835  \\\n",
      "0     107.0  230.0  105.0  188.0   92.0  132.0  104.0  125.0   91.0   99.0   \n",
      "1      95.0  235.0  142.0  177.0  103.0  119.0  127.0   83.0   95.0  125.0   \n",
      "2     104.0  235.0  144.0   98.0  112.0  115.0  120.0   76.0   88.0  117.0   \n",
      "3     104.0  233.0  114.0   77.0  106.0  110.0  139.0   90.0   80.0  136.0   \n",
      "4      73.0  164.0  108.0  196.0  143.0  107.0  145.0  108.0  106.0  149.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685   41.0   68.0  101.0  205.0   45.0   18.0   46.0  221.0   34.0   87.0   \n",
      "9686   40.0   61.0   98.0  191.0   36.0   17.0   80.0  229.0   39.0   89.0   \n",
      "9687   41.0   72.0   96.0   53.0   36.0   16.0   29.0  225.0   49.0  104.0   \n",
      "9688   35.0   76.0   90.0  253.0   38.0   15.0   32.0  255.0   99.0   89.0   \n",
      "9689   33.0   65.0   86.0  254.0   31.0   13.0   20.0   24.0   33.0   91.0   \n",
      "\n",
      "      ...  1535   1855   1806    531    213  1677    136    280    512  label  \n",
      "0     ...  90.0  134.0  143.0  139.0  212.0  80.0   98.0  111.0  118.0      1  \n",
      "1     ...  86.0  126.0  117.0  144.0  173.0  90.0   92.0   78.0  132.0      1  \n",
      "2     ...  84.0  123.0  116.0  149.0  213.0  90.0   89.0   70.0  120.0      1  \n",
      "3     ...  86.0  113.0  118.0  149.0  172.0  88.0   90.0   71.0  114.0      1  \n",
      "4     ...  80.0  131.0  166.0   97.0  190.0  79.0   84.0   68.0  100.0      1  \n",
      "...   ...   ...    ...    ...    ...    ...   ...    ...    ...    ...    ...  \n",
      "9685  ...  40.0   85.0   79.0  255.0  255.0  40.0  102.0  232.0  128.0      1  \n",
      "9686  ...  33.0  101.0   42.0  255.0   49.0  36.0   88.0   19.0  113.0      1  \n",
      "9687  ...  30.0   70.0   85.0  255.0  192.0  31.0  151.0  105.0   37.0      1  \n",
      "9688  ...  29.0   66.0   78.0  255.0  251.0  28.0  251.0   96.0  133.0      1  \n",
      "9689  ...  34.0   55.0   79.0  206.0   49.0  53.0   25.0  169.0   68.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  7\n",
      "Accuracy: 0.6171310629514963\n",
      "F1 Score: 0.49059398466163334\n",
      "Precision: 0.9646944606223494\n",
      "Recall/Sensitivity/True Positive Rate: 0.6171310629514963\n",
      "Confusion Matrix:\n",
      " [[  40 1088]\n",
      " [  25 1754]]\n",
      "\n",
      "\n",
      "        425    237   2084    129   1491    461   1322    218   2192    884  \\\n",
      "0      98.0   72.0   97.0  166.0  181.0   89.0  148.0  179.0  155.0  228.0   \n",
      "1     107.0   75.0  117.0  229.0  182.0   96.0  169.0  200.0  119.0  207.0   \n",
      "2      96.0   74.0  124.0  230.0  176.0  132.0  126.0  186.0  115.0  195.0   \n",
      "3      76.0   81.0  122.0  215.0  174.0  128.0  133.0  143.0   99.0  146.0   \n",
      "4      70.0   91.0  103.0  226.0  114.0   76.0  137.0  190.0  116.0  182.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  130.0  133.0  101.0   31.0   68.0  173.0   45.0  255.0  100.0   56.0   \n",
      "9686   69.0  225.0   64.0   30.0   79.0  239.0   36.0   20.0   71.0   91.0   \n",
      "9687   90.0  124.0   97.0  244.0   71.0   64.0   21.0  159.0   94.0   90.0   \n",
      "9688   27.0   25.0   96.0  255.0  116.0  124.0   17.0  255.0   89.0   84.0   \n",
      "9689   56.0   36.0   89.0  108.0  255.0  103.0   16.0  104.0   86.0   82.0   \n",
      "\n",
      "      ...    375    211    829    628    927    115  1389    338    450  label  \n",
      "0     ...   72.0  182.0  100.0  166.0  105.0  188.0  91.0   84.0   93.0      1  \n",
      "1     ...   78.0  208.0  117.0  182.0   80.0  227.0  84.0   73.0   94.0      1  \n",
      "2     ...   91.0  174.0   97.0  173.0  110.0  156.0  83.0   88.0  108.0      1  \n",
      "3     ...  102.0  176.0   81.0  175.0  135.0  147.0  78.0  100.0  124.0      1  \n",
      "4     ...   70.0  161.0  128.0  127.0   81.0  177.0  77.0   90.0   82.0      1  \n",
      "...   ...    ...    ...    ...    ...    ...    ...   ...    ...    ...    ...  \n",
      "9685  ...  101.0  255.0  208.0  255.0  161.0  227.0  35.0  255.0  179.0      1  \n",
      "9686  ...  137.0   36.0  217.0  255.0  104.0   92.0  34.0  255.0  255.0      1  \n",
      "9687  ...  249.0  255.0  251.0  255.0   75.0  254.0  30.0  204.0  135.0      1  \n",
      "9688  ...   81.0  255.0   99.0  192.0   86.0  254.0  30.0  255.0  251.0      1  \n",
      "9689  ...   86.0   58.0  102.0  255.0   70.0   88.0  67.0  238.0   79.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  8\n",
      "Accuracy: 0.8286893704850361\n",
      "F1 Score: 0.7977301904641446\n",
      "Precision: 0.8986401452810748\n",
      "Recall/Sensitivity/True Positive Rate: 0.8286893704850361\n",
      "Confusion Matrix:\n",
      " [[  52  372]\n",
      " [ 126 2357]]\n",
      "\n",
      "\n",
      "       1109    346     42    646    798   2256    492   1934   2170   1402  \\\n",
      "0     124.0  170.0   78.0   90.0   95.0   85.0   86.0  111.0   84.0  120.0   \n",
      "1      90.0  127.0   96.0   80.0  139.0   74.0  102.0  108.0   82.0  136.0   \n",
      "2      79.0  131.0   95.0   83.0  149.0   77.0  134.0   99.0   96.0  122.0   \n",
      "3      99.0   84.0   95.0  124.0  172.0   75.0  135.0  102.0   89.0  139.0   \n",
      "4     108.0  201.0   87.0  101.0   90.0  129.0   81.0   98.0  120.0  130.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  241.0  255.0   40.0   26.0   57.0   50.0  255.0   19.0   58.0  100.0   \n",
      "9686  169.0  254.0  104.0   62.0   80.0   43.0  255.0   19.0   53.0   87.0   \n",
      "9687  224.0   40.0  246.0   65.0   99.0   35.0  134.0   18.0   63.0   87.0   \n",
      "9688  255.0  254.0  189.0   71.0   61.0   33.0  214.0   16.0   58.0  130.0   \n",
      "9689  150.0  139.0   61.0   59.0   52.0   37.0  166.0   15.0   65.0   98.0   \n",
      "\n",
      "      ...     71   2176   1204    916    917   850  1679   2287   1855  label  \n",
      "0     ...  165.0   92.0  108.0  100.0  136.0  94.0  84.0  149.0  134.0      1  \n",
      "1     ...  192.0   94.0  123.0  118.0   87.0  78.0  80.0  104.0  126.0      1  \n",
      "2     ...  224.0  105.0  119.0  106.0   84.0  74.0  87.0   98.0  123.0      1  \n",
      "3     ...  236.0   93.0  111.0  122.0   78.0  79.0  88.0   95.0  113.0      1  \n",
      "4     ...  173.0  126.0  141.0  176.0  176.0  77.0  79.0   94.0  131.0      1  \n",
      "...   ...    ...    ...    ...    ...    ...   ...   ...    ...    ...    ...  \n",
      "9685  ...   27.0   84.0  153.0  184.0  157.0  50.0  39.0  100.0   85.0      0  \n",
      "9686  ...  247.0   36.0  189.0  254.0  247.0  67.0  34.0  100.0  101.0      0  \n",
      "9687  ...  217.0   89.0  210.0  190.0  163.0  54.0  27.0   94.0   70.0      0  \n",
      "9688  ...  204.0   83.0  255.0  255.0  255.0  10.0  37.0   89.0   66.0      0  \n",
      "9689  ...   48.0   88.0  255.0   78.0   43.0  66.0  23.0   85.0   55.0      0  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  9\n",
      "Accuracy: 0.9267285861713106\n",
      "F1 Score: 0.9144435925616496\n",
      "Precision: 0.9524633778175498\n",
      "Recall/Sensitivity/True Positive Rate: 0.9267285861713106\n",
      "Confusion Matrix:\n",
      " [[  12  148]\n",
      " [  65 2682]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in [5, 10, 20]:\n",
    "    for i in range(10):\n",
    "        strings=globals()[\"xy{}_{}\".format(i, x)]\n",
    "        print(strings)\n",
    "        print(\"The current Data frame is: \",i)\n",
    "        y_train=strings['label']\n",
    "        processed_df=strings.drop(columns=['label'])\n",
    "        naive_bayes_search(processed_df,y_train)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685    9\n",
      "9686    9\n",
      "9687    9\n",
      "9688    9\n",
      "9689    9\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685    9\n",
      "9686    9\n",
      "9687    9\n",
      "9688    9\n",
      "9689    9\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685    9\n",
      "9686    9\n",
      "9687    9\n",
      "9688    9\n",
      "9689    9\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "[-1  0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- 1016\n- 109\n- 1136\n- 1141\n- 1265\n- ...\nFeature names seen at fit time, yet now missing:\n- 1599\n- 595\n- 76\n- 908\n- 916\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\victo\\Documents\\year4\\F20DL\\labs\\DMML\\Coursework\\Part 1\\Feature_Selection.ipynb Cell 30\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/victo/Documents/year4/F20DL/labs/DMML/Coursework/Part%201/Feature_Selection.ipynb#X42sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m gnb \u001b[39min\u001b[39;00m gnbs:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/victo/Documents/year4/F20DL/labs/DMML/Coursework/Part%201/Feature_Selection.ipynb#X42sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mprint\u001b[39m(gnb\u001b[39m.\u001b[39mclasses_)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/victo/Documents/year4/F20DL/labs/DMML/Coursework/Part%201/Feature_Selection.ipynb#X42sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     predi \u001b[39m=\u001b[39m gnb\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/victo/Documents/year4/F20DL/labs/DMML/Coursework/Part%201/Feature_Selection.ipynb#X42sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     predis\u001b[39m.\u001b[39mappend(predi)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/victo/Documents/year4/F20DL/labs/DMML/Coursework/Part%201/Feature_Selection.ipynb#X42sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m y_pred_multilabel \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcolumn_stack(predis)\n",
      "File \u001b[1;32mc:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\naive_bayes.py:101\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[39mPerform classification on an array of test vectors X.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39m    Predicted target values for X.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    100\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 101\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_X(X)\n\u001b[0;32m    102\u001b[0m jll \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_joint_log_likelihood(X)\n\u001b[0;32m    103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_[np\u001b[39m.\u001b[39margmax(jll, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\naive_bayes.py:269\u001b[0m, in \u001b[0;36mGaussianNB._check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_X\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    268\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate X, used only in predict* methods.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:580\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_data\u001b[39m(\n\u001b[0;32m    510\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    511\u001b[0m     X\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_validation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params,\n\u001b[0;32m    517\u001b[0m ):\n\u001b[0;32m    518\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \n\u001b[0;32m    520\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[39m        validated.\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 580\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_feature_names(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    582\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    583\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    584\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m estimator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    585\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequires y to be passed, but the target y is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    586\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:507\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing_names \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    503\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    504\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n\u001b[1;32m--> 507\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- 1016\n- 109\n- 1136\n- 1141\n- 1265\n- ...\nFeature names seen at fit time, yet now missing:\n- 1599\n- 595\n- 76\n- 908\n- 916\n"
     ]
    }
   ],
   "source": [
    "gnbs = []\n",
    "\n",
    "# for x in [5, 10, 20]:\n",
    "for x in [5]:\n",
    "    for i in range(10):\n",
    "        strings=globals()[\"xy{}_{}\".format(i, x)]\n",
    "        # print(\"The current Data frame is: \",i)\n",
    "        y_train=strings['label']\n",
    "        y_train = y_train.replace({0: i, 1: -1})\n",
    "        print(y_train)\n",
    "        processed_df=strings.drop(columns=['label'])\n",
    "        # naive_bayes_search(processed_df,y_train)\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(processed_df, y_train, test_size=0.3,random_state=seed_value)\n",
    "        gnb = GaussianNB()\n",
    "        gnb.fit(X_train, Y_train)\n",
    "        gnbs.append(gnb)\n",
    "\n",
    "predis = []\n",
    "for gnb in gnbs:\n",
    "    gnb.classes_\n",
    "    predi = gnb.predict(X_test)\n",
    "    predis.append(predi)\n",
    "\n",
    "y_pred_multilabel = np.column_stack(predis)\n",
    "accuracy_score(Y_test, y_pred_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reduced_x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\anshu\\OneDrive\\Desktop\\Course\\F21DL\\DMML\\Coursework\\Part 1\\Feature_Selection_fixed.ipynb Cell 31\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m classifiers \u001b[39m=\u001b[39m [GaussianNB() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ovr \u001b[39m=\u001b[39m OneVsRestClassifier(GaussianNB(), n_jobs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_train, X_test, Y_train, Y_test \u001b[39m=\u001b[39m train_test_split(reduced_x_train, ytrainall, test_size\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m,random_state\u001b[39m=\u001b[39mseed_value)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m ovr\u001b[39m.\u001b[39mfit(X_train, Y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m predicted \u001b[39m=\u001b[39m ovr\u001b[39m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reduced_x_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "classifiers = [GaussianNB() for i in range(10)]\n",
    "ovr = OneVsRestClassifier(GaussianNB(), n_jobs=10)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(reduced_x_train, ytrainall, test_size=0.3,random_state=seed_value)\n",
    "\n",
    "ovr.fit(X_train, Y_train)\n",
    "predicted = ovr.predict(X_test)\n",
    "predicted_probs = ovr.predict_proba(X_test)\n",
    "\n",
    "# cross_val_scores = cross_val_score(gnb, X_train, Y_train, cv=5)  \n",
    "# print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "# print(\"Mean CV Score:\", cross_val_scores.mean())\n",
    "\n",
    "\n",
    "# train_sizes, train_scores, test_scores = learning_curve(gnb, X_train, Y_train, cv=5)\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Learning Curves\")\n",
    "# plt.xlabel(\"Training examples\")\n",
    "# plt.ylabel(\"Score\")\n",
    "# plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "# plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()\n",
    "\n",
    "accuracy = accuracy_score(Y_test,predicted )\n",
    "f1 = f1_score(predicted, Y_test, average=\"weighted\")\n",
    "conf_matrix = confusion_matrix(predicted, Y_test)\n",
    "precision = precision_score(Y_test, predicted, average=\"weighted\",zero_division=1)\n",
    "recall = recall_score(Y_test, predicted, average=\"weighted\")\n",
    "# roc = roc_auc_score(Y_test, predicted_probs, multi_class=\"ovr\", average=\"weighted\")\n",
    "# conf_matrices = multilabel_confusion_matrix(Y_test, predicted)\n",
    "# tp = conf_matrices[:,1,1]\n",
    "# fp = conf_matrices[:,0,1]\n",
    "# tn = conf_matrices[:,0,0]\n",
    "# fn = conf_matrices[:,1,0]\n",
    "# fpr = _nanaverage(fp/(tn + fp), tp + fn)\n",
    "# tnr = _nanaverage(tn/(tn + fp), tp + fn)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall/Sensitivity/True Positive Rate:\", recall)\n",
    "# print(\"Specificity:\", tnr)\n",
    "# print(\"False Positive Rate:\", fpr)\n",
    "# print(\"Area under ROC curve:\", roc)\n",
    "# print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xy3_4'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"xy{}_{}\".format(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
