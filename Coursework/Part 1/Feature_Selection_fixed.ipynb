{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix,multilabel_confusion_matrix,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "# from sklearn.metrics._classification import _nanaverage\n",
    "\n",
    "def naive_bayes_search(df1, df2,seed_value=22):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(df1, df2, test_size=0.3,random_state=seed_value)\n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, Y_train)\n",
    "    \n",
    "    predicted = gnb.predict(X_test)\n",
    "    predicted_probs = gnb.predict_proba(X_test)\n",
    "    \n",
    "    # cross_val_scores = cross_val_score(gnb, X_train, Y_train, cv=5)  \n",
    "    # print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "    # print(\"Mean CV Score:\", cross_val_scores.mean())\n",
    "\n",
    "\n",
    "    # train_sizes, train_scores, test_scores = learning_curve(gnb, X_train, Y_train, cv=5)\n",
    "    # train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    # test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.title(\"Learning Curves\")\n",
    "    # plt.xlabel(\"Training examples\")\n",
    "    # plt.ylabel(\"Score\")\n",
    "    # plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    # plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    # plt.legend(loc=\"best\")\n",
    "    # plt.show()\n",
    "\n",
    "    accuracy = accuracy_score(Y_test,predicted )\n",
    "    f1 = f1_score(predicted, Y_test, average=\"weighted\")\n",
    "    conf_matrix = confusion_matrix(predicted, Y_test)\n",
    "    precision = precision_score(Y_test, predicted, average=\"weighted\",zero_division=1)\n",
    "    recall = recall_score(Y_test, predicted, average=\"weighted\")\n",
    "    # roc = roc_auc_score(Y_test, predicted_probs, multi_class=\"ovr\", average=\"weighted\")\n",
    "    conf_matrices = multilabel_confusion_matrix(Y_test, predicted)\n",
    "    tp = conf_matrices[:,1,1]\n",
    "    fp = conf_matrices[:,0,1]\n",
    "    tn = conf_matrices[:,0,0]\n",
    "    fn = conf_matrices[:,1,0]\n",
    "    # fpr = _nanaverage(fp/(tn + fp), tp + fn)\n",
    "    # tnr = _nanaverage(tn/(tn + fp), tp + fn)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall/Sensitivity/True Positive Rate:\", recall)\n",
    "    # print(\"Specificity:\", tnr)\n",
    "    # print(\"False Positive Rate:\", fpr)\n",
    "    # print(\"Area under ROC curve:\", roc)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "    return predicted\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "merged_data = pd.read_csv('processed_df.csv')\n",
    "# merged_data=pd.read_csv('Dataset/x_train_all.csv')\n",
    "ytrainall = pd.read_csv('Dataset/y_train_all.csv')\n",
    "merged_data = pd.concat([merged_data,ytrainall],axis = 1)\n",
    "merged_data=merged_data.rename(columns={merged_data.columns[-1]:'label'})\n",
    "# merged_data=merged_data.rename(columns={merged_data.columns[0]:'labels'})\n",
    "# merged_data=merged_data.drop(columns =['labels'])\n",
    "merged_data.columns.values[0] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2295</th>\n",
       "      <th>2296</th>\n",
       "      <th>2297</th>\n",
       "      <th>2298</th>\n",
       "      <th>2299</th>\n",
       "      <th>2300</th>\n",
       "      <th>2301</th>\n",
       "      <th>2302</th>\n",
       "      <th>2303</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>...</td>\n",
       "      <td>93.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4      5      6      7      8      9  ...  2295  \\\n",
       "0  78.0  77.0  76.0  82.0  87.0   92.0  104.0  119.0  117.0  120.0  ...  79.0   \n",
       "1  73.0  75.0  79.0  78.0  76.0   75.0   89.0  107.0  133.0  125.0  ...  93.0   \n",
       "2  72.0  75.0  79.0  77.0  81.0   89.0  105.0  109.0   86.0   90.0  ...  95.0   \n",
       "3  67.0  70.0  74.0  80.0  93.0  107.0  110.0   96.0   69.0  100.0  ...  92.0   \n",
       "4  74.0  74.0  73.0  72.0  77.0   87.0  104.0  109.0   84.0   83.0  ...  98.0   \n",
       "\n",
       "   2296   2297  2298  2299  2300   2301   2302   2303  label  \n",
       "0  72.0   76.0  83.0  95.0  99.0   98.0   95.0   94.0      0  \n",
       "1  85.0   77.0  69.0  73.0  83.0  100.0  101.0  101.0      0  \n",
       "2  88.0   80.0  73.0  71.0  74.0   80.0   89.0   95.0      0  \n",
       "3  87.0   82.0  77.0  72.0  70.0   72.0   81.0   88.0      0  \n",
       "4  99.0  100.0  99.0  89.0  78.0   66.0   68.0   72.0      0  \n",
       "\n",
       "[5 rows x 2305 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "x = merged_data.drop('label',axis=1)\n",
    "y = merged_data['label']\n",
    "\n",
    "svm = SVC(kernel='linear', decision_function_shape='ovr')\n",
    "\n",
    "svm.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_weights = svm.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([1605,  490, 1536,  927,  742, 1966, 2066, 2235,  239, 1869, 1941,\n",
      "       1264, 2090, 1815, 1766,  661, 2122,  409, 1497,  628], dtype=int64), 1: array([1432,   52, 1733,  637, 1262,  829, 1388,  280,  635, 1423,  702,\n",
      "       2221, 1773, 1868,  739,  828, 2022, 1876, 1609, 1377], dtype=int64), 2: array([1997,  166,  335, 1765, 1780,  845,  281,  638, 1561,  148,  510,\n",
      "        487,  537, 2293, 1699, 1023,  136,  284, 1185,  391], dtype=int64), 3: array([1772,  481,  670, 1212, 2245, 1465, 2023, 2246, 1389,  274, 1164,\n",
      "       1243,  777, 2204, 2156,  684, 1677,  314, 2011,  541], dtype=int64), 4: array([1676, 2039, 2051,  581, 2272,  491, 1677, 1674, 1921, 1148,  486,\n",
      "        348,  910, 2182,  470, 1474, 1103,  921, 2066,    7], dtype=int64), 5: array([ 464,   74, 1739, 1361, 1756,  445, 1874, 1928,  774,   58, 1998,\n",
      "       1921, 1617, 1865, 1018, 1909,  811, 1056, 2054,  615], dtype=int64), 6: array([2216, 1948, 1778,  966,  935, 1063,  963,  956,  830,  374,  574,\n",
      "        965, 1433, 1734,   41,  972, 1049, 1095,  719,  967], dtype=int64), 7: array([1382, 1564, 2290,  314, 2163, 1948, 1883, 1013, 1241, 1835,  483,\n",
      "       1535, 1855, 1806,  531,  213, 1677,  136,  280,  512], dtype=int64), 8: array([ 425,  237, 2084,  129, 1491,  461, 1322,  218, 2192,  884,  510,\n",
      "        375,  211,  829,  628,  927,  115, 1389,  338,  450], dtype=int64), 9: array([1109,  346,   42,  646,  798, 2256,  492, 1934, 2170, 1402, 2201,\n",
      "         71, 2176, 1204,  916,  917,  850, 1679, 2287, 1855], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "k = 20\n",
    "selected_features_per_class = {}\n",
    "for class_label in range(10): \n",
    "    feature_ranking = np.argsort(np.abs(feature_weights[class_label]))\n",
    "    selected_features = feature_ranking[:k]\n",
    "    selected_features_per_class[class_label] = selected_features\n",
    "\n",
    "print(selected_features_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtrain = pd.read_csv('processed_df.csv')\n",
    "xtrain = pd.read_csv('Dataset/x_train_all.csv')\n",
    "# xtrain = xtrain.rename(columns={xtrain.columns[0]:'labels'})\n",
    "# xtrain = xtrain.drop(columns=['labels'])\n",
    "ytrain0 = pd.read_csv('y_train_0.csv')\n",
    "ytrain3 = pd.read_csv('y_train_3.csv')\n",
    "ytrain1 = pd.read_csv('y_train_1.csv')\n",
    "ytrain2 = pd.read_csv('y_train_2.csv')\n",
    "ytrain4 = pd.read_csv('y_train_4.csv')\n",
    "ytrain5 = pd.read_csv('y_train_5.csv')\n",
    "ytrain6 = pd.read_csv('y_train_6.csv')\n",
    "ytrain7 = pd.read_csv('y_train_7.csv')\n",
    "ytrain8 = pd.read_csv('y_train_8.csv')\n",
    "ytrain9 = pd.read_csv('y_train_9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2294</th>\n",
       "      <th>2295</th>\n",
       "      <th>2296</th>\n",
       "      <th>2297</th>\n",
       "      <th>2298</th>\n",
       "      <th>2299</th>\n",
       "      <th>2300</th>\n",
       "      <th>2301</th>\n",
       "      <th>2302</th>\n",
       "      <th>2303</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>112.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4      5      6      7      8      9  ...  \\\n",
       "0  78.0  77.0  76.0  82.0  87.0   92.0  104.0  119.0  117.0  120.0  ...   \n",
       "1  73.0  75.0  79.0  78.0  76.0   75.0   89.0  107.0  133.0  125.0  ...   \n",
       "2  72.0  75.0  79.0  77.0  81.0   89.0  105.0  109.0   86.0   90.0  ...   \n",
       "3  67.0  70.0  74.0  80.0  93.0  107.0  110.0   96.0   69.0  100.0  ...   \n",
       "4  74.0  74.0  73.0  72.0  77.0   87.0  104.0  109.0   84.0   83.0  ...   \n",
       "\n",
       "    2294  2295  2296   2297  2298  2299  2300   2301   2302   2303  \n",
       "0   87.0  79.0  72.0   76.0  83.0  95.0  99.0   98.0   95.0   94.0  \n",
       "1   96.0  93.0  85.0   77.0  69.0  73.0  83.0  100.0  101.0  101.0  \n",
       "2   98.0  95.0  88.0   80.0  73.0  71.0  74.0   80.0   89.0   95.0  \n",
       "3  112.0  92.0  87.0   82.0  77.0  72.0  70.0   72.0   81.0   88.0  \n",
       "4  100.0  98.0  99.0  100.0  99.0  89.0  78.0   66.0   68.0   72.0  \n",
       "\n",
       "[5 rows x 2304 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1605    490   1536    927    742  1966   2066   2235    239  1869  ...  \\\n",
      "0     219.0   83.0  184.0  105.0  103.0  82.0  126.0   98.0   77.0  79.0  ...   \n",
      "1     185.0   97.0  187.0   80.0  123.0  80.0  136.0  125.0   71.0  79.0  ...   \n",
      "2     204.0  129.0  182.0  110.0  196.0  76.0  124.0  109.0   68.0  79.0  ...   \n",
      "3     185.0  148.0  184.0  135.0  235.0  77.0  128.0  111.0   64.0  80.0  ...   \n",
      "4     175.0   80.0  107.0   81.0   78.0  77.0  153.0  119.0   83.0  75.0  ...   \n",
      "...     ...    ...    ...    ...    ...   ...    ...    ...    ...   ...  ...   \n",
      "9685   54.0  255.0  222.0  161.0   96.0  29.0   60.0   92.0   36.0  30.0  ...   \n",
      "9686   55.0  255.0   92.0  104.0  104.0  29.0   38.0  100.0  122.0  36.0  ...   \n",
      "9687   53.0  254.0  109.0   75.0  101.0  31.0   41.0   93.0   60.0  32.0  ...   \n",
      "9688   53.0  255.0  113.0   86.0   94.0  23.0   38.0   91.0   33.0  27.0  ...   \n",
      "9689   41.0  248.0  255.0   70.0   91.0  36.0   34.0   82.0  214.0  28.0  ...   \n",
      "\n",
      "       1264   2090  1815   1766    661   2122    409   1497    628  label  \n",
      "0     234.0  119.0  87.0   81.0   85.0  102.0   95.0  132.0  166.0      0  \n",
      "1     194.0  137.0  75.0   77.0   88.0  111.0   83.0  167.0  182.0      0  \n",
      "2     227.0  128.0  72.0   75.0   87.0  131.0  102.0  167.0  173.0      0  \n",
      "3     225.0  123.0  72.0   82.0   85.0  118.0  135.0  165.0  175.0      0  \n",
      "4     224.0  116.0  85.0  105.0   75.0  118.0   79.0  126.0  127.0      0  \n",
      "...     ...    ...   ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "9685   38.0   97.0  18.0   17.0   57.0   53.0  104.0   76.0  255.0      1  \n",
      "9686   60.0   81.0  17.0   17.0  119.0   77.0   98.0  109.0  255.0      1  \n",
      "9687   80.0   92.0  16.0   17.0   83.0   52.0   63.0   87.0  255.0      1  \n",
      "9688   58.0   89.0  15.0   15.0   22.0   47.0   83.0  118.0  192.0      1  \n",
      "9689   66.0   83.0  14.0   13.0   29.0   45.0  134.0  144.0  255.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "       1432     52   1733    637   1262    829  1388    280    635   1423  \\\n",
      "0      89.0   89.0   94.0  115.0  176.0  100.0  89.0  111.0  115.0  178.0   \n",
      "1      91.0   79.0  111.0  110.0  100.0  117.0  85.0   78.0  119.0  147.0   \n",
      "2      87.0   88.0  120.0  119.0  153.0   97.0  83.0   70.0  115.0  152.0   \n",
      "3      82.0   98.0  105.0  129.0  142.0   81.0  78.0   71.0  122.0  197.0   \n",
      "4     116.0   84.0  179.0  131.0  158.0  128.0  76.0   68.0  127.0  157.0   \n",
      "...     ...    ...    ...    ...    ...    ...   ...    ...    ...    ...   \n",
      "9685   42.0  199.0   43.0  255.0   20.0  208.0  38.0  232.0  201.0  102.0   \n",
      "9686   52.0  205.0   47.0  206.0   19.0  217.0  37.0   19.0  170.0   95.0   \n",
      "9687   37.0  255.0   38.0  255.0   17.0  251.0  31.0  105.0  255.0   87.0   \n",
      "9688   38.0  255.0   55.0   76.0   16.0   99.0  26.0   96.0  221.0   80.0   \n",
      "9689   25.0  255.0   82.0  254.0   15.0  102.0  85.0  169.0  255.0   80.0   \n",
      "\n",
      "      ...   2221  1773  1868    739    828   2022   1876   1609   1377  label  \n",
      "0     ...   88.0  77.0  80.0   83.0  109.0  117.0   83.0  234.0  151.0      1  \n",
      "1     ...   93.0  83.0  83.0   80.0  112.0  111.0  131.0  236.0  158.0      1  \n",
      "2     ...   88.0  81.0  85.0  115.0  112.0  104.0  118.0  234.0  153.0      1  \n",
      "3     ...   73.0  84.0  84.0  154.0  100.0   95.0  178.0  221.0  180.0      1  \n",
      "4     ...  139.0  77.0  72.0   77.0  131.0  114.0  121.0  209.0  132.0      1  \n",
      "...   ...    ...   ...   ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "9685  ...  104.0  35.0  37.0   19.0  226.0   30.0   57.0   37.0   19.0      1  \n",
      "9686  ...   99.0  40.0  39.0   18.0  165.0   21.0   57.0   46.0   20.0      1  \n",
      "9687  ...  101.0  33.0  30.0   17.0  212.0   20.0   32.0   38.0   21.0      1  \n",
      "9688  ...   95.0  37.0  34.0   16.0  226.0   22.0   37.0   26.0   20.0      1  \n",
      "9689  ...   91.0  23.0  39.0   15.0   81.0   21.0   59.0   40.0   17.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "       1997    166   335   1765   1780    845    281    638   1561    148  \\\n",
      "0     126.0  215.0  85.0   81.0   74.0  141.0  103.0  120.0  225.0   96.0   \n",
      "1     119.0  183.0  76.0   81.0  149.0  191.0   89.0  110.0  231.0   83.0   \n",
      "2     116.0  221.0  70.0   82.0  134.0  169.0   81.0  127.0  234.0  108.0   \n",
      "3     119.0  225.0  64.0   94.0  142.0  139.0   77.0  132.0  237.0  109.0   \n",
      "4     126.0  214.0  91.0  121.0  177.0  148.0   73.0  132.0  152.0  107.0   \n",
      "...     ...    ...   ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685   17.0  250.0  68.0   22.0   62.0   39.0  255.0  253.0   50.0  255.0   \n",
      "9686   16.0   26.0  17.0   21.0   48.0   24.0   21.0  153.0   41.0  255.0   \n",
      "9687   17.0  246.0  68.0   27.0   37.0   23.0  189.0  255.0   48.0  255.0   \n",
      "9688   16.0  220.0  74.0   25.0   45.0   18.0   80.0   31.0   36.0  255.0   \n",
      "9689   14.0   61.0  42.0   23.0   94.0   19.0  189.0  217.0   36.0   19.0   \n",
      "\n",
      "      ...    487    537   2293   1699   1023    136   284   1185    391  label  \n",
      "0     ...   80.0  109.0   94.0  101.0  153.0   98.0  71.0  168.0   81.0      1  \n",
      "1     ...  120.0  144.0   99.0   85.0   97.0   92.0  91.0  162.0   81.0      1  \n",
      "2     ...  118.0  143.0  103.0   95.0  156.0   89.0  90.0  175.0   73.0      1  \n",
      "3     ...  145.0  143.0  133.0   97.0  176.0   90.0  84.0  191.0   72.0      1  \n",
      "4     ...   75.0   81.0  103.0  164.0  110.0   84.0  97.0  144.0   92.0      1  \n",
      "...   ...    ...    ...    ...    ...    ...    ...   ...    ...    ...    ...  \n",
      "9685  ...  255.0  255.0   52.0  112.0   61.0  102.0  67.0   40.0  255.0      1  \n",
      "9686  ...  255.0  255.0   55.0  110.0   23.0   88.0  41.0   31.0  255.0      1  \n",
      "9687  ...  255.0  255.0   41.0  106.0   21.0  151.0  65.0   21.0   28.0      1  \n",
      "9688  ...  255.0  255.0   37.0   98.0   21.0  251.0  34.0   17.0  255.0      1  \n",
      "9689  ...  255.0  255.0   32.0   93.0   18.0   25.0  29.0   17.0  255.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "      1772    481   670   1212   2245   1465   2023   2246  1389    274  ...  \\\n",
      "0     80.0  112.0  72.0   74.0   91.0  172.0  132.0   83.0  91.0  204.0  ...   \n",
      "1     87.0  112.0  72.0  120.0  100.0  168.0  100.0   95.0  84.0  166.0  ...   \n",
      "2     85.0  125.0  71.0   81.0  103.0  171.0   93.0   97.0  83.0   88.0  ...   \n",
      "3     83.0  127.0  65.0   79.0  126.0  190.0   90.0  109.0  78.0   64.0  ...   \n",
      "4     77.0  109.0  65.0   79.0   97.0  176.0   85.0   96.0  77.0  208.0  ...   \n",
      "...    ...    ...   ...    ...    ...    ...    ...    ...   ...    ...  ...   \n",
      "9685  36.0  255.0  38.0  102.0   52.0   85.0   19.0   37.0  35.0  226.0  ...   \n",
      "9686  37.0  255.0  27.0   93.0   56.0   69.0   18.0   36.0  34.0  215.0  ...   \n",
      "9687  29.0  255.0  30.0   88.0   42.0   59.0   18.0   41.0  30.0  133.0  ...   \n",
      "9688  24.0  255.0  20.0  142.0   39.0   64.0   17.0   39.0  30.0  238.0  ...   \n",
      "9689  34.0  226.0  28.0   72.0   33.0   52.0   17.0   34.0  67.0  239.0  ...   \n",
      "\n",
      "      1243    777   2204  2156    684  1677    314  2011    541  label  \n",
      "0     87.0  107.0  103.0  97.0  105.0  80.0  188.0  79.0  121.0      1  \n",
      "1     90.0  137.0   84.0  80.0  107.0  90.0  177.0  79.0  145.0      1  \n",
      "2     89.0  126.0   75.0  75.0  117.0  90.0   98.0  79.0  139.0      1  \n",
      "3     86.0  140.0   68.0  71.0  128.0  88.0   77.0  76.0  141.0      1  \n",
      "4     79.0  145.0   71.0  70.0  133.0  79.0  196.0  71.0   89.0      1  \n",
      "...    ...    ...    ...   ...    ...   ...    ...   ...    ...    ...  \n",
      "9685  34.0  255.0   26.0  29.0  238.0  40.0  205.0  50.0  255.0      1  \n",
      "9686  39.0  202.0   29.0  30.0  204.0  36.0  191.0  54.0  255.0      1  \n",
      "9687  38.0  255.0   34.0  30.0  255.0  31.0   53.0  65.0  255.0      1  \n",
      "9688  47.0   58.0   23.0  24.0   24.0  28.0  253.0  65.0  164.0      1  \n",
      "9689  68.0  251.0   35.0  29.0  255.0  53.0  254.0  65.0  158.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "      1676   2039   2051    581   2272    491  1677  1674   1921   1148  ...  \\\n",
      "0     83.0  135.0  108.0  143.0   95.0   84.0  80.0  89.0  125.0   85.0  ...   \n",
      "1     91.0  137.0  113.0  170.0   84.0   99.0  90.0  86.0  142.0   93.0  ...   \n",
      "2     88.0  123.0  112.0  164.0   82.0  133.0  90.0  80.0  146.0  101.0  ...   \n",
      "3     84.0  147.0   98.0  164.0   78.0  151.0  88.0  76.0  143.0   92.0  ...   \n",
      "4     76.0  114.0  126.0  116.0  125.0   81.0  79.0  75.0  144.0   76.0  ...   \n",
      "...    ...    ...    ...    ...    ...    ...   ...   ...    ...    ...  ...   \n",
      "9685  39.0   33.0   62.0  255.0  104.0  255.0  40.0  33.0  101.0   32.0  ...   \n",
      "9686  39.0   18.0   23.0  255.0  102.0  255.0  36.0  47.0   41.0   41.0  ...   \n",
      "9687  36.0   27.0   65.0  253.0  101.0  168.0  31.0  36.0   54.0   36.0  ...   \n",
      "9688  23.0   25.0   51.0  255.0   96.0  255.0  28.0  26.0   45.0   94.0  ...   \n",
      "9689  45.0   31.0   60.0  254.0   90.0  224.0  53.0  43.0   56.0   35.0  ...   \n",
      "\n",
      "        348   910   2182    470   1474   1103    921   2066      7  label  \n",
      "0     225.0  82.0   90.0   95.0   90.0   94.0  109.0  126.0  119.0      1  \n",
      "1     168.0  73.0   84.0   97.0  141.0   80.0  137.0  136.0  107.0      1  \n",
      "2     106.0  72.0  103.0   94.0  104.0   84.0  137.0  124.0  109.0      1  \n",
      "3      86.0  73.0   96.0   76.0   84.0   87.0  147.0  128.0   96.0      1  \n",
      "4     212.0  69.0  134.0   97.0  193.0   73.0  157.0  153.0  109.0      1  \n",
      "...     ...   ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "9685  255.0  48.0   96.0  103.0   20.0   36.0  252.0   60.0  255.0      1  \n",
      "9686  255.0  47.0   49.0  170.0   20.0   49.0  207.0   38.0  254.0      1  \n",
      "9687   40.0  39.0   92.0  199.0   23.0   33.0  107.0   41.0  255.0      1  \n",
      "9688  255.0  35.0   88.0   35.0   21.0   70.0  255.0   38.0  255.0      1  \n",
      "9689  155.0  17.0   85.0   33.0   18.0  137.0   26.0   34.0  212.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "        464     74   1739   1361   1756    445   1874   1928    774     58  \\\n",
      "0      89.0  208.0   91.0  198.0  149.0  109.0  152.0  144.0  153.0  113.0   \n",
      "1     106.0  176.0  124.0  204.0  111.0   89.0  150.0  100.0  165.0   92.0   \n",
      "2     123.0  162.0  114.0  197.0  122.0  103.0  177.0  105.0  165.0  121.0   \n",
      "3     113.0  164.0  132.0  173.0   96.0  111.0  137.0   70.0  169.0  162.0   \n",
      "4      82.0  144.0  154.0  226.0  200.0   98.0  122.0   83.0  161.0  103.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  158.0   23.0   21.0  115.0   71.0  255.0   67.0   19.0  227.0  255.0   \n",
      "9686  203.0  255.0   29.0  111.0   80.0  255.0   58.0   18.0  228.0  134.0   \n",
      "9687   17.0  255.0   53.0  107.0   54.0   83.0   42.0   18.0  255.0  255.0   \n",
      "9688  119.0  103.0   23.0   99.0   42.0  253.0   47.0   16.0  253.0  236.0   \n",
      "9689  172.0   48.0   40.0   95.0   39.0  198.0   60.0   16.0  124.0   15.0   \n",
      "\n",
      "      ...   1921   1617  1865   1018   1909   811   1056   2054   615  label  \n",
      "0     ...  125.0  105.0  85.0  124.0   77.0  75.0  171.0   74.0  79.0      1  \n",
      "1     ...  142.0  106.0  84.0  114.0   91.0  77.0  118.0   94.0  78.0      1  \n",
      "2     ...  146.0   95.0  76.0  131.0   95.0  76.0  138.0   94.0  73.0      1  \n",
      "3     ...  143.0   95.0  73.0  139.0   99.0  76.0  136.0   95.0  76.0      1  \n",
      "4     ...  144.0  158.0  72.0  144.0  115.0  70.0  122.0  109.0  73.0      1  \n",
      "...   ...    ...    ...   ...    ...    ...   ...    ...    ...   ...    ...  \n",
      "9685  ...  101.0   93.0  55.0  246.0   16.0  46.0  108.0   67.0  60.0      1  \n",
      "9686  ...   41.0   89.0  58.0  144.0   16.0  44.0  255.0   26.0  57.0      1  \n",
      "9687  ...   54.0   84.0  26.0  113.0   16.0  21.0  202.0   77.0  27.0      1  \n",
      "9688  ...   45.0   77.0  24.0  252.0   15.0  19.0  255.0   59.0  28.0      1  \n",
      "9689  ...   56.0   77.0  21.0   28.0   13.0  18.0   98.0   65.0  28.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "       2216   1948   1778    966    935   1063    963   956    830    374  \\\n",
      "0      75.0  132.0  125.0  135.0  228.0  139.0   88.0  78.0   92.0   68.0   \n",
      "1      76.0  119.0  166.0   92.0  197.0  107.0  165.0  83.0  108.0   79.0   \n",
      "2      82.0  115.0  141.0   94.0  204.0  126.0  140.0  79.0   85.0   89.0   \n",
      "3      77.0  110.0  155.0   80.0  179.0   93.0  159.0  76.0   76.0  101.0   \n",
      "4     106.0  107.0  180.0  161.0  236.0   98.0  166.0  76.0  110.0   76.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...   ...    ...    ...   \n",
      "9685   40.0   18.0   78.0  191.0  112.0  150.0  185.0  42.0  172.0  109.0   \n",
      "9686   29.0   17.0   76.0  227.0  107.0  211.0  228.0  40.0  244.0  217.0   \n",
      "9687   31.0   16.0   58.0  154.0  102.0  109.0  221.0  39.0  255.0  240.0   \n",
      "9688   33.0   15.0   40.0  255.0   98.0  255.0  255.0  35.0  148.0  160.0   \n",
      "9689   32.0   13.0  143.0   17.0   93.0  243.0   20.0  17.0  208.0   60.0   \n",
      "\n",
      "      ...    965   1433   1734     41    972   1049   1095   719    967  label  \n",
      "0     ...  129.0   88.0  119.0   85.0  104.0  102.0  106.0  75.0  128.0      1  \n",
      "1     ...   78.0   89.0  102.0  103.0  120.0   93.0  101.0  73.0  116.0      1  \n",
      "2     ...   73.0   84.0  110.0  104.0   98.0   84.0   96.0  70.0  120.0      1  \n",
      "3     ...   83.0   78.0   87.0   94.0   86.0   83.0  116.0  67.0  102.0      1  \n",
      "4     ...  160.0  106.0  177.0  103.0   98.0   91.0   99.0  65.0  162.0      1  \n",
      "...   ...    ...    ...    ...    ...    ...    ...    ...   ...    ...    ...  \n",
      "9685  ...  185.0   36.0   42.0   28.0  255.0   40.0   48.0  28.0  185.0      1  \n",
      "9686  ...  220.0   34.0   60.0  100.0  176.0   48.0   43.0  44.0  171.0      1  \n",
      "9687  ...  173.0   36.0   60.0  253.0  115.0   50.0   37.0  32.0  142.0      1  \n",
      "9688  ...  255.0   54.0   56.0  242.0  222.0  100.0   93.0  13.0  255.0      1  \n",
      "9689  ...   17.0   21.0   99.0   97.0   43.0   50.0   62.0  52.0   14.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "       1382   1564   2290    314   2163   1948   1883   1013   1241   1835  \\\n",
      "0     107.0  230.0  105.0  188.0   92.0  132.0  104.0  125.0   91.0   99.0   \n",
      "1      95.0  235.0  142.0  177.0  103.0  119.0  127.0   83.0   95.0  125.0   \n",
      "2     104.0  235.0  144.0   98.0  112.0  115.0  120.0   76.0   88.0  117.0   \n",
      "3     104.0  233.0  114.0   77.0  106.0  110.0  139.0   90.0   80.0  136.0   \n",
      "4      73.0  164.0  108.0  196.0  143.0  107.0  145.0  108.0  106.0  149.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685   41.0   68.0  101.0  205.0   45.0   18.0   46.0  221.0   34.0   87.0   \n",
      "9686   40.0   61.0   98.0  191.0   36.0   17.0   80.0  229.0   39.0   89.0   \n",
      "9687   41.0   72.0   96.0   53.0   36.0   16.0   29.0  225.0   49.0  104.0   \n",
      "9688   35.0   76.0   90.0  253.0   38.0   15.0   32.0  255.0   99.0   89.0   \n",
      "9689   33.0   65.0   86.0  254.0   31.0   13.0   20.0   24.0   33.0   91.0   \n",
      "\n",
      "      ...  1535   1855   1806    531    213  1677    136    280    512  label  \n",
      "0     ...  90.0  134.0  143.0  139.0  212.0  80.0   98.0  111.0  118.0      1  \n",
      "1     ...  86.0  126.0  117.0  144.0  173.0  90.0   92.0   78.0  132.0      1  \n",
      "2     ...  84.0  123.0  116.0  149.0  213.0  90.0   89.0   70.0  120.0      1  \n",
      "3     ...  86.0  113.0  118.0  149.0  172.0  88.0   90.0   71.0  114.0      1  \n",
      "4     ...  80.0  131.0  166.0   97.0  190.0  79.0   84.0   68.0  100.0      1  \n",
      "...   ...   ...    ...    ...    ...    ...   ...    ...    ...    ...    ...  \n",
      "9685  ...  40.0   85.0   79.0  255.0  255.0  40.0  102.0  232.0  128.0      1  \n",
      "9686  ...  33.0  101.0   42.0  255.0   49.0  36.0   88.0   19.0  113.0      1  \n",
      "9687  ...  30.0   70.0   85.0  255.0  192.0  31.0  151.0  105.0   37.0      1  \n",
      "9688  ...  29.0   66.0   78.0  255.0  251.0  28.0  251.0   96.0  133.0      1  \n",
      "9689  ...  34.0   55.0   79.0  206.0   49.0  53.0   25.0  169.0   68.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "        425    237   2084    129   1491    461   1322    218   2192    884  \\\n",
      "0      98.0   72.0   97.0  166.0  181.0   89.0  148.0  179.0  155.0  228.0   \n",
      "1     107.0   75.0  117.0  229.0  182.0   96.0  169.0  200.0  119.0  207.0   \n",
      "2      96.0   74.0  124.0  230.0  176.0  132.0  126.0  186.0  115.0  195.0   \n",
      "3      76.0   81.0  122.0  215.0  174.0  128.0  133.0  143.0   99.0  146.0   \n",
      "4      70.0   91.0  103.0  226.0  114.0   76.0  137.0  190.0  116.0  182.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  130.0  133.0  101.0   31.0   68.0  173.0   45.0  255.0  100.0   56.0   \n",
      "9686   69.0  225.0   64.0   30.0   79.0  239.0   36.0   20.0   71.0   91.0   \n",
      "9687   90.0  124.0   97.0  244.0   71.0   64.0   21.0  159.0   94.0   90.0   \n",
      "9688   27.0   25.0   96.0  255.0  116.0  124.0   17.0  255.0   89.0   84.0   \n",
      "9689   56.0   36.0   89.0  108.0  255.0  103.0   16.0  104.0   86.0   82.0   \n",
      "\n",
      "      ...    375    211    829    628    927    115  1389    338    450  label  \n",
      "0     ...   72.0  182.0  100.0  166.0  105.0  188.0  91.0   84.0   93.0      1  \n",
      "1     ...   78.0  208.0  117.0  182.0   80.0  227.0  84.0   73.0   94.0      1  \n",
      "2     ...   91.0  174.0   97.0  173.0  110.0  156.0  83.0   88.0  108.0      1  \n",
      "3     ...  102.0  176.0   81.0  175.0  135.0  147.0  78.0  100.0  124.0      1  \n",
      "4     ...   70.0  161.0  128.0  127.0   81.0  177.0  77.0   90.0   82.0      1  \n",
      "...   ...    ...    ...    ...    ...    ...    ...   ...    ...    ...    ...  \n",
      "9685  ...  101.0  255.0  208.0  255.0  161.0  227.0  35.0  255.0  179.0      1  \n",
      "9686  ...  137.0   36.0  217.0  255.0  104.0   92.0  34.0  255.0  255.0      1  \n",
      "9687  ...  249.0  255.0  251.0  255.0   75.0  254.0  30.0  204.0  135.0      1  \n",
      "9688  ...   81.0  255.0   99.0  192.0   86.0  254.0  30.0  255.0  251.0      1  \n",
      "9689  ...   86.0   58.0  102.0  255.0   70.0   88.0  67.0  238.0   79.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "       1109    346     42    646    798   2256    492   1934   2170   1402  \\\n",
      "0     124.0  170.0   78.0   90.0   95.0   85.0   86.0  111.0   84.0  120.0   \n",
      "1      90.0  127.0   96.0   80.0  139.0   74.0  102.0  108.0   82.0  136.0   \n",
      "2      79.0  131.0   95.0   83.0  149.0   77.0  134.0   99.0   96.0  122.0   \n",
      "3      99.0   84.0   95.0  124.0  172.0   75.0  135.0  102.0   89.0  139.0   \n",
      "4     108.0  201.0   87.0  101.0   90.0  129.0   81.0   98.0  120.0  130.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  241.0  255.0   40.0   26.0   57.0   50.0  255.0   19.0   58.0  100.0   \n",
      "9686  169.0  254.0  104.0   62.0   80.0   43.0  255.0   19.0   53.0   87.0   \n",
      "9687  224.0   40.0  246.0   65.0   99.0   35.0  134.0   18.0   63.0   87.0   \n",
      "9688  255.0  254.0  189.0   71.0   61.0   33.0  214.0   16.0   58.0  130.0   \n",
      "9689  150.0  139.0   61.0   59.0   52.0   37.0  166.0   15.0   65.0   98.0   \n",
      "\n",
      "      ...     71   2176   1204    916    917   850  1679   2287   1855  label  \n",
      "0     ...  165.0   92.0  108.0  100.0  136.0  94.0  84.0  149.0  134.0      1  \n",
      "1     ...  192.0   94.0  123.0  118.0   87.0  78.0  80.0  104.0  126.0      1  \n",
      "2     ...  224.0  105.0  119.0  106.0   84.0  74.0  87.0   98.0  123.0      1  \n",
      "3     ...  236.0   93.0  111.0  122.0   78.0  79.0  88.0   95.0  113.0      1  \n",
      "4     ...  173.0  126.0  141.0  176.0  176.0  77.0  79.0   94.0  131.0      1  \n",
      "...   ...    ...    ...    ...    ...    ...   ...   ...    ...    ...    ...  \n",
      "9685  ...   27.0   84.0  153.0  184.0  157.0  50.0  39.0  100.0   85.0      0  \n",
      "9686  ...  247.0   36.0  189.0  254.0  247.0  67.0  34.0  100.0  101.0      0  \n",
      "9687  ...  217.0   89.0  210.0  190.0  163.0  54.0  27.0   94.0   70.0      0  \n",
      "9688  ...  204.0   83.0  255.0  255.0  255.0  10.0  37.0   89.0   66.0      0  \n",
      "9689  ...   48.0   88.0  255.0   78.0   43.0  66.0  23.0   85.0   55.0      0  \n",
      "\n",
      "[9690 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "xy0_20 = None\n",
    "for i in selected_features_per_class[0]:\n",
    "    xy0_20 = pd.concat([xy0_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy0_20 = pd.concat([xy0_20,ytrain0],axis=1)\n",
    "xy0_20 = xy0_20.rename(columns={xy0_20.columns[-1]:'label'})\n",
    "print(xy0_20)\n",
    "    \n",
    "xy1_20 = None\n",
    "for i in selected_features_per_class[1]:\n",
    "    xy1_20 = pd.concat([xy1_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy1_20 = pd.concat([xy1_20,ytrain1],axis=1)\n",
    "xy1_20 = xy1_20.rename(columns={xy1_20.columns[-1]:'label'})\n",
    "print(xy1_20)\n",
    "\n",
    "xy2_20 = None\n",
    "for i in selected_features_per_class[2]:\n",
    "    xy2_20 = pd.concat([xy2_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy2_20 = pd.concat([xy2_20,ytrain2],axis=1)\n",
    "xy2_20 = xy2_20.rename(columns={xy2_20.columns[-1]:'label'})\n",
    "print(xy2_20)\n",
    "\n",
    "xy3_20 = None\n",
    "for i in selected_features_per_class[3]:\n",
    "    xy3_20 = pd.concat([xy3_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy3_20 = pd.concat([xy3_20,ytrain3],axis=1)\n",
    "xy3_20 = xy3_20.rename(columns={xy3_20.columns[-1]:'label'})\n",
    "print(xy3_20)\n",
    "\n",
    "xy4_20 = None\n",
    "for i in selected_features_per_class[4]:\n",
    "    xy4_20 = pd.concat([xy4_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy4_20 = pd.concat([xy4_20,ytrain4],axis=1)\n",
    "xy4_20 = xy4_20.rename(columns={xy4_20.columns[-1]:'label'})\n",
    "print(xy4_20)\n",
    "\n",
    "xy5_20 = None\n",
    "for i in selected_features_per_class[5]:\n",
    "    xy5_20 = pd.concat([xy5_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy5_20 = pd.concat([xy5_20,ytrain5],axis=1)\n",
    "xy5_20 = xy5_20.rename(columns={xy5_20.columns[-1]:'label'})\n",
    "print(xy5_20)\n",
    "\n",
    "xy6_20 = None\n",
    "for i in selected_features_per_class[6]:\n",
    "    xy6_20 = pd.concat([xy6_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy6_20 = pd.concat([xy6_20,ytrain6],axis=1)\n",
    "xy6_20 = xy6_20.rename(columns={xy6_20.columns[-1]:'label'})\n",
    "print(xy6_20)\n",
    "\n",
    "xy7_20 = None\n",
    "for i in selected_features_per_class[7]:\n",
    "    xy7_20 = pd.concat([xy7_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy7_20 = pd.concat([xy7_20,ytrain7],axis=1)\n",
    "xy7_20 = xy7_20.rename(columns={xy7_20.columns[-1]:'label'})\n",
    "print(xy7_20)\n",
    "\n",
    "xy8_20 = None\n",
    "for i in selected_features_per_class[8]:\n",
    "    xy8_20 = pd.concat([xy8_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy8_20 = pd.concat([xy8_20,ytrain8],axis=1)\n",
    "xy8_20 = xy8_20.rename(columns={xy8_20.columns[-1]:'label'})\n",
    "print(xy8_20)\n",
    "\n",
    "xy9_20 = None\n",
    "for i in selected_features_per_class[9]:\n",
    "    xy9_20 = pd.concat([xy9_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy9_20 = pd.concat([xy9_20,ytrain9],axis=1)\n",
    "xy9_20 = xy9_20.rename(columns={xy9_20.columns[-1]:'label'})\n",
    "print(xy9_20)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1605    490   1536    927    742  1966   2066   2235    239  1869  \\\n",
      "0     219.0   83.0  184.0  105.0  103.0  82.0  126.0   98.0   77.0  79.0   \n",
      "1     185.0   97.0  187.0   80.0  123.0  80.0  136.0  125.0   71.0  79.0   \n",
      "2     204.0  129.0  182.0  110.0  196.0  76.0  124.0  109.0   68.0  79.0   \n",
      "3     185.0  148.0  184.0  135.0  235.0  77.0  128.0  111.0   64.0  80.0   \n",
      "4     175.0   80.0  107.0   81.0   78.0  77.0  153.0  119.0   83.0  75.0   \n",
      "...     ...    ...    ...    ...    ...   ...    ...    ...    ...   ...   \n",
      "9685   54.0  255.0  222.0  161.0   96.0  29.0   60.0   92.0   36.0  30.0   \n",
      "9686   55.0  255.0   92.0  104.0  104.0  29.0   38.0  100.0  122.0  36.0   \n",
      "9687   53.0  254.0  109.0   75.0  101.0  31.0   41.0   93.0   60.0  32.0   \n",
      "9688   53.0  255.0  113.0   86.0   94.0  23.0   38.0   91.0   33.0  27.0   \n",
      "9689   41.0  248.0  255.0   70.0   91.0  36.0   34.0   82.0  214.0  28.0   \n",
      "\n",
      "      label  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "       1432     52   1733    637   1262    829  1388    280    635   1423  \\\n",
      "0      89.0   89.0   94.0  115.0  176.0  100.0  89.0  111.0  115.0  178.0   \n",
      "1      91.0   79.0  111.0  110.0  100.0  117.0  85.0   78.0  119.0  147.0   \n",
      "2      87.0   88.0  120.0  119.0  153.0   97.0  83.0   70.0  115.0  152.0   \n",
      "3      82.0   98.0  105.0  129.0  142.0   81.0  78.0   71.0  122.0  197.0   \n",
      "4     116.0   84.0  179.0  131.0  158.0  128.0  76.0   68.0  127.0  157.0   \n",
      "...     ...    ...    ...    ...    ...    ...   ...    ...    ...    ...   \n",
      "9685   42.0  199.0   43.0  255.0   20.0  208.0  38.0  232.0  201.0  102.0   \n",
      "9686   52.0  205.0   47.0  206.0   19.0  217.0  37.0   19.0  170.0   95.0   \n",
      "9687   37.0  255.0   38.0  255.0   17.0  251.0  31.0  105.0  255.0   87.0   \n",
      "9688   38.0  255.0   55.0   76.0   16.0   99.0  26.0   96.0  221.0   80.0   \n",
      "9689   25.0  255.0   82.0  254.0   15.0  102.0  85.0  169.0  255.0   80.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "       1997    166   335   1765   1780    845    281    638   1561    148  \\\n",
      "0     126.0  215.0  85.0   81.0   74.0  141.0  103.0  120.0  225.0   96.0   \n",
      "1     119.0  183.0  76.0   81.0  149.0  191.0   89.0  110.0  231.0   83.0   \n",
      "2     116.0  221.0  70.0   82.0  134.0  169.0   81.0  127.0  234.0  108.0   \n",
      "3     119.0  225.0  64.0   94.0  142.0  139.0   77.0  132.0  237.0  109.0   \n",
      "4     126.0  214.0  91.0  121.0  177.0  148.0   73.0  132.0  152.0  107.0   \n",
      "...     ...    ...   ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685   17.0  250.0  68.0   22.0   62.0   39.0  255.0  253.0   50.0  255.0   \n",
      "9686   16.0   26.0  17.0   21.0   48.0   24.0   21.0  153.0   41.0  255.0   \n",
      "9687   17.0  246.0  68.0   27.0   37.0   23.0  189.0  255.0   48.0  255.0   \n",
      "9688   16.0  220.0  74.0   25.0   45.0   18.0   80.0   31.0   36.0  255.0   \n",
      "9689   14.0   61.0  42.0   23.0   94.0   19.0  189.0  217.0   36.0   19.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "      1772    481   670   1212   2245   1465   2023   2246  1389    274  label\n",
      "0     80.0  112.0  72.0   74.0   91.0  172.0  132.0   83.0  91.0  204.0      1\n",
      "1     87.0  112.0  72.0  120.0  100.0  168.0  100.0   95.0  84.0  166.0      1\n",
      "2     85.0  125.0  71.0   81.0  103.0  171.0   93.0   97.0  83.0   88.0      1\n",
      "3     83.0  127.0  65.0   79.0  126.0  190.0   90.0  109.0  78.0   64.0      1\n",
      "4     77.0  109.0  65.0   79.0   97.0  176.0   85.0   96.0  77.0  208.0      1\n",
      "...    ...    ...   ...    ...    ...    ...    ...    ...   ...    ...    ...\n",
      "9685  36.0  255.0  38.0  102.0   52.0   85.0   19.0   37.0  35.0  226.0      1\n",
      "9686  37.0  255.0  27.0   93.0   56.0   69.0   18.0   36.0  34.0  215.0      1\n",
      "9687  29.0  255.0  30.0   88.0   42.0   59.0   18.0   41.0  30.0  133.0      1\n",
      "9688  24.0  255.0  20.0  142.0   39.0   64.0   17.0   39.0  30.0  238.0      1\n",
      "9689  34.0  226.0  28.0   72.0   33.0   52.0   17.0   34.0  67.0  239.0      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "      1676   2039   2051    581   2272    491  1677  1674   1921   1148  label\n",
      "0     83.0  135.0  108.0  143.0   95.0   84.0  80.0  89.0  125.0   85.0      1\n",
      "1     91.0  137.0  113.0  170.0   84.0   99.0  90.0  86.0  142.0   93.0      1\n",
      "2     88.0  123.0  112.0  164.0   82.0  133.0  90.0  80.0  146.0  101.0      1\n",
      "3     84.0  147.0   98.0  164.0   78.0  151.0  88.0  76.0  143.0   92.0      1\n",
      "4     76.0  114.0  126.0  116.0  125.0   81.0  79.0  75.0  144.0   76.0      1\n",
      "...    ...    ...    ...    ...    ...    ...   ...   ...    ...    ...    ...\n",
      "9685  39.0   33.0   62.0  255.0  104.0  255.0  40.0  33.0  101.0   32.0      1\n",
      "9686  39.0   18.0   23.0  255.0  102.0  255.0  36.0  47.0   41.0   41.0      1\n",
      "9687  36.0   27.0   65.0  253.0  101.0  168.0  31.0  36.0   54.0   36.0      1\n",
      "9688  23.0   25.0   51.0  255.0   96.0  255.0  28.0  26.0   45.0   94.0      1\n",
      "9689  45.0   31.0   60.0  254.0   90.0  224.0  53.0  43.0   56.0   35.0      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "        464     74   1739   1361   1756    445   1874   1928    774     58  \\\n",
      "0      89.0  208.0   91.0  198.0  149.0  109.0  152.0  144.0  153.0  113.0   \n",
      "1     106.0  176.0  124.0  204.0  111.0   89.0  150.0  100.0  165.0   92.0   \n",
      "2     123.0  162.0  114.0  197.0  122.0  103.0  177.0  105.0  165.0  121.0   \n",
      "3     113.0  164.0  132.0  173.0   96.0  111.0  137.0   70.0  169.0  162.0   \n",
      "4      82.0  144.0  154.0  226.0  200.0   98.0  122.0   83.0  161.0  103.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  158.0   23.0   21.0  115.0   71.0  255.0   67.0   19.0  227.0  255.0   \n",
      "9686  203.0  255.0   29.0  111.0   80.0  255.0   58.0   18.0  228.0  134.0   \n",
      "9687   17.0  255.0   53.0  107.0   54.0   83.0   42.0   18.0  255.0  255.0   \n",
      "9688  119.0  103.0   23.0   99.0   42.0  253.0   47.0   16.0  253.0  236.0   \n",
      "9689  172.0   48.0   40.0   95.0   39.0  198.0   60.0   16.0  124.0   15.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "       2216   1948   1778    966    935   1063    963   956    830    374  \\\n",
      "0      75.0  132.0  125.0  135.0  228.0  139.0   88.0  78.0   92.0   68.0   \n",
      "1      76.0  119.0  166.0   92.0  197.0  107.0  165.0  83.0  108.0   79.0   \n",
      "2      82.0  115.0  141.0   94.0  204.0  126.0  140.0  79.0   85.0   89.0   \n",
      "3      77.0  110.0  155.0   80.0  179.0   93.0  159.0  76.0   76.0  101.0   \n",
      "4     106.0  107.0  180.0  161.0  236.0   98.0  166.0  76.0  110.0   76.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...   ...    ...    ...   \n",
      "9685   40.0   18.0   78.0  191.0  112.0  150.0  185.0  42.0  172.0  109.0   \n",
      "9686   29.0   17.0   76.0  227.0  107.0  211.0  228.0  40.0  244.0  217.0   \n",
      "9687   31.0   16.0   58.0  154.0  102.0  109.0  221.0  39.0  255.0  240.0   \n",
      "9688   33.0   15.0   40.0  255.0   98.0  255.0  255.0  35.0  148.0  160.0   \n",
      "9689   32.0   13.0  143.0   17.0   93.0  243.0   20.0  17.0  208.0   60.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "       1382   1564   2290    314   2163   1948   1883   1013   1241   1835  \\\n",
      "0     107.0  230.0  105.0  188.0   92.0  132.0  104.0  125.0   91.0   99.0   \n",
      "1      95.0  235.0  142.0  177.0  103.0  119.0  127.0   83.0   95.0  125.0   \n",
      "2     104.0  235.0  144.0   98.0  112.0  115.0  120.0   76.0   88.0  117.0   \n",
      "3     104.0  233.0  114.0   77.0  106.0  110.0  139.0   90.0   80.0  136.0   \n",
      "4      73.0  164.0  108.0  196.0  143.0  107.0  145.0  108.0  106.0  149.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685   41.0   68.0  101.0  205.0   45.0   18.0   46.0  221.0   34.0   87.0   \n",
      "9686   40.0   61.0   98.0  191.0   36.0   17.0   80.0  229.0   39.0   89.0   \n",
      "9687   41.0   72.0   96.0   53.0   36.0   16.0   29.0  225.0   49.0  104.0   \n",
      "9688   35.0   76.0   90.0  253.0   38.0   15.0   32.0  255.0   99.0   89.0   \n",
      "9689   33.0   65.0   86.0  254.0   31.0   13.0   20.0   24.0   33.0   91.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "        425    237   2084    129   1491    461   1322    218   2192    884  \\\n",
      "0      98.0   72.0   97.0  166.0  181.0   89.0  148.0  179.0  155.0  228.0   \n",
      "1     107.0   75.0  117.0  229.0  182.0   96.0  169.0  200.0  119.0  207.0   \n",
      "2      96.0   74.0  124.0  230.0  176.0  132.0  126.0  186.0  115.0  195.0   \n",
      "3      76.0   81.0  122.0  215.0  174.0  128.0  133.0  143.0   99.0  146.0   \n",
      "4      70.0   91.0  103.0  226.0  114.0   76.0  137.0  190.0  116.0  182.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  130.0  133.0  101.0   31.0   68.0  173.0   45.0  255.0  100.0   56.0   \n",
      "9686   69.0  225.0   64.0   30.0   79.0  239.0   36.0   20.0   71.0   91.0   \n",
      "9687   90.0  124.0   97.0  244.0   71.0   64.0   21.0  159.0   94.0   90.0   \n",
      "9688   27.0   25.0   96.0  255.0  116.0  124.0   17.0  255.0   89.0   84.0   \n",
      "9689   56.0   36.0   89.0  108.0  255.0  103.0   16.0  104.0   86.0   82.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "       1109    346     42    646    798   2256    492   1934   2170   1402  \\\n",
      "0     124.0  170.0   78.0   90.0   95.0   85.0   86.0  111.0   84.0  120.0   \n",
      "1      90.0  127.0   96.0   80.0  139.0   74.0  102.0  108.0   82.0  136.0   \n",
      "2      79.0  131.0   95.0   83.0  149.0   77.0  134.0   99.0   96.0  122.0   \n",
      "3      99.0   84.0   95.0  124.0  172.0   75.0  135.0  102.0   89.0  139.0   \n",
      "4     108.0  201.0   87.0  101.0   90.0  129.0   81.0   98.0  120.0  130.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  241.0  255.0   40.0   26.0   57.0   50.0  255.0   19.0   58.0  100.0   \n",
      "9686  169.0  254.0  104.0   62.0   80.0   43.0  255.0   19.0   53.0   87.0   \n",
      "9687  224.0   40.0  246.0   65.0   99.0   35.0  134.0   18.0   63.0   87.0   \n",
      "9688  255.0  254.0  189.0   71.0   61.0   33.0  214.0   16.0   58.0  130.0   \n",
      "9689  150.0  139.0   61.0   59.0   52.0   37.0  166.0   15.0   65.0   98.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      0  \n",
      "9686      0  \n",
      "9687      0  \n",
      "9688      0  \n",
      "9689      0  \n",
      "\n",
      "[9690 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "xy0_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[0]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy0_10 = pd.concat([xy0_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy0_10 = pd.concat([xy0_10,ytrain0],axis=1)\n",
    "xy0_10 = xy0_10.rename(columns={xy0_10.columns[-1]:'label'})\n",
    "print(xy0_10)\n",
    "    \n",
    "xy1_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[1]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy1_10 = pd.concat([xy1_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy1_10 = pd.concat([xy1_10,ytrain1],axis=1)\n",
    "xy1_10 = xy1_10.rename(columns={xy1_10.columns[-1]:'label'})\n",
    "print(xy1_10)\n",
    "\n",
    "xy2_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[2]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy2_10 = pd.concat([xy2_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy2_10 = pd.concat([xy2_10,ytrain2],axis=1)\n",
    "xy2_10 = xy2_10.rename(columns={xy2_10.columns[-1]:'label'})\n",
    "print(xy2_10)\n",
    "\n",
    "xy3_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[3]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy3_10 = pd.concat([xy3_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy3_10 = pd.concat([xy3_10,ytrain3],axis=1)\n",
    "xy3_10 = xy3_10.rename(columns={xy3_10.columns[-1]:'label'})\n",
    "print(xy3_10)\n",
    "\n",
    "xy4_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[4]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy4_10 = pd.concat([xy4_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy4_10 = pd.concat([xy4_10,ytrain4],axis=1)\n",
    "xy4_10 = xy4_10.rename(columns={xy4_10.columns[-1]:'label'})\n",
    "print(xy4_10)\n",
    "\n",
    "xy5_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[5]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy5_10 = pd.concat([xy5_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy5_10 = pd.concat([xy5_10,ytrain5],axis=1)\n",
    "xy5_10 = xy5_10.rename(columns={xy5_10.columns[-1]:'label'})\n",
    "print(xy5_10)\n",
    "\n",
    "xy6_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[6]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy6_10 = pd.concat([xy6_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy6_10 = pd.concat([xy6_10,ytrain6],axis=1)\n",
    "xy6_10 = xy6_10.rename(columns={xy6_10.columns[-1]:'label'})\n",
    "print(xy6_10)\n",
    "\n",
    "xy7_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[7]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy7_10 = pd.concat([xy7_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy7_10 = pd.concat([xy7_10,ytrain7],axis=1)\n",
    "xy7_10 = xy7_10.rename(columns={xy7_10.columns[-1]:'label'})\n",
    "print(xy7_10)\n",
    "\n",
    "xy8_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[8]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy8_10 = pd.concat([xy8_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy8_10 = pd.concat([xy8_10,ytrain8],axis=1)\n",
    "xy8_10 = xy8_10.rename(columns={xy8_10.columns[-1]:'label'})\n",
    "print(xy8_10)\n",
    "\n",
    "xy9_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[9]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy9_10 = pd.concat([xy9_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy9_10 = pd.concat([xy9_10,ytrain9],axis=1)\n",
    "xy9_10 = xy9_10.rename(columns={xy9_10.columns[-1]:'label'})\n",
    "print(xy9_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1605    490   1536    927    742  label\n",
      "0     219.0   83.0  184.0  105.0  103.0      0\n",
      "1     185.0   97.0  187.0   80.0  123.0      0\n",
      "2     204.0  129.0  182.0  110.0  196.0      0\n",
      "3     185.0  148.0  184.0  135.0  235.0      0\n",
      "4     175.0   80.0  107.0   81.0   78.0      0\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685   54.0  255.0  222.0  161.0   96.0      1\n",
      "9686   55.0  255.0   92.0  104.0  104.0      1\n",
      "9687   53.0  254.0  109.0   75.0  101.0      1\n",
      "9688   53.0  255.0  113.0   86.0   94.0      1\n",
      "9689   41.0  248.0  255.0   70.0   91.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "       1432     52   1733    637   1262  label\n",
      "0      89.0   89.0   94.0  115.0  176.0      1\n",
      "1      91.0   79.0  111.0  110.0  100.0      1\n",
      "2      87.0   88.0  120.0  119.0  153.0      1\n",
      "3      82.0   98.0  105.0  129.0  142.0      1\n",
      "4     116.0   84.0  179.0  131.0  158.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685   42.0  199.0   43.0  255.0   20.0      1\n",
      "9686   52.0  205.0   47.0  206.0   19.0      1\n",
      "9687   37.0  255.0   38.0  255.0   17.0      1\n",
      "9688   38.0  255.0   55.0   76.0   16.0      1\n",
      "9689   25.0  255.0   82.0  254.0   15.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "       1997    166   335   1765   1780  label\n",
      "0     126.0  215.0  85.0   81.0   74.0      1\n",
      "1     119.0  183.0  76.0   81.0  149.0      1\n",
      "2     116.0  221.0  70.0   82.0  134.0      1\n",
      "3     119.0  225.0  64.0   94.0  142.0      1\n",
      "4     126.0  214.0  91.0  121.0  177.0      1\n",
      "...     ...    ...   ...    ...    ...    ...\n",
      "9685   17.0  250.0  68.0   22.0   62.0      1\n",
      "9686   16.0   26.0  17.0   21.0   48.0      1\n",
      "9687   17.0  246.0  68.0   27.0   37.0      1\n",
      "9688   16.0  220.0  74.0   25.0   45.0      1\n",
      "9689   14.0   61.0  42.0   23.0   94.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "      1772    481   670   1212   2245  label\n",
      "0     80.0  112.0  72.0   74.0   91.0      1\n",
      "1     87.0  112.0  72.0  120.0  100.0      1\n",
      "2     85.0  125.0  71.0   81.0  103.0      1\n",
      "3     83.0  127.0  65.0   79.0  126.0      1\n",
      "4     77.0  109.0  65.0   79.0   97.0      1\n",
      "...    ...    ...   ...    ...    ...    ...\n",
      "9685  36.0  255.0  38.0  102.0   52.0      1\n",
      "9686  37.0  255.0  27.0   93.0   56.0      1\n",
      "9687  29.0  255.0  30.0   88.0   42.0      1\n",
      "9688  24.0  255.0  20.0  142.0   39.0      1\n",
      "9689  34.0  226.0  28.0   72.0   33.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "      1676   2039   2051    581   2272  label\n",
      "0     83.0  135.0  108.0  143.0   95.0      1\n",
      "1     91.0  137.0  113.0  170.0   84.0      1\n",
      "2     88.0  123.0  112.0  164.0   82.0      1\n",
      "3     84.0  147.0   98.0  164.0   78.0      1\n",
      "4     76.0  114.0  126.0  116.0  125.0      1\n",
      "...    ...    ...    ...    ...    ...    ...\n",
      "9685  39.0   33.0   62.0  255.0  104.0      1\n",
      "9686  39.0   18.0   23.0  255.0  102.0      1\n",
      "9687  36.0   27.0   65.0  253.0  101.0      1\n",
      "9688  23.0   25.0   51.0  255.0   96.0      1\n",
      "9689  45.0   31.0   60.0  254.0   90.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "        464     74   1739   1361   1756  label\n",
      "0      89.0  208.0   91.0  198.0  149.0      1\n",
      "1     106.0  176.0  124.0  204.0  111.0      1\n",
      "2     123.0  162.0  114.0  197.0  122.0      1\n",
      "3     113.0  164.0  132.0  173.0   96.0      1\n",
      "4      82.0  144.0  154.0  226.0  200.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685  158.0   23.0   21.0  115.0   71.0      1\n",
      "9686  203.0  255.0   29.0  111.0   80.0      1\n",
      "9687   17.0  255.0   53.0  107.0   54.0      1\n",
      "9688  119.0  103.0   23.0   99.0   42.0      1\n",
      "9689  172.0   48.0   40.0   95.0   39.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "       2216   1948   1778    966    935  label\n",
      "0      75.0  132.0  125.0  135.0  228.0      1\n",
      "1      76.0  119.0  166.0   92.0  197.0      1\n",
      "2      82.0  115.0  141.0   94.0  204.0      1\n",
      "3      77.0  110.0  155.0   80.0  179.0      1\n",
      "4     106.0  107.0  180.0  161.0  236.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685   40.0   18.0   78.0  191.0  112.0      1\n",
      "9686   29.0   17.0   76.0  227.0  107.0      1\n",
      "9687   31.0   16.0   58.0  154.0  102.0      1\n",
      "9688   33.0   15.0   40.0  255.0   98.0      1\n",
      "9689   32.0   13.0  143.0   17.0   93.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "       1382   1564   2290    314   2163  label\n",
      "0     107.0  230.0  105.0  188.0   92.0      1\n",
      "1      95.0  235.0  142.0  177.0  103.0      1\n",
      "2     104.0  235.0  144.0   98.0  112.0      1\n",
      "3     104.0  233.0  114.0   77.0  106.0      1\n",
      "4      73.0  164.0  108.0  196.0  143.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685   41.0   68.0  101.0  205.0   45.0      1\n",
      "9686   40.0   61.0   98.0  191.0   36.0      1\n",
      "9687   41.0   72.0   96.0   53.0   36.0      1\n",
      "9688   35.0   76.0   90.0  253.0   38.0      1\n",
      "9689   33.0   65.0   86.0  254.0   31.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "        425    237   2084    129   1491  label\n",
      "0      98.0   72.0   97.0  166.0  181.0      1\n",
      "1     107.0   75.0  117.0  229.0  182.0      1\n",
      "2      96.0   74.0  124.0  230.0  176.0      1\n",
      "3      76.0   81.0  122.0  215.0  174.0      1\n",
      "4      70.0   91.0  103.0  226.0  114.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685  130.0  133.0  101.0   31.0   68.0      1\n",
      "9686   69.0  225.0   64.0   30.0   79.0      1\n",
      "9687   90.0  124.0   97.0  244.0   71.0      1\n",
      "9688   27.0   25.0   96.0  255.0  116.0      1\n",
      "9689   56.0   36.0   89.0  108.0  255.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "       1109    346     42    646    798  label\n",
      "0     124.0  170.0   78.0   90.0   95.0      1\n",
      "1      90.0  127.0   96.0   80.0  139.0      1\n",
      "2      79.0  131.0   95.0   83.0  149.0      1\n",
      "3      99.0   84.0   95.0  124.0  172.0      1\n",
      "4     108.0  201.0   87.0  101.0   90.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685  241.0  255.0   40.0   26.0   57.0      0\n",
      "9686  169.0  254.0  104.0   62.0   80.0      0\n",
      "9687  224.0   40.0  246.0   65.0   99.0      0\n",
      "9688  255.0  254.0  189.0   71.0   61.0      0\n",
      "9689  150.0  139.0   61.0   59.0   52.0      0\n",
      "\n",
      "[9690 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "xy0_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[0]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy0_5 = pd.concat([xy0_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy0_5 = pd.concat([xy0_5,ytrain0],axis=1)\n",
    "xy0_5 = xy0_5.rename(columns={xy0_5.columns[-1]:'label'})\n",
    "print(xy0_5)\n",
    "    \n",
    "xy1_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[1]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy1_5 = pd.concat([xy1_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy1_5 = pd.concat([xy1_5,ytrain1],axis=1)\n",
    "xy1_5 = xy1_5.rename(columns={xy1_5.columns[-1]:'label'})\n",
    "print(xy1_5)\n",
    "\n",
    "xy2_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[2]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy2_5 = pd.concat([xy2_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy2_5 = pd.concat([xy2_5,ytrain2],axis=1)\n",
    "xy2_5 = xy2_5.rename(columns={xy2_5.columns[-1]:'label'})\n",
    "print(xy2_5)\n",
    "\n",
    "xy3_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[3]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy3_5 = pd.concat([xy3_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy3_5 = pd.concat([xy3_5,ytrain3],axis=1)\n",
    "xy3_5 = xy3_5.rename(columns={xy3_5.columns[-1]:'label'})\n",
    "print(xy3_5)\n",
    "\n",
    "xy4_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[4]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy4_5 = pd.concat([xy4_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy4_5 = pd.concat([xy4_5,ytrain4],axis=1)\n",
    "xy4_5 = xy4_5.rename(columns={xy4_5.columns[-1]:'label'})\n",
    "print(xy4_5)\n",
    "\n",
    "xy5_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[5]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy5_5 = pd.concat([xy5_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy5_5 = pd.concat([xy5_5,ytrain5],axis=1)\n",
    "xy5_5 = xy5_5.rename(columns={xy5_5.columns[-1]:'label'})\n",
    "print(xy5_5)\n",
    "\n",
    "xy6_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[6]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy6_5 = pd.concat([xy6_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy6_5 = pd.concat([xy6_5,ytrain6],axis=1)\n",
    "xy6_5 = xy6_5.rename(columns={xy6_5.columns[-1]:'label'})\n",
    "print(xy6_5)\n",
    "\n",
    "xy7_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[7]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy7_5 = pd.concat([xy7_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy7_5 = pd.concat([xy7_5,ytrain7],axis=1)\n",
    "xy7_5 = xy7_5.rename(columns={xy7_5.columns[-1]:'label'})\n",
    "print(xy7_5)\n",
    "\n",
    "xy8_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[8]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy8_5 = pd.concat([xy8_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy8_5 = pd.concat([xy8_5,ytrain8],axis=1)\n",
    "xy8_5 = xy8_5.rename(columns={xy8_5.columns[-1]:'label'})\n",
    "print(xy8_5)\n",
    "\n",
    "xy9_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[9]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy9_5 = pd.concat([xy9_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy9_5 = pd.concat([xy9_5,ytrain9],axis=1)\n",
    "xy9_5 = xy9_5.rename(columns={xy9_5.columns[-1]:'label'})\n",
    "print(xy9_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9685    1\n",
       "9686    1\n",
       "9687    1\n",
       "9688    1\n",
       "9689    1\n",
       "Name: label, Length: 9690, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=xy0_5['label']\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1605</th>\n",
       "      <th>490</th>\n",
       "      <th>1536</th>\n",
       "      <th>927</th>\n",
       "      <th>742</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>219.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>185.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9685</th>\n",
       "      <td>54.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9686</th>\n",
       "      <td>55.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9687</th>\n",
       "      <td>53.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9688</th>\n",
       "      <td>53.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9689</th>\n",
       "      <td>41.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9690 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1605    490   1536    927    742  label\n",
       "0     219.0   83.0  184.0  105.0  103.0      0\n",
       "1     185.0   97.0  187.0   80.0  123.0      0\n",
       "2     204.0  129.0  182.0  110.0  196.0      0\n",
       "3     185.0  148.0  184.0  135.0  235.0      0\n",
       "4     175.0   80.0  107.0   81.0   78.0      0\n",
       "...     ...    ...    ...    ...    ...    ...\n",
       "9685   54.0  255.0  222.0  161.0   96.0      1\n",
       "9686   55.0  255.0   92.0  104.0  104.0      1\n",
       "9687   53.0  254.0  109.0   75.0  101.0      1\n",
       "9688   53.0  255.0  113.0   86.0   94.0      1\n",
       "9689   41.0  248.0  255.0   70.0   91.0      1\n",
       "\n",
       "[9690 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy0_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "seed_value = 22\n",
    "processed_df = xy9_20.drop(columns=['label'])\n",
    "y_train = xy9_20['label']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(processed_df, y_train, test_size=0.3, random_state=seed_value)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train, Y_train)\n",
    "\n",
    "predicted = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9267285861713106\n",
      "F1 Score: 0.9144435925616496\n",
      "Confusion Matrix:\n",
      " [[  12  148]\n",
      " [  65 2682]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(predicted, Y_test)\n",
    "f1 = f1_score(predicted, Y_test, average=\"weighted\")\n",
    "conf_matrix = confusion_matrix(predicted, Y_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=xy0_5['label']\n",
    "processed_df=xy0_5.drop(columns=['label'])\n",
    "naive_bayes_search(processed_df,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current Data frame is:  0\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "The current Data frame is:  1\n",
      "Accuracy: 0.7206742346061231\n",
      "F1 Score: 0.7282272614049545\n",
      "Precision: 0.7071068742350334\n",
      "Recall/Sensitivity/True Positive Rate: 0.7206742346061231\n",
      "Confusion Matrix:\n",
      " [[ 232  358]\n",
      " [ 454 1863]]\n",
      "\n",
      "\n",
      "The current Data frame is:  2\n",
      "Accuracy: 0.760921912624699\n",
      "F1 Score: 0.8204924612426809\n",
      "Precision: 0.696758798358478\n",
      "Recall/Sensitivity/True Positive Rate: 0.760921912624699\n",
      "Confusion Matrix:\n",
      " [[  68   99]\n",
      " [ 596 2144]]\n",
      "\n",
      "\n",
      "The current Data frame is:  3\n",
      "Accuracy: 0.8582731338149295\n",
      "F1 Score: 0.8878519519945112\n",
      "Precision: 0.8259810945105907\n",
      "Recall/Sensitivity/True Positive Rate: 0.8582731338149295\n",
      "Confusion Matrix:\n",
      " [[  80   72]\n",
      " [ 340 2415]]\n",
      "\n",
      "\n",
      "The current Data frame is:  4\n",
      "Accuracy: 0.6130030959752322\n",
      "F1 Score: 0.5745084899556268\n",
      "Precision: 0.7621563059023773\n",
      "Recall/Sensitivity/True Positive Rate: 0.6130030959752322\n",
      "Confusion Matrix:\n",
      " [[ 392  934]\n",
      " [ 191 1390]]\n",
      "\n",
      "\n",
      "The current Data frame is:  5\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "The current Data frame is:  6\n",
      "Accuracy: 0.9642242862057103\n",
      "F1 Score: 0.9817863397548159\n",
      "Precision: 0.9655041879032012\n",
      "Recall/Sensitivity/True Positive Rate: 0.9642242862057103\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [ 104 2803]]\n",
      "\n",
      "\n",
      "The current Data frame is:  7\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "The current Data frame is:  8\n",
      "Accuracy: 0.9215686274509803\n",
      "F1 Score: 0.9411570087091911\n",
      "Precision: 0.8844252888808979\n",
      "Recall/Sensitivity/True Positive Rate: 0.9215686274509803\n",
      "Confusion Matrix:\n",
      " [[   3   53]\n",
      " [ 175 2676]]\n",
      "\n",
      "\n",
      "The current Data frame is:  9\n",
      "Accuracy: 0.9594083247334021\n",
      "F1 Score: 0.9638186016874735\n",
      "Precision: 0.9508087030375234\n",
      "Recall/Sensitivity/True Positive Rate: 0.9594083247334021\n",
      "Confusion Matrix:\n",
      " [[   4   45]\n",
      " [  73 2785]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    strings=globals()[\"xy{}_5\".format(i)]\n",
    "    print(\"The current Data frame is: \",i)\n",
    "    y_train=strings['label']\n",
    "    processed_df=strings.drop(columns=['label'])\n",
    "    naive_bayes_search(processed_df,y_train)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current Data frame is:  0\n",
      "Accuracy: 0.8885448916408669\n",
      "F1 Score: 0.8546058025000232\n",
      "Precision: 0.9648222903099499\n",
      "Recall/Sensitivity/True Positive Rate: 0.8885448916408669\n",
      "Confusion Matrix:\n",
      " [[  26  285]\n",
      " [  39 2557]]\n",
      "\n",
      "\n",
      "The current Data frame is:  1\n",
      "Accuracy: 0.6917784657722739\n",
      "F1 Score: 0.6820846329363506\n",
      "Precision: 0.7144587872674384\n",
      "Recall/Sensitivity/True Positive Rate: 0.6917784657722739\n",
      "Confusion Matrix:\n",
      " [[ 312  522]\n",
      " [ 374 1699]]\n",
      "\n",
      "\n",
      "The current Data frame is:  2\n",
      "Accuracy: 0.7351221190230478\n",
      "F1 Score: 0.7448278768406621\n",
      "Precision: 0.7182343362243369\n",
      "Recall/Sensitivity/True Positive Rate: 0.7351221190230478\n",
      "Confusion Matrix:\n",
      " [[ 219  325]\n",
      " [ 445 1918]]\n",
      "\n",
      "\n",
      "The current Data frame is:  3\n",
      "Accuracy: 0.7925696594427245\n",
      "F1 Score: 0.7808256892588054\n",
      "Precision: 0.8195796333773478\n",
      "Recall/Sensitivity/True Positive Rate: 0.7925696594427245\n",
      "Confusion Matrix:\n",
      " [[ 188  371]\n",
      " [ 232 2116]]\n",
      "\n",
      "\n",
      "The current Data frame is:  4\n",
      "Accuracy: 0.5366357069143447\n",
      "F1 Score: 0.49532723738210094\n",
      "Precision: 0.7675844066171659\n",
      "Recall/Sensitivity/True Positive Rate: 0.5366357069143447\n",
      "Confusion Matrix:\n",
      " [[ 449 1213]\n",
      " [ 134 1111]]\n",
      "\n",
      "\n",
      "The current Data frame is:  5\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "The current Data frame is:  6\n",
      "Accuracy: 0.7616099071207431\n",
      "F1 Score: 0.6874428655278926\n",
      "Precision: 0.9456411632248648\n",
      "Recall/Sensitivity/True Positive Rate: 0.7616099071207431\n",
      "Confusion Matrix:\n",
      " [[  55  644]\n",
      " [  49 2159]]\n",
      "\n",
      "\n",
      "The current Data frame is:  7\n",
      "Accuracy: 0.9656002751977985\n",
      "F1 Score: 0.9698219226855641\n",
      "Precision: 0.9573114767940992\n",
      "Recall/Sensitivity/True Positive Rate: 0.9656002751977985\n",
      "Confusion Matrix:\n",
      " [[   2   37]\n",
      " [  63 2805]]\n",
      "\n",
      "\n",
      "The current Data frame is:  8\n",
      "Accuracy: 0.8964568283453732\n",
      "F1 Score: 0.8921566765829845\n",
      "Precision: 0.9053586927829773\n",
      "Recall/Sensitivity/True Positive Rate: 0.8964568283453732\n",
      "Confusion Matrix:\n",
      " [[  45  168]\n",
      " [ 133 2561]]\n",
      "\n",
      "\n",
      "The current Data frame is:  9\n",
      "Accuracy: 0.9484004127966976\n",
      "F1 Score: 0.9460453359604873\n",
      "Precision: 0.9531814989719715\n",
      "Recall/Sensitivity/True Positive Rate: 0.9484004127966976\n",
      "Confusion Matrix:\n",
      " [[  10   83]\n",
      " [  67 2747]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    strings=globals()[\"xy{}_10\".format(i)]\n",
    "    print(\"The current Data frame is: \",i)\n",
    "    y_train=strings['label']\n",
    "    processed_df=strings.drop(columns=['label'])\n",
    "    naive_bayes_search(processed_df,y_train)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current Data frame is:  0\n",
      "Accuracy: 0.8796009631922944\n",
      "F1 Score: 0.840835167070912\n",
      "Precision: 0.9713255757983613\n",
      "Recall/Sensitivity/True Positive Rate: 0.8796009631922944\n",
      "Confusion Matrix:\n",
      " [[  42  327]\n",
      " [  23 2515]]\n",
      "\n",
      "\n",
      "The current Data frame is:  1\n",
      "Accuracy: 0.6824905400756794\n",
      "F1 Score: 0.6659160189027782\n",
      "Precision: 0.7279689983916663\n",
      "Recall/Sensitivity/True Positive Rate: 0.6824905400756794\n",
      "Confusion Matrix:\n",
      " [[ 369  606]\n",
      " [ 317 1615]]\n",
      "\n",
      "\n",
      "The current Data frame is:  2\n",
      "Accuracy: 0.7003783969728242\n",
      "F1 Score: 0.68695212853178\n",
      "Precision: 0.7344234619779695\n",
      "Recall/Sensitivity/True Positive Rate: 0.7003783969728242\n",
      "Confusion Matrix:\n",
      " [[ 337  544]\n",
      " [ 327 1699]]\n",
      "\n",
      "\n",
      "The current Data frame is:  3\n",
      "Accuracy: 0.7296181630546955\n",
      "F1 Score: 0.6925545518773143\n",
      "Precision: 0.8519568209571109\n",
      "Recall/Sensitivity/True Positive Rate: 0.7296181630546955\n",
      "Confusion Matrix:\n",
      " [[ 310  676]\n",
      " [ 110 1811]]\n",
      "\n",
      "\n",
      "The current Data frame is:  4\n",
      "Accuracy: 0.52046783625731\n",
      "F1 Score: 0.48000633242161717\n",
      "Precision: 0.7679480647713061\n",
      "Recall/Sensitivity/True Positive Rate: 0.52046783625731\n",
      "Confusion Matrix:\n",
      " [[ 458 1269]\n",
      " [ 125 1055]]\n",
      "\n",
      "\n",
      "The current Data frame is:  5\n",
      "Accuracy: 0.5576195390436877\n",
      "F1 Score: 0.4186555600505352\n",
      "Precision: 0.9612976878531656\n",
      "Recall/Sensitivity/True Positive Rate: 0.5576195390436877\n",
      "Confusion Matrix:\n",
      " [[  37 1258]\n",
      " [  28 1584]]\n",
      "\n",
      "\n",
      "The current Data frame is:  6\n",
      "Accuracy: 0.6487788097695218\n",
      "F1 Score: 0.5406714335178404\n",
      "Precision: 0.9499374305065909\n",
      "Recall/Sensitivity/True Positive Rate: 0.648778809769522\n",
      "Confusion Matrix:\n",
      " [[  72  989]\n",
      " [  32 1814]]\n",
      "\n",
      "\n",
      "The current Data frame is:  7\n",
      "Accuracy: 0.6171310629514963\n",
      "F1 Score: 0.49059398466163334\n",
      "Precision: 0.9646944606223494\n",
      "Recall/Sensitivity/True Positive Rate: 0.6171310629514963\n",
      "Confusion Matrix:\n",
      " [[  40 1088]\n",
      " [  25 1754]]\n",
      "\n",
      "\n",
      "The current Data frame is:  8\n",
      "Accuracy: 0.8286893704850361\n",
      "F1 Score: 0.7977301904641446\n",
      "Precision: 0.8986401452810748\n",
      "Recall/Sensitivity/True Positive Rate: 0.8286893704850361\n",
      "Confusion Matrix:\n",
      " [[  52  372]\n",
      " [ 126 2357]]\n",
      "\n",
      "\n",
      "The current Data frame is:  9\n",
      "Accuracy: 0.9267285861713106\n",
      "F1 Score: 0.9144435925616496\n",
      "Precision: 0.9524633778175498\n",
      "Recall/Sensitivity/True Positive Rate: 0.9267285861713106\n",
      "Confusion Matrix:\n",
      " [[  12  148]\n",
      " [  65 2682]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    strings=globals()[\"xy{}_20\".format(i)]\n",
    "    print(\"The current Data frame is: \",i)\n",
    "    y_train=strings['label']\n",
    "    processed_df=strings.drop(columns=['label'])\n",
    "    naive_bayes_search(processed_df,y_train)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Victor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7',\n",
       " '41',\n",
       " '42',\n",
       " '52',\n",
       " '58',\n",
       " '71',\n",
       " '74',\n",
       " '115',\n",
       " '129',\n",
       " '136',\n",
       " '148',\n",
       " '166',\n",
       " '211',\n",
       " '213',\n",
       " '218',\n",
       " '237',\n",
       " '239',\n",
       " '274',\n",
       " '280',\n",
       " '281',\n",
       " '284',\n",
       " '314',\n",
       " '335',\n",
       " '338',\n",
       " '346',\n",
       " '348',\n",
       " '374',\n",
       " '375',\n",
       " '391',\n",
       " '409',\n",
       " '425',\n",
       " '445',\n",
       " '450',\n",
       " '461',\n",
       " '464',\n",
       " '470',\n",
       " '481',\n",
       " '483',\n",
       " '486',\n",
       " '487',\n",
       " '490',\n",
       " '491',\n",
       " '492',\n",
       " '510',\n",
       " '512',\n",
       " '531',\n",
       " '537',\n",
       " '541',\n",
       " '574',\n",
       " '581',\n",
       " '615',\n",
       " '628',\n",
       " '635',\n",
       " '637',\n",
       " '638',\n",
       " '646',\n",
       " '661',\n",
       " '670',\n",
       " '684',\n",
       " '702',\n",
       " '719',\n",
       " '739',\n",
       " '742',\n",
       " '774',\n",
       " '777',\n",
       " '798',\n",
       " '811',\n",
       " '828',\n",
       " '829',\n",
       " '830',\n",
       " '845',\n",
       " '850',\n",
       " '884',\n",
       " '910',\n",
       " '916',\n",
       " '917',\n",
       " '921',\n",
       " '927',\n",
       " '935',\n",
       " '956',\n",
       " '963',\n",
       " '965',\n",
       " '966',\n",
       " '967',\n",
       " '972',\n",
       " '1013',\n",
       " '1018',\n",
       " '1023',\n",
       " '1049',\n",
       " '1056',\n",
       " '1063',\n",
       " '1095',\n",
       " '1103',\n",
       " '1109',\n",
       " '1148',\n",
       " '1164',\n",
       " '1185',\n",
       " '1204',\n",
       " '1212',\n",
       " '1241',\n",
       " '1243',\n",
       " '1262',\n",
       " '1264',\n",
       " '1322',\n",
       " '1361',\n",
       " '1377',\n",
       " '1382',\n",
       " '1388',\n",
       " '1389',\n",
       " '1402',\n",
       " '1423',\n",
       " '1432',\n",
       " '1433',\n",
       " '1465',\n",
       " '1474',\n",
       " '1491',\n",
       " '1497',\n",
       " '1535',\n",
       " '1536',\n",
       " '1561',\n",
       " '1564',\n",
       " '1605',\n",
       " '1609',\n",
       " '1617',\n",
       " '1674',\n",
       " '1676',\n",
       " '1677',\n",
       " '1679',\n",
       " '1699',\n",
       " '1733',\n",
       " '1734',\n",
       " '1739',\n",
       " '1756',\n",
       " '1765',\n",
       " '1766',\n",
       " '1772',\n",
       " '1773',\n",
       " '1778',\n",
       " '1780',\n",
       " '1806',\n",
       " '1815',\n",
       " '1835',\n",
       " '1855',\n",
       " '1865',\n",
       " '1868',\n",
       " '1869',\n",
       " '1874',\n",
       " '1876',\n",
       " '1883',\n",
       " '1909',\n",
       " '1921',\n",
       " '1928',\n",
       " '1934',\n",
       " '1941',\n",
       " '1948',\n",
       " '1966',\n",
       " '1997',\n",
       " '1998',\n",
       " '2011',\n",
       " '2022',\n",
       " '2023',\n",
       " '2039',\n",
       " '2051',\n",
       " '2054',\n",
       " '2066',\n",
       " '2084',\n",
       " '2090',\n",
       " '2122',\n",
       " '2156',\n",
       " '2163',\n",
       " '2170',\n",
       " '2176',\n",
       " '2182',\n",
       " '2192',\n",
       " '2201',\n",
       " '2204',\n",
       " '2216',\n",
       " '2221',\n",
       " '2235',\n",
       " '2245',\n",
       " '2246',\n",
       " '2256',\n",
       " '2272',\n",
       " '2287',\n",
       " '2290',\n",
       " '2293']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = []\n",
    "for i in range(len(selected_features_per_class)):\n",
    "    features.append(selected_features_per_class[i][0:20])\n",
    "features = np.concatenate(features)\n",
    "features = np.unique(features)\n",
    "features = features.tolist()\n",
    "for i in range(len(features)):\n",
    "    features[i] = str(features[i])\n",
    "features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2294</th>\n",
       "      <th>2295</th>\n",
       "      <th>2296</th>\n",
       "      <th>2297</th>\n",
       "      <th>2298</th>\n",
       "      <th>2299</th>\n",
       "      <th>2300</th>\n",
       "      <th>2301</th>\n",
       "      <th>2302</th>\n",
       "      <th>2303</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>112.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9685</th>\n",
       "      <td>247.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9686</th>\n",
       "      <td>151.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9687</th>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9688</th>\n",
       "      <td>255.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9689</th>\n",
       "      <td>252.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9690 rows Ã— 2304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2      3      4      5      6      7      8      9  \\\n",
       "0      78.0   77.0   76.0   82.0   87.0   92.0  104.0  119.0  117.0  120.0   \n",
       "1      73.0   75.0   79.0   78.0   76.0   75.0   89.0  107.0  133.0  125.0   \n",
       "2      72.0   75.0   79.0   77.0   81.0   89.0  105.0  109.0   86.0   90.0   \n",
       "3      67.0   70.0   74.0   80.0   93.0  107.0  110.0   96.0   69.0  100.0   \n",
       "4      74.0   74.0   73.0   72.0   77.0   87.0  104.0  109.0   84.0   83.0   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "9685  247.0  220.0  254.0  213.0  129.0  208.0  254.0  255.0  255.0  255.0   \n",
       "9686  151.0  118.0  254.0  255.0  255.0  255.0  254.0  254.0  254.0  252.0   \n",
       "9687  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "9688  255.0  253.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "9689  252.0  189.0  238.0  255.0  255.0  245.0  219.0  212.0  140.0   40.0   \n",
       "\n",
       "      ...   2294  2295  2296   2297  2298  2299  2300   2301   2302   2303  \n",
       "0     ...   87.0  79.0  72.0   76.0  83.0  95.0  99.0   98.0   95.0   94.0  \n",
       "1     ...   96.0  93.0  85.0   77.0  69.0  73.0  83.0  100.0  101.0  101.0  \n",
       "2     ...   98.0  95.0  88.0   80.0  73.0  71.0  74.0   80.0   89.0   95.0  \n",
       "3     ...  112.0  92.0  87.0   82.0  77.0  72.0  70.0   72.0   81.0   88.0  \n",
       "4     ...  100.0  98.0  99.0  100.0  99.0  89.0  78.0   66.0   68.0   72.0  \n",
       "...   ...    ...   ...   ...    ...   ...   ...   ...    ...    ...    ...  \n",
       "9685  ...   35.0  29.0  27.0   26.0  25.0  23.0  22.0   26.0   26.0   27.0  \n",
       "9686  ...   37.0  31.0  30.0   30.0  30.0  30.0  29.0   26.0   28.0   27.0  \n",
       "9687  ...   41.0  49.0  42.0   36.0  33.0  36.0  39.0   31.0   39.0   43.0  \n",
       "9688  ...   38.0  27.0  26.0   27.0  35.0  28.0  27.0   26.0   26.0   24.0  \n",
       "9689  ...   34.0  23.0  23.0   30.0  32.0  23.0  23.0   26.0   20.0   17.0  \n",
       "\n",
       "[9690 rows x 2304 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pd.read_csv('Dataset/x_train_all.csv')\n",
    "y_train = pd.read_csv('Dataset/y_train_all.csv')\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>52</th>\n",
       "      <th>58</th>\n",
       "      <th>71</th>\n",
       "      <th>74</th>\n",
       "      <th>115</th>\n",
       "      <th>129</th>\n",
       "      <th>136</th>\n",
       "      <th>...</th>\n",
       "      <th>2216</th>\n",
       "      <th>2221</th>\n",
       "      <th>2235</th>\n",
       "      <th>2245</th>\n",
       "      <th>2246</th>\n",
       "      <th>2256</th>\n",
       "      <th>2272</th>\n",
       "      <th>2287</th>\n",
       "      <th>2290</th>\n",
       "      <th>2293</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>106.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9685</th>\n",
       "      <td>255.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9686</th>\n",
       "      <td>254.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9687</th>\n",
       "      <td>255.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9688</th>\n",
       "      <td>255.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9689</th>\n",
       "      <td>212.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9690 rows Ã— 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          7     41     42     52     58     71     74    115    129    136  \\\n",
       "0     119.0   85.0   78.0   89.0  113.0  165.0  208.0  188.0  166.0   98.0   \n",
       "1     107.0  103.0   96.0   79.0   92.0  192.0  176.0  227.0  229.0   92.0   \n",
       "2     109.0  104.0   95.0   88.0  121.0  224.0  162.0  156.0  230.0   89.0   \n",
       "3      96.0   94.0   95.0   98.0  162.0  236.0  164.0  147.0  215.0   90.0   \n",
       "4     109.0  103.0   87.0   84.0  103.0  173.0  144.0  177.0  226.0   84.0   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "9685  255.0   28.0   40.0  199.0  255.0   27.0   23.0  227.0   31.0  102.0   \n",
       "9686  254.0  100.0  104.0  205.0  134.0  247.0  255.0   92.0   30.0   88.0   \n",
       "9687  255.0  253.0  246.0  255.0  255.0  217.0  255.0  254.0  244.0  151.0   \n",
       "9688  255.0  242.0  189.0  255.0  236.0  204.0  103.0  254.0  255.0  251.0   \n",
       "9689  212.0   97.0   61.0  255.0   15.0   48.0   48.0   88.0  108.0   25.0   \n",
       "\n",
       "      ...   2216   2221   2235   2245   2246   2256   2272   2287   2290  \\\n",
       "0     ...   75.0   88.0   98.0   91.0   83.0   85.0   95.0  149.0  105.0   \n",
       "1     ...   76.0   93.0  125.0  100.0   95.0   74.0   84.0  104.0  142.0   \n",
       "2     ...   82.0   88.0  109.0  103.0   97.0   77.0   82.0   98.0  144.0   \n",
       "3     ...   77.0   73.0  111.0  126.0  109.0   75.0   78.0   95.0  114.0   \n",
       "4     ...  106.0  139.0  119.0   97.0   96.0  129.0  125.0   94.0  108.0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "9685  ...   40.0  104.0   92.0   52.0   37.0   50.0  104.0  100.0  101.0   \n",
       "9686  ...   29.0   99.0  100.0   56.0   36.0   43.0  102.0  100.0   98.0   \n",
       "9687  ...   31.0  101.0   93.0   42.0   41.0   35.0  101.0   94.0   96.0   \n",
       "9688  ...   33.0   95.0   91.0   39.0   39.0   33.0   96.0   89.0   90.0   \n",
       "9689  ...   32.0   91.0   82.0   33.0   34.0   37.0   90.0   85.0   86.0   \n",
       "\n",
       "       2293  \n",
       "0      94.0  \n",
       "1      99.0  \n",
       "2     103.0  \n",
       "3     133.0  \n",
       "4     103.0  \n",
       "...     ...  \n",
       "9685   52.0  \n",
       "9686   55.0  \n",
       "9687   41.0  \n",
       "9688   37.0  \n",
       "9689   32.0  \n",
       "\n",
       "[9690 rows x 186 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_x_train = xtrain[features]\n",
    "reduced_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anshu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.20536635706914344\n",
      "F1 Score: 0.1826215019670626\n",
      "Precision: 0.38046928931651885\n",
      "Recall/Sensitivity/True Positive Rate: 0.20536635706914344\n",
      "Confusion Matrix:\n",
      " [[ 49 163  54  23  24   1   1   2  12   0]\n",
      " [  2 148 130  34  46   0   3   0   8   2]\n",
      " [  4  84  83   2  37   1   0   2   6   0]\n",
      " [  2  15  33  68  31   1   0   4   0   0]\n",
      " [  2  35  91  14  84   0   0   0   0   0]\n",
      " [  0   5   7   4   3  12   3   0   3   2]\n",
      " [  0  72  89 200 253  19  62  15  39   8]\n",
      " [  6 156 155  46 100  28  17  35  60  47]\n",
      " [  0   4   1   4   1   3   1   2  38   0]\n",
      " [  0   4  21  25   4   0  17   5  12  18]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 5, 7, ..., 9, 6, 7], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes_search(reduced_x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 186 into shape (14,14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\anshu\\OneDrive\\Desktop\\Course\\F21DL\\DMML\\Coursework\\Part 1\\Feature_Selection_fixed.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m original_image \u001b[39m=\u001b[39m reduced_x_train\u001b[39m.\u001b[39;49miloc[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mreshape(\u001b[39m14\u001b[39;49m, \u001b[39m14\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(original_image, cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgray\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 186 into shape (14,14)"
     ]
    }
   ],
   "source": [
    "original_image = reduced_x_train.iloc[0].values.reshape(14, 14)\n",
    "plt.imshow(original_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d080205970>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_image = xtrain.iloc[0].values.reshape(48, 48)\n",
    "plt.imshow(original_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d08143bc40>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new = xy0_20.drop(columns=[\"label\"])\n",
    "\n",
    "original_image = new.iloc[0].values.reshape(4, 5)\n",
    "plt.imshow(original_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.17784657722738217\n",
      "F1 Score: 0.1436398047200998\n",
      "Precision: 0.34542132352513194\n",
      "Recall/Sensitivity/True Positive Rate: 0.17784657722738217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "classifiers = [GaussianNB() for i in range(10)]\n",
    "ovr = OneVsRestClassifier(GaussianNB())\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(reduced_x_train, ytrainall, test_size=0.3,random_state=seed_value)\n",
    "\n",
    "ovr.fit(X_train, Y_train)\n",
    "predicted = ovr.predict(X_test)\n",
    "predicted_probs = ovr.predict_proba(X_test)\n",
    "\n",
    "# cross_val_scores = cross_val_score(gnb, X_train, Y_train, cv=5)  \n",
    "# print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "# print(\"Mean CV Score:\", cross_val_scores.mean())\n",
    "\n",
    "\n",
    "# train_sizes, train_scores, test_scores = learning_curve(gnb, X_train, Y_train, cv=5)\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Learning Curves\")\n",
    "# plt.xlabel(\"Training examples\")\n",
    "# plt.ylabel(\"Score\")\n",
    "# plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "# plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()\n",
    "\n",
    "accuracy = accuracy_score(Y_test,predicted )\n",
    "f1 = f1_score(predicted, Y_test, average=\"weighted\")\n",
    "conf_matrix = confusion_matrix(predicted, Y_test)\n",
    "precision = precision_score(Y_test, predicted, average=\"weighted\",zero_division=1)\n",
    "recall = recall_score(Y_test, predicted, average=\"weighted\")\n",
    "# roc = roc_auc_score(Y_test, predicted_probs, multi_class=\"ovr\", average=\"weighted\")\n",
    "# conf_matrices = multilabel_confusion_matrix(Y_test, predicted)\n",
    "# tp = conf_matrices[:,1,1]\n",
    "# fp = conf_matrices[:,0,1]\n",
    "# tn = conf_matrices[:,0,0]\n",
    "# fn = conf_matrices[:,1,0]\n",
    "# fpr = _nanaverage(fp/(tn + fp), tp + fn)\n",
    "# tnr = _nanaverage(tn/(tn + fp), tp + fn)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall/Sensitivity/True Positive Rate:\", recall)\n",
    "# print(\"Specificity:\", tnr)\n",
    "# print(\"False Positive Rate:\", fpr)\n",
    "# print(\"Area under ROC curve:\", roc)\n",
    "# print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4757481940144479\n",
      "F1 Score: 0.46517680193532784\n",
      "Precision: 0.5257300207272383\n",
      "Recall/Sensitivity/True Positive Rate: 0.4757481940144479\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "classifiers = [GaussianNB() for i in range(5)]\n",
    "ovr = OneVsOneClassifier(GaussianNB(), n_jobs=45)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(reduced_x_train, ytrainall, test_size=0.3,random_state=seed_value)\n",
    "\n",
    "ovr.fit(X_train, Y_train)\n",
    "predicted = ovr.predict(X_test)\n",
    "# predicted_probs = ovr.predict_proba(X_test)\n",
    "\n",
    "# cross_val_scores = cross_val_score(gnb, X_train, Y_train, cv=5)  \n",
    "# print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "# print(\"Mean CV Score:\", cross_val_scores.mean())\n",
    "\n",
    "\n",
    "# train_sizes, train_scores, test_scores = learning_curve(gnb, X_train, Y_train, cv=5)\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Learning Curves\")\n",
    "# plt.xlabel(\"Training examples\")\n",
    "# plt.ylabel(\"Score\")\n",
    "# plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "# plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()\n",
    "\n",
    "accuracy = accuracy_score(Y_test,predicted )\n",
    "f1 = f1_score(predicted, Y_test, average=\"weighted\")\n",
    "conf_matrix = confusion_matrix(predicted, Y_test)\n",
    "precision = precision_score(Y_test, predicted, average=\"weighted\",zero_division=1)\n",
    "recall = recall_score(Y_test, predicted, average=\"weighted\")\n",
    "# roc = roc_auc_score(Y_test, predicted_probs, multi_class=\"ovr\", average=\"weighted\")\n",
    "# conf_matrices = multilabel_confusion_matrix(Y_test, predicted)\n",
    "# tp = conf_matrices[:,1,1]\n",
    "# fp = conf_matrices[:,0,1]\n",
    "# tn = conf_matrices[:,0,0]\n",
    "# fn = conf_matrices[:,1,0]\n",
    "# fpr = _nanaverage(fp/(tn + fp), tp + fn)\n",
    "# tnr = _nanaverage(tn/(tn + fp), tp + fn)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall/Sensitivity/True Positive Rate:\", recall)\n",
    "# print(\"Specificity:\", tnr)\n",
    "# print(\"False Positive Rate:\", fpr)\n",
    "# print(\"Area under ROC curve:\", roc)\n",
    "# print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1605    490   1536    927    742  label\n",
      "0     219.0   83.0  184.0  105.0  103.0      0\n",
      "1     185.0   97.0  187.0   80.0  123.0      0\n",
      "2     204.0  129.0  182.0  110.0  196.0      0\n",
      "3     185.0  148.0  184.0  135.0  235.0      0\n",
      "4     175.0   80.0  107.0   81.0   78.0      0\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685   54.0  255.0  222.0  161.0   96.0      1\n",
      "9686   55.0  255.0   92.0  104.0  104.0      1\n",
      "9687   53.0  254.0  109.0   75.0  101.0      1\n",
      "9688   53.0  255.0  113.0   86.0   94.0      1\n",
      "9689   41.0  248.0  255.0   70.0   91.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  0\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "       1432     52   1733    637   1262  label\n",
      "0      89.0   89.0   94.0  115.0  176.0      1\n",
      "1      91.0   79.0  111.0  110.0  100.0      1\n",
      "2      87.0   88.0  120.0  119.0  153.0      1\n",
      "3      82.0   98.0  105.0  129.0  142.0      1\n",
      "4     116.0   84.0  179.0  131.0  158.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685   42.0  199.0   43.0  255.0   20.0      1\n",
      "9686   52.0  205.0   47.0  206.0   19.0      1\n",
      "9687   37.0  255.0   38.0  255.0   17.0      1\n",
      "9688   38.0  255.0   55.0   76.0   16.0      1\n",
      "9689   25.0  255.0   82.0  254.0   15.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  1\n",
      "Accuracy: 0.7206742346061231\n",
      "F1 Score: 0.7282272614049545\n",
      "Precision: 0.7071068742350334\n",
      "Recall/Sensitivity/True Positive Rate: 0.7206742346061231\n",
      "Confusion Matrix:\n",
      " [[ 232  358]\n",
      " [ 454 1863]]\n",
      "\n",
      "\n",
      "       1997    166   335   1765   1780  label\n",
      "0     126.0  215.0  85.0   81.0   74.0      1\n",
      "1     119.0  183.0  76.0   81.0  149.0      1\n",
      "2     116.0  221.0  70.0   82.0  134.0      1\n",
      "3     119.0  225.0  64.0   94.0  142.0      1\n",
      "4     126.0  214.0  91.0  121.0  177.0      1\n",
      "...     ...    ...   ...    ...    ...    ...\n",
      "9685   17.0  250.0  68.0   22.0   62.0      1\n",
      "9686   16.0   26.0  17.0   21.0   48.0      1\n",
      "9687   17.0  246.0  68.0   27.0   37.0      1\n",
      "9688   16.0  220.0  74.0   25.0   45.0      1\n",
      "9689   14.0   61.0  42.0   23.0   94.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  2\n",
      "Accuracy: 0.760921912624699\n",
      "F1 Score: 0.8204924612426809\n",
      "Precision: 0.696758798358478\n",
      "Recall/Sensitivity/True Positive Rate: 0.760921912624699\n",
      "Confusion Matrix:\n",
      " [[  68   99]\n",
      " [ 596 2144]]\n",
      "\n",
      "\n",
      "      1772    481   670   1212   2245  label\n",
      "0     80.0  112.0  72.0   74.0   91.0      1\n",
      "1     87.0  112.0  72.0  120.0  100.0      1\n",
      "2     85.0  125.0  71.0   81.0  103.0      1\n",
      "3     83.0  127.0  65.0   79.0  126.0      1\n",
      "4     77.0  109.0  65.0   79.0   97.0      1\n",
      "...    ...    ...   ...    ...    ...    ...\n",
      "9685  36.0  255.0  38.0  102.0   52.0      1\n",
      "9686  37.0  255.0  27.0   93.0   56.0      1\n",
      "9687  29.0  255.0  30.0   88.0   42.0      1\n",
      "9688  24.0  255.0  20.0  142.0   39.0      1\n",
      "9689  34.0  226.0  28.0   72.0   33.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  3\n",
      "Accuracy: 0.8582731338149295\n",
      "F1 Score: 0.8878519519945112\n",
      "Precision: 0.8259810945105907\n",
      "Recall/Sensitivity/True Positive Rate: 0.8582731338149295\n",
      "Confusion Matrix:\n",
      " [[  80   72]\n",
      " [ 340 2415]]\n",
      "\n",
      "\n",
      "      1676   2039   2051    581   2272  label\n",
      "0     83.0  135.0  108.0  143.0   95.0      1\n",
      "1     91.0  137.0  113.0  170.0   84.0      1\n",
      "2     88.0  123.0  112.0  164.0   82.0      1\n",
      "3     84.0  147.0   98.0  164.0   78.0      1\n",
      "4     76.0  114.0  126.0  116.0  125.0      1\n",
      "...    ...    ...    ...    ...    ...    ...\n",
      "9685  39.0   33.0   62.0  255.0  104.0      1\n",
      "9686  39.0   18.0   23.0  255.0  102.0      1\n",
      "9687  36.0   27.0   65.0  253.0  101.0      1\n",
      "9688  23.0   25.0   51.0  255.0   96.0      1\n",
      "9689  45.0   31.0   60.0  254.0   90.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  4\n",
      "Accuracy: 0.6130030959752322\n",
      "F1 Score: 0.5745084899556268\n",
      "Precision: 0.7621563059023773\n",
      "Recall/Sensitivity/True Positive Rate: 0.6130030959752322\n",
      "Confusion Matrix:\n",
      " [[ 392  934]\n",
      " [ 191 1390]]\n",
      "\n",
      "\n",
      "        464     74   1739   1361   1756  label\n",
      "0      89.0  208.0   91.0  198.0  149.0      1\n",
      "1     106.0  176.0  124.0  204.0  111.0      1\n",
      "2     123.0  162.0  114.0  197.0  122.0      1\n",
      "3     113.0  164.0  132.0  173.0   96.0      1\n",
      "4      82.0  144.0  154.0  226.0  200.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685  158.0   23.0   21.0  115.0   71.0      1\n",
      "9686  203.0  255.0   29.0  111.0   80.0      1\n",
      "9687   17.0  255.0   53.0  107.0   54.0      1\n",
      "9688  119.0  103.0   23.0   99.0   42.0      1\n",
      "9689  172.0   48.0   40.0   95.0   39.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  5\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "       2216   1948   1778    966    935  label\n",
      "0      75.0  132.0  125.0  135.0  228.0      1\n",
      "1      76.0  119.0  166.0   92.0  197.0      1\n",
      "2      82.0  115.0  141.0   94.0  204.0      1\n",
      "3      77.0  110.0  155.0   80.0  179.0      1\n",
      "4     106.0  107.0  180.0  161.0  236.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685   40.0   18.0   78.0  191.0  112.0      1\n",
      "9686   29.0   17.0   76.0  227.0  107.0      1\n",
      "9687   31.0   16.0   58.0  154.0  102.0      1\n",
      "9688   33.0   15.0   40.0  255.0   98.0      1\n",
      "9689   32.0   13.0  143.0   17.0   93.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  6\n",
      "Accuracy: 0.9642242862057103\n",
      "F1 Score: 0.9817863397548159\n",
      "Precision: 0.9655041879032012\n",
      "Recall/Sensitivity/True Positive Rate: 0.9642242862057103\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [ 104 2803]]\n",
      "\n",
      "\n",
      "       1382   1564   2290    314   2163  label\n",
      "0     107.0  230.0  105.0  188.0   92.0      1\n",
      "1      95.0  235.0  142.0  177.0  103.0      1\n",
      "2     104.0  235.0  144.0   98.0  112.0      1\n",
      "3     104.0  233.0  114.0   77.0  106.0      1\n",
      "4      73.0  164.0  108.0  196.0  143.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685   41.0   68.0  101.0  205.0   45.0      1\n",
      "9686   40.0   61.0   98.0  191.0   36.0      1\n",
      "9687   41.0   72.0   96.0   53.0   36.0      1\n",
      "9688   35.0   76.0   90.0  253.0   38.0      1\n",
      "9689   33.0   65.0   86.0  254.0   31.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  7\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "        425    237   2084    129   1491  label\n",
      "0      98.0   72.0   97.0  166.0  181.0      1\n",
      "1     107.0   75.0  117.0  229.0  182.0      1\n",
      "2      96.0   74.0  124.0  230.0  176.0      1\n",
      "3      76.0   81.0  122.0  215.0  174.0      1\n",
      "4      70.0   91.0  103.0  226.0  114.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685  130.0  133.0  101.0   31.0   68.0      1\n",
      "9686   69.0  225.0   64.0   30.0   79.0      1\n",
      "9687   90.0  124.0   97.0  244.0   71.0      1\n",
      "9688   27.0   25.0   96.0  255.0  116.0      1\n",
      "9689   56.0   36.0   89.0  108.0  255.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  8\n",
      "Accuracy: 0.9215686274509803\n",
      "F1 Score: 0.9411570087091911\n",
      "Precision: 0.8844252888808979\n",
      "Recall/Sensitivity/True Positive Rate: 0.9215686274509803\n",
      "Confusion Matrix:\n",
      " [[   3   53]\n",
      " [ 175 2676]]\n",
      "\n",
      "\n",
      "       1109    346     42    646    798  label\n",
      "0     124.0  170.0   78.0   90.0   95.0      1\n",
      "1      90.0  127.0   96.0   80.0  139.0      1\n",
      "2      79.0  131.0   95.0   83.0  149.0      1\n",
      "3      99.0   84.0   95.0  124.0  172.0      1\n",
      "4     108.0  201.0   87.0  101.0   90.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685  241.0  255.0   40.0   26.0   57.0      0\n",
      "9686  169.0  254.0  104.0   62.0   80.0      0\n",
      "9687  224.0   40.0  246.0   65.0   99.0      0\n",
      "9688  255.0  254.0  189.0   71.0   61.0      0\n",
      "9689  150.0  139.0   61.0   59.0   52.0      0\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  9\n",
      "Accuracy: 0.9594083247334021\n",
      "F1 Score: 0.9638186016874735\n",
      "Precision: 0.9508087030375234\n",
      "Recall/Sensitivity/True Positive Rate: 0.9594083247334021\n",
      "Confusion Matrix:\n",
      " [[   4   45]\n",
      " [  73 2785]]\n",
      "\n",
      "\n",
      "       1605    490   1536    927    742  1966   2066   2235    239  1869  \\\n",
      "0     219.0   83.0  184.0  105.0  103.0  82.0  126.0   98.0   77.0  79.0   \n",
      "1     185.0   97.0  187.0   80.0  123.0  80.0  136.0  125.0   71.0  79.0   \n",
      "2     204.0  129.0  182.0  110.0  196.0  76.0  124.0  109.0   68.0  79.0   \n",
      "3     185.0  148.0  184.0  135.0  235.0  77.0  128.0  111.0   64.0  80.0   \n",
      "4     175.0   80.0  107.0   81.0   78.0  77.0  153.0  119.0   83.0  75.0   \n",
      "...     ...    ...    ...    ...    ...   ...    ...    ...    ...   ...   \n",
      "9685   54.0  255.0  222.0  161.0   96.0  29.0   60.0   92.0   36.0  30.0   \n",
      "9686   55.0  255.0   92.0  104.0  104.0  29.0   38.0  100.0  122.0  36.0   \n",
      "9687   53.0  254.0  109.0   75.0  101.0  31.0   41.0   93.0   60.0  32.0   \n",
      "9688   53.0  255.0  113.0   86.0   94.0  23.0   38.0   91.0   33.0  27.0   \n",
      "9689   41.0  248.0  255.0   70.0   91.0  36.0   34.0   82.0  214.0  28.0   \n",
      "\n",
      "      label  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  0\n",
      "Accuracy: 0.8885448916408669\n",
      "F1 Score: 0.8546058025000232\n",
      "Precision: 0.9648222903099499\n",
      "Recall/Sensitivity/True Positive Rate: 0.8885448916408669\n",
      "Confusion Matrix:\n",
      " [[  26  285]\n",
      " [  39 2557]]\n",
      "\n",
      "\n",
      "       1432     52   1733    637   1262    829  1388    280    635   1423  \\\n",
      "0      89.0   89.0   94.0  115.0  176.0  100.0  89.0  111.0  115.0  178.0   \n",
      "1      91.0   79.0  111.0  110.0  100.0  117.0  85.0   78.0  119.0  147.0   \n",
      "2      87.0   88.0  120.0  119.0  153.0   97.0  83.0   70.0  115.0  152.0   \n",
      "3      82.0   98.0  105.0  129.0  142.0   81.0  78.0   71.0  122.0  197.0   \n",
      "4     116.0   84.0  179.0  131.0  158.0  128.0  76.0   68.0  127.0  157.0   \n",
      "...     ...    ...    ...    ...    ...    ...   ...    ...    ...    ...   \n",
      "9685   42.0  199.0   43.0  255.0   20.0  208.0  38.0  232.0  201.0  102.0   \n",
      "9686   52.0  205.0   47.0  206.0   19.0  217.0  37.0   19.0  170.0   95.0   \n",
      "9687   37.0  255.0   38.0  255.0   17.0  251.0  31.0  105.0  255.0   87.0   \n",
      "9688   38.0  255.0   55.0   76.0   16.0   99.0  26.0   96.0  221.0   80.0   \n",
      "9689   25.0  255.0   82.0  254.0   15.0  102.0  85.0  169.0  255.0   80.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  1\n",
      "Accuracy: 0.6917784657722739\n",
      "F1 Score: 0.6820846329363506\n",
      "Precision: 0.7144587872674384\n",
      "Recall/Sensitivity/True Positive Rate: 0.6917784657722739\n",
      "Confusion Matrix:\n",
      " [[ 312  522]\n",
      " [ 374 1699]]\n",
      "\n",
      "\n",
      "       1997    166   335   1765   1780    845    281    638   1561    148  \\\n",
      "0     126.0  215.0  85.0   81.0   74.0  141.0  103.0  120.0  225.0   96.0   \n",
      "1     119.0  183.0  76.0   81.0  149.0  191.0   89.0  110.0  231.0   83.0   \n",
      "2     116.0  221.0  70.0   82.0  134.0  169.0   81.0  127.0  234.0  108.0   \n",
      "3     119.0  225.0  64.0   94.0  142.0  139.0   77.0  132.0  237.0  109.0   \n",
      "4     126.0  214.0  91.0  121.0  177.0  148.0   73.0  132.0  152.0  107.0   \n",
      "...     ...    ...   ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685   17.0  250.0  68.0   22.0   62.0   39.0  255.0  253.0   50.0  255.0   \n",
      "9686   16.0   26.0  17.0   21.0   48.0   24.0   21.0  153.0   41.0  255.0   \n",
      "9687   17.0  246.0  68.0   27.0   37.0   23.0  189.0  255.0   48.0  255.0   \n",
      "9688   16.0  220.0  74.0   25.0   45.0   18.0   80.0   31.0   36.0  255.0   \n",
      "9689   14.0   61.0  42.0   23.0   94.0   19.0  189.0  217.0   36.0   19.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  2\n",
      "Accuracy: 0.7351221190230478\n",
      "F1 Score: 0.7448278768406621\n",
      "Precision: 0.7182343362243369\n",
      "Recall/Sensitivity/True Positive Rate: 0.7351221190230478\n",
      "Confusion Matrix:\n",
      " [[ 219  325]\n",
      " [ 445 1918]]\n",
      "\n",
      "\n",
      "      1772    481   670   1212   2245   1465   2023   2246  1389    274  label\n",
      "0     80.0  112.0  72.0   74.0   91.0  172.0  132.0   83.0  91.0  204.0      1\n",
      "1     87.0  112.0  72.0  120.0  100.0  168.0  100.0   95.0  84.0  166.0      1\n",
      "2     85.0  125.0  71.0   81.0  103.0  171.0   93.0   97.0  83.0   88.0      1\n",
      "3     83.0  127.0  65.0   79.0  126.0  190.0   90.0  109.0  78.0   64.0      1\n",
      "4     77.0  109.0  65.0   79.0   97.0  176.0   85.0   96.0  77.0  208.0      1\n",
      "...    ...    ...   ...    ...    ...    ...    ...    ...   ...    ...    ...\n",
      "9685  36.0  255.0  38.0  102.0   52.0   85.0   19.0   37.0  35.0  226.0      1\n",
      "9686  37.0  255.0  27.0   93.0   56.0   69.0   18.0   36.0  34.0  215.0      1\n",
      "9687  29.0  255.0  30.0   88.0   42.0   59.0   18.0   41.0  30.0  133.0      1\n",
      "9688  24.0  255.0  20.0  142.0   39.0   64.0   17.0   39.0  30.0  238.0      1\n",
      "9689  34.0  226.0  28.0   72.0   33.0   52.0   17.0   34.0  67.0  239.0      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  3\n",
      "Accuracy: 0.7925696594427245\n",
      "F1 Score: 0.7808256892588054\n",
      "Precision: 0.8195796333773478\n",
      "Recall/Sensitivity/True Positive Rate: 0.7925696594427245\n",
      "Confusion Matrix:\n",
      " [[ 188  371]\n",
      " [ 232 2116]]\n",
      "\n",
      "\n",
      "      1676   2039   2051    581   2272    491  1677  1674   1921   1148  label\n",
      "0     83.0  135.0  108.0  143.0   95.0   84.0  80.0  89.0  125.0   85.0      1\n",
      "1     91.0  137.0  113.0  170.0   84.0   99.0  90.0  86.0  142.0   93.0      1\n",
      "2     88.0  123.0  112.0  164.0   82.0  133.0  90.0  80.0  146.0  101.0      1\n",
      "3     84.0  147.0   98.0  164.0   78.0  151.0  88.0  76.0  143.0   92.0      1\n",
      "4     76.0  114.0  126.0  116.0  125.0   81.0  79.0  75.0  144.0   76.0      1\n",
      "...    ...    ...    ...    ...    ...    ...   ...   ...    ...    ...    ...\n",
      "9685  39.0   33.0   62.0  255.0  104.0  255.0  40.0  33.0  101.0   32.0      1\n",
      "9686  39.0   18.0   23.0  255.0  102.0  255.0  36.0  47.0   41.0   41.0      1\n",
      "9687  36.0   27.0   65.0  253.0  101.0  168.0  31.0  36.0   54.0   36.0      1\n",
      "9688  23.0   25.0   51.0  255.0   96.0  255.0  28.0  26.0   45.0   94.0      1\n",
      "9689  45.0   31.0   60.0  254.0   90.0  224.0  53.0  43.0   56.0   35.0      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  4\n",
      "Accuracy: 0.5366357069143447\n",
      "F1 Score: 0.49532723738210094\n",
      "Precision: 0.7675844066171659\n",
      "Recall/Sensitivity/True Positive Rate: 0.5366357069143447\n",
      "Confusion Matrix:\n",
      " [[ 449 1213]\n",
      " [ 134 1111]]\n",
      "\n",
      "\n",
      "        464     74   1739   1361   1756    445   1874   1928    774     58  \\\n",
      "0      89.0  208.0   91.0  198.0  149.0  109.0  152.0  144.0  153.0  113.0   \n",
      "1     106.0  176.0  124.0  204.0  111.0   89.0  150.0  100.0  165.0   92.0   \n",
      "2     123.0  162.0  114.0  197.0  122.0  103.0  177.0  105.0  165.0  121.0   \n",
      "3     113.0  164.0  132.0  173.0   96.0  111.0  137.0   70.0  169.0  162.0   \n",
      "4      82.0  144.0  154.0  226.0  200.0   98.0  122.0   83.0  161.0  103.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  158.0   23.0   21.0  115.0   71.0  255.0   67.0   19.0  227.0  255.0   \n",
      "9686  203.0  255.0   29.0  111.0   80.0  255.0   58.0   18.0  228.0  134.0   \n",
      "9687   17.0  255.0   53.0  107.0   54.0   83.0   42.0   18.0  255.0  255.0   \n",
      "9688  119.0  103.0   23.0   99.0   42.0  253.0   47.0   16.0  253.0  236.0   \n",
      "9689  172.0   48.0   40.0   95.0   39.0  198.0   60.0   16.0  124.0   15.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  5\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "       2216   1948   1778    966    935   1063    963   956    830    374  \\\n",
      "0      75.0  132.0  125.0  135.0  228.0  139.0   88.0  78.0   92.0   68.0   \n",
      "1      76.0  119.0  166.0   92.0  197.0  107.0  165.0  83.0  108.0   79.0   \n",
      "2      82.0  115.0  141.0   94.0  204.0  126.0  140.0  79.0   85.0   89.0   \n",
      "3      77.0  110.0  155.0   80.0  179.0   93.0  159.0  76.0   76.0  101.0   \n",
      "4     106.0  107.0  180.0  161.0  236.0   98.0  166.0  76.0  110.0   76.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...   ...    ...    ...   \n",
      "9685   40.0   18.0   78.0  191.0  112.0  150.0  185.0  42.0  172.0  109.0   \n",
      "9686   29.0   17.0   76.0  227.0  107.0  211.0  228.0  40.0  244.0  217.0   \n",
      "9687   31.0   16.0   58.0  154.0  102.0  109.0  221.0  39.0  255.0  240.0   \n",
      "9688   33.0   15.0   40.0  255.0   98.0  255.0  255.0  35.0  148.0  160.0   \n",
      "9689   32.0   13.0  143.0   17.0   93.0  243.0   20.0  17.0  208.0   60.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  6\n",
      "Accuracy: 0.7616099071207431\n",
      "F1 Score: 0.6874428655278926\n",
      "Precision: 0.9456411632248648\n",
      "Recall/Sensitivity/True Positive Rate: 0.7616099071207431\n",
      "Confusion Matrix:\n",
      " [[  55  644]\n",
      " [  49 2159]]\n",
      "\n",
      "\n",
      "       1382   1564   2290    314   2163   1948   1883   1013   1241   1835  \\\n",
      "0     107.0  230.0  105.0  188.0   92.0  132.0  104.0  125.0   91.0   99.0   \n",
      "1      95.0  235.0  142.0  177.0  103.0  119.0  127.0   83.0   95.0  125.0   \n",
      "2     104.0  235.0  144.0   98.0  112.0  115.0  120.0   76.0   88.0  117.0   \n",
      "3     104.0  233.0  114.0   77.0  106.0  110.0  139.0   90.0   80.0  136.0   \n",
      "4      73.0  164.0  108.0  196.0  143.0  107.0  145.0  108.0  106.0  149.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685   41.0   68.0  101.0  205.0   45.0   18.0   46.0  221.0   34.0   87.0   \n",
      "9686   40.0   61.0   98.0  191.0   36.0   17.0   80.0  229.0   39.0   89.0   \n",
      "9687   41.0   72.0   96.0   53.0   36.0   16.0   29.0  225.0   49.0  104.0   \n",
      "9688   35.0   76.0   90.0  253.0   38.0   15.0   32.0  255.0   99.0   89.0   \n",
      "9689   33.0   65.0   86.0  254.0   31.0   13.0   20.0   24.0   33.0   91.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  7\n",
      "Accuracy: 0.9656002751977985\n",
      "F1 Score: 0.9698219226855641\n",
      "Precision: 0.9573114767940992\n",
      "Recall/Sensitivity/True Positive Rate: 0.9656002751977985\n",
      "Confusion Matrix:\n",
      " [[   2   37]\n",
      " [  63 2805]]\n",
      "\n",
      "\n",
      "        425    237   2084    129   1491    461   1322    218   2192    884  \\\n",
      "0      98.0   72.0   97.0  166.0  181.0   89.0  148.0  179.0  155.0  228.0   \n",
      "1     107.0   75.0  117.0  229.0  182.0   96.0  169.0  200.0  119.0  207.0   \n",
      "2      96.0   74.0  124.0  230.0  176.0  132.0  126.0  186.0  115.0  195.0   \n",
      "3      76.0   81.0  122.0  215.0  174.0  128.0  133.0  143.0   99.0  146.0   \n",
      "4      70.0   91.0  103.0  226.0  114.0   76.0  137.0  190.0  116.0  182.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  130.0  133.0  101.0   31.0   68.0  173.0   45.0  255.0  100.0   56.0   \n",
      "9686   69.0  225.0   64.0   30.0   79.0  239.0   36.0   20.0   71.0   91.0   \n",
      "9687   90.0  124.0   97.0  244.0   71.0   64.0   21.0  159.0   94.0   90.0   \n",
      "9688   27.0   25.0   96.0  255.0  116.0  124.0   17.0  255.0   89.0   84.0   \n",
      "9689   56.0   36.0   89.0  108.0  255.0  103.0   16.0  104.0   86.0   82.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  8\n",
      "Accuracy: 0.8964568283453732\n",
      "F1 Score: 0.8921566765829845\n",
      "Precision: 0.9053586927829773\n",
      "Recall/Sensitivity/True Positive Rate: 0.8964568283453732\n",
      "Confusion Matrix:\n",
      " [[  45  168]\n",
      " [ 133 2561]]\n",
      "\n",
      "\n",
      "       1109    346     42    646    798   2256    492   1934   2170   1402  \\\n",
      "0     124.0  170.0   78.0   90.0   95.0   85.0   86.0  111.0   84.0  120.0   \n",
      "1      90.0  127.0   96.0   80.0  139.0   74.0  102.0  108.0   82.0  136.0   \n",
      "2      79.0  131.0   95.0   83.0  149.0   77.0  134.0   99.0   96.0  122.0   \n",
      "3      99.0   84.0   95.0  124.0  172.0   75.0  135.0  102.0   89.0  139.0   \n",
      "4     108.0  201.0   87.0  101.0   90.0  129.0   81.0   98.0  120.0  130.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  241.0  255.0   40.0   26.0   57.0   50.0  255.0   19.0   58.0  100.0   \n",
      "9686  169.0  254.0  104.0   62.0   80.0   43.0  255.0   19.0   53.0   87.0   \n",
      "9687  224.0   40.0  246.0   65.0   99.0   35.0  134.0   18.0   63.0   87.0   \n",
      "9688  255.0  254.0  189.0   71.0   61.0   33.0  214.0   16.0   58.0  130.0   \n",
      "9689  150.0  139.0   61.0   59.0   52.0   37.0  166.0   15.0   65.0   98.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      0  \n",
      "9686      0  \n",
      "9687      0  \n",
      "9688      0  \n",
      "9689      0  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  9\n",
      "Accuracy: 0.9484004127966976\n",
      "F1 Score: 0.9460453359604873\n",
      "Precision: 0.9531814989719715\n",
      "Recall/Sensitivity/True Positive Rate: 0.9484004127966976\n",
      "Confusion Matrix:\n",
      " [[  10   83]\n",
      " [  67 2747]]\n",
      "\n",
      "\n",
      "       1605    490   1536    927    742  1966   2066   2235    239  1869  ...  \\\n",
      "0     219.0   83.0  184.0  105.0  103.0  82.0  126.0   98.0   77.0  79.0  ...   \n",
      "1     185.0   97.0  187.0   80.0  123.0  80.0  136.0  125.0   71.0  79.0  ...   \n",
      "2     204.0  129.0  182.0  110.0  196.0  76.0  124.0  109.0   68.0  79.0  ...   \n",
      "3     185.0  148.0  184.0  135.0  235.0  77.0  128.0  111.0   64.0  80.0  ...   \n",
      "4     175.0   80.0  107.0   81.0   78.0  77.0  153.0  119.0   83.0  75.0  ...   \n",
      "...     ...    ...    ...    ...    ...   ...    ...    ...    ...   ...  ...   \n",
      "9685   54.0  255.0  222.0  161.0   96.0  29.0   60.0   92.0   36.0  30.0  ...   \n",
      "9686   55.0  255.0   92.0  104.0  104.0  29.0   38.0  100.0  122.0  36.0  ...   \n",
      "9687   53.0  254.0  109.0   75.0  101.0  31.0   41.0   93.0   60.0  32.0  ...   \n",
      "9688   53.0  255.0  113.0   86.0   94.0  23.0   38.0   91.0   33.0  27.0  ...   \n",
      "9689   41.0  248.0  255.0   70.0   91.0  36.0   34.0   82.0  214.0  28.0  ...   \n",
      "\n",
      "       1264   2090  1815   1766    661   2122    409   1497    628  label  \n",
      "0     234.0  119.0  87.0   81.0   85.0  102.0   95.0  132.0  166.0      0  \n",
      "1     194.0  137.0  75.0   77.0   88.0  111.0   83.0  167.0  182.0      0  \n",
      "2     227.0  128.0  72.0   75.0   87.0  131.0  102.0  167.0  173.0      0  \n",
      "3     225.0  123.0  72.0   82.0   85.0  118.0  135.0  165.0  175.0      0  \n",
      "4     224.0  116.0  85.0  105.0   75.0  118.0   79.0  126.0  127.0      0  \n",
      "...     ...    ...   ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "9685   38.0   97.0  18.0   17.0   57.0   53.0  104.0   76.0  255.0      1  \n",
      "9686   60.0   81.0  17.0   17.0  119.0   77.0   98.0  109.0  255.0      1  \n",
      "9687   80.0   92.0  16.0   17.0   83.0   52.0   63.0   87.0  255.0      1  \n",
      "9688   58.0   89.0  15.0   15.0   22.0   47.0   83.0  118.0  192.0      1  \n",
      "9689   66.0   83.0  14.0   13.0   29.0   45.0  134.0  144.0  255.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  0\n",
      "Accuracy: 0.8796009631922944\n",
      "F1 Score: 0.840835167070912\n",
      "Precision: 0.9713255757983613\n",
      "Recall/Sensitivity/True Positive Rate: 0.8796009631922944\n",
      "Confusion Matrix:\n",
      " [[  42  327]\n",
      " [  23 2515]]\n",
      "\n",
      "\n",
      "       1432     52   1733    637   1262    829  1388    280    635   1423  \\\n",
      "0      89.0   89.0   94.0  115.0  176.0  100.0  89.0  111.0  115.0  178.0   \n",
      "1      91.0   79.0  111.0  110.0  100.0  117.0  85.0   78.0  119.0  147.0   \n",
      "2      87.0   88.0  120.0  119.0  153.0   97.0  83.0   70.0  115.0  152.0   \n",
      "3      82.0   98.0  105.0  129.0  142.0   81.0  78.0   71.0  122.0  197.0   \n",
      "4     116.0   84.0  179.0  131.0  158.0  128.0  76.0   68.0  127.0  157.0   \n",
      "...     ...    ...    ...    ...    ...    ...   ...    ...    ...    ...   \n",
      "9685   42.0  199.0   43.0  255.0   20.0  208.0  38.0  232.0  201.0  102.0   \n",
      "9686   52.0  205.0   47.0  206.0   19.0  217.0  37.0   19.0  170.0   95.0   \n",
      "9687   37.0  255.0   38.0  255.0   17.0  251.0  31.0  105.0  255.0   87.0   \n",
      "9688   38.0  255.0   55.0   76.0   16.0   99.0  26.0   96.0  221.0   80.0   \n",
      "9689   25.0  255.0   82.0  254.0   15.0  102.0  85.0  169.0  255.0   80.0   \n",
      "\n",
      "      ...   2221  1773  1868    739    828   2022   1876   1609   1377  label  \n",
      "0     ...   88.0  77.0  80.0   83.0  109.0  117.0   83.0  234.0  151.0      1  \n",
      "1     ...   93.0  83.0  83.0   80.0  112.0  111.0  131.0  236.0  158.0      1  \n",
      "2     ...   88.0  81.0  85.0  115.0  112.0  104.0  118.0  234.0  153.0      1  \n",
      "3     ...   73.0  84.0  84.0  154.0  100.0   95.0  178.0  221.0  180.0      1  \n",
      "4     ...  139.0  77.0  72.0   77.0  131.0  114.0  121.0  209.0  132.0      1  \n",
      "...   ...    ...   ...   ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "9685  ...  104.0  35.0  37.0   19.0  226.0   30.0   57.0   37.0   19.0      1  \n",
      "9686  ...   99.0  40.0  39.0   18.0  165.0   21.0   57.0   46.0   20.0      1  \n",
      "9687  ...  101.0  33.0  30.0   17.0  212.0   20.0   32.0   38.0   21.0      1  \n",
      "9688  ...   95.0  37.0  34.0   16.0  226.0   22.0   37.0   26.0   20.0      1  \n",
      "9689  ...   91.0  23.0  39.0   15.0   81.0   21.0   59.0   40.0   17.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  1\n",
      "Accuracy: 0.6824905400756794\n",
      "F1 Score: 0.6659160189027782\n",
      "Precision: 0.7279689983916663\n",
      "Recall/Sensitivity/True Positive Rate: 0.6824905400756794\n",
      "Confusion Matrix:\n",
      " [[ 369  606]\n",
      " [ 317 1615]]\n",
      "\n",
      "\n",
      "       1997    166   335   1765   1780    845    281    638   1561    148  \\\n",
      "0     126.0  215.0  85.0   81.0   74.0  141.0  103.0  120.0  225.0   96.0   \n",
      "1     119.0  183.0  76.0   81.0  149.0  191.0   89.0  110.0  231.0   83.0   \n",
      "2     116.0  221.0  70.0   82.0  134.0  169.0   81.0  127.0  234.0  108.0   \n",
      "3     119.0  225.0  64.0   94.0  142.0  139.0   77.0  132.0  237.0  109.0   \n",
      "4     126.0  214.0  91.0  121.0  177.0  148.0   73.0  132.0  152.0  107.0   \n",
      "...     ...    ...   ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685   17.0  250.0  68.0   22.0   62.0   39.0  255.0  253.0   50.0  255.0   \n",
      "9686   16.0   26.0  17.0   21.0   48.0   24.0   21.0  153.0   41.0  255.0   \n",
      "9687   17.0  246.0  68.0   27.0   37.0   23.0  189.0  255.0   48.0  255.0   \n",
      "9688   16.0  220.0  74.0   25.0   45.0   18.0   80.0   31.0   36.0  255.0   \n",
      "9689   14.0   61.0  42.0   23.0   94.0   19.0  189.0  217.0   36.0   19.0   \n",
      "\n",
      "      ...    487    537   2293   1699   1023    136   284   1185    391  label  \n",
      "0     ...   80.0  109.0   94.0  101.0  153.0   98.0  71.0  168.0   81.0      1  \n",
      "1     ...  120.0  144.0   99.0   85.0   97.0   92.0  91.0  162.0   81.0      1  \n",
      "2     ...  118.0  143.0  103.0   95.0  156.0   89.0  90.0  175.0   73.0      1  \n",
      "3     ...  145.0  143.0  133.0   97.0  176.0   90.0  84.0  191.0   72.0      1  \n",
      "4     ...   75.0   81.0  103.0  164.0  110.0   84.0  97.0  144.0   92.0      1  \n",
      "...   ...    ...    ...    ...    ...    ...    ...   ...    ...    ...    ...  \n",
      "9685  ...  255.0  255.0   52.0  112.0   61.0  102.0  67.0   40.0  255.0      1  \n",
      "9686  ...  255.0  255.0   55.0  110.0   23.0   88.0  41.0   31.0  255.0      1  \n",
      "9687  ...  255.0  255.0   41.0  106.0   21.0  151.0  65.0   21.0   28.0      1  \n",
      "9688  ...  255.0  255.0   37.0   98.0   21.0  251.0  34.0   17.0  255.0      1  \n",
      "9689  ...  255.0  255.0   32.0   93.0   18.0   25.0  29.0   17.0  255.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  2\n",
      "Accuracy: 0.7003783969728242\n",
      "F1 Score: 0.68695212853178\n",
      "Precision: 0.7344234619779695\n",
      "Recall/Sensitivity/True Positive Rate: 0.7003783969728242\n",
      "Confusion Matrix:\n",
      " [[ 337  544]\n",
      " [ 327 1699]]\n",
      "\n",
      "\n",
      "      1772    481   670   1212   2245   1465   2023   2246  1389    274  ...  \\\n",
      "0     80.0  112.0  72.0   74.0   91.0  172.0  132.0   83.0  91.0  204.0  ...   \n",
      "1     87.0  112.0  72.0  120.0  100.0  168.0  100.0   95.0  84.0  166.0  ...   \n",
      "2     85.0  125.0  71.0   81.0  103.0  171.0   93.0   97.0  83.0   88.0  ...   \n",
      "3     83.0  127.0  65.0   79.0  126.0  190.0   90.0  109.0  78.0   64.0  ...   \n",
      "4     77.0  109.0  65.0   79.0   97.0  176.0   85.0   96.0  77.0  208.0  ...   \n",
      "...    ...    ...   ...    ...    ...    ...    ...    ...   ...    ...  ...   \n",
      "9685  36.0  255.0  38.0  102.0   52.0   85.0   19.0   37.0  35.0  226.0  ...   \n",
      "9686  37.0  255.0  27.0   93.0   56.0   69.0   18.0   36.0  34.0  215.0  ...   \n",
      "9687  29.0  255.0  30.0   88.0   42.0   59.0   18.0   41.0  30.0  133.0  ...   \n",
      "9688  24.0  255.0  20.0  142.0   39.0   64.0   17.0   39.0  30.0  238.0  ...   \n",
      "9689  34.0  226.0  28.0   72.0   33.0   52.0   17.0   34.0  67.0  239.0  ...   \n",
      "\n",
      "      1243    777   2204  2156    684  1677    314  2011    541  label  \n",
      "0     87.0  107.0  103.0  97.0  105.0  80.0  188.0  79.0  121.0      1  \n",
      "1     90.0  137.0   84.0  80.0  107.0  90.0  177.0  79.0  145.0      1  \n",
      "2     89.0  126.0   75.0  75.0  117.0  90.0   98.0  79.0  139.0      1  \n",
      "3     86.0  140.0   68.0  71.0  128.0  88.0   77.0  76.0  141.0      1  \n",
      "4     79.0  145.0   71.0  70.0  133.0  79.0  196.0  71.0   89.0      1  \n",
      "...    ...    ...    ...   ...    ...   ...    ...   ...    ...    ...  \n",
      "9685  34.0  255.0   26.0  29.0  238.0  40.0  205.0  50.0  255.0      1  \n",
      "9686  39.0  202.0   29.0  30.0  204.0  36.0  191.0  54.0  255.0      1  \n",
      "9687  38.0  255.0   34.0  30.0  255.0  31.0   53.0  65.0  255.0      1  \n",
      "9688  47.0   58.0   23.0  24.0   24.0  28.0  253.0  65.0  164.0      1  \n",
      "9689  68.0  251.0   35.0  29.0  255.0  53.0  254.0  65.0  158.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  3\n",
      "Accuracy: 0.7296181630546955\n",
      "F1 Score: 0.6925545518773143\n",
      "Precision: 0.8519568209571109\n",
      "Recall/Sensitivity/True Positive Rate: 0.7296181630546955\n",
      "Confusion Matrix:\n",
      " [[ 310  676]\n",
      " [ 110 1811]]\n",
      "\n",
      "\n",
      "      1676   2039   2051    581   2272    491  1677  1674   1921   1148  ...  \\\n",
      "0     83.0  135.0  108.0  143.0   95.0   84.0  80.0  89.0  125.0   85.0  ...   \n",
      "1     91.0  137.0  113.0  170.0   84.0   99.0  90.0  86.0  142.0   93.0  ...   \n",
      "2     88.0  123.0  112.0  164.0   82.0  133.0  90.0  80.0  146.0  101.0  ...   \n",
      "3     84.0  147.0   98.0  164.0   78.0  151.0  88.0  76.0  143.0   92.0  ...   \n",
      "4     76.0  114.0  126.0  116.0  125.0   81.0  79.0  75.0  144.0   76.0  ...   \n",
      "...    ...    ...    ...    ...    ...    ...   ...   ...    ...    ...  ...   \n",
      "9685  39.0   33.0   62.0  255.0  104.0  255.0  40.0  33.0  101.0   32.0  ...   \n",
      "9686  39.0   18.0   23.0  255.0  102.0  255.0  36.0  47.0   41.0   41.0  ...   \n",
      "9687  36.0   27.0   65.0  253.0  101.0  168.0  31.0  36.0   54.0   36.0  ...   \n",
      "9688  23.0   25.0   51.0  255.0   96.0  255.0  28.0  26.0   45.0   94.0  ...   \n",
      "9689  45.0   31.0   60.0  254.0   90.0  224.0  53.0  43.0   56.0   35.0  ...   \n",
      "\n",
      "        348   910   2182    470   1474   1103    921   2066      7  label  \n",
      "0     225.0  82.0   90.0   95.0   90.0   94.0  109.0  126.0  119.0      1  \n",
      "1     168.0  73.0   84.0   97.0  141.0   80.0  137.0  136.0  107.0      1  \n",
      "2     106.0  72.0  103.0   94.0  104.0   84.0  137.0  124.0  109.0      1  \n",
      "3      86.0  73.0   96.0   76.0   84.0   87.0  147.0  128.0   96.0      1  \n",
      "4     212.0  69.0  134.0   97.0  193.0   73.0  157.0  153.0  109.0      1  \n",
      "...     ...   ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "9685  255.0  48.0   96.0  103.0   20.0   36.0  252.0   60.0  255.0      1  \n",
      "9686  255.0  47.0   49.0  170.0   20.0   49.0  207.0   38.0  254.0      1  \n",
      "9687   40.0  39.0   92.0  199.0   23.0   33.0  107.0   41.0  255.0      1  \n",
      "9688  255.0  35.0   88.0   35.0   21.0   70.0  255.0   38.0  255.0      1  \n",
      "9689  155.0  17.0   85.0   33.0   18.0  137.0   26.0   34.0  212.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  4\n",
      "Accuracy: 0.52046783625731\n",
      "F1 Score: 0.48000633242161717\n",
      "Precision: 0.7679480647713061\n",
      "Recall/Sensitivity/True Positive Rate: 0.52046783625731\n",
      "Confusion Matrix:\n",
      " [[ 458 1269]\n",
      " [ 125 1055]]\n",
      "\n",
      "\n",
      "        464     74   1739   1361   1756    445   1874   1928    774     58  \\\n",
      "0      89.0  208.0   91.0  198.0  149.0  109.0  152.0  144.0  153.0  113.0   \n",
      "1     106.0  176.0  124.0  204.0  111.0   89.0  150.0  100.0  165.0   92.0   \n",
      "2     123.0  162.0  114.0  197.0  122.0  103.0  177.0  105.0  165.0  121.0   \n",
      "3     113.0  164.0  132.0  173.0   96.0  111.0  137.0   70.0  169.0  162.0   \n",
      "4      82.0  144.0  154.0  226.0  200.0   98.0  122.0   83.0  161.0  103.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  158.0   23.0   21.0  115.0   71.0  255.0   67.0   19.0  227.0  255.0   \n",
      "9686  203.0  255.0   29.0  111.0   80.0  255.0   58.0   18.0  228.0  134.0   \n",
      "9687   17.0  255.0   53.0  107.0   54.0   83.0   42.0   18.0  255.0  255.0   \n",
      "9688  119.0  103.0   23.0   99.0   42.0  253.0   47.0   16.0  253.0  236.0   \n",
      "9689  172.0   48.0   40.0   95.0   39.0  198.0   60.0   16.0  124.0   15.0   \n",
      "\n",
      "      ...   1921   1617  1865   1018   1909   811   1056   2054   615  label  \n",
      "0     ...  125.0  105.0  85.0  124.0   77.0  75.0  171.0   74.0  79.0      1  \n",
      "1     ...  142.0  106.0  84.0  114.0   91.0  77.0  118.0   94.0  78.0      1  \n",
      "2     ...  146.0   95.0  76.0  131.0   95.0  76.0  138.0   94.0  73.0      1  \n",
      "3     ...  143.0   95.0  73.0  139.0   99.0  76.0  136.0   95.0  76.0      1  \n",
      "4     ...  144.0  158.0  72.0  144.0  115.0  70.0  122.0  109.0  73.0      1  \n",
      "...   ...    ...    ...   ...    ...    ...   ...    ...    ...   ...    ...  \n",
      "9685  ...  101.0   93.0  55.0  246.0   16.0  46.0  108.0   67.0  60.0      1  \n",
      "9686  ...   41.0   89.0  58.0  144.0   16.0  44.0  255.0   26.0  57.0      1  \n",
      "9687  ...   54.0   84.0  26.0  113.0   16.0  21.0  202.0   77.0  27.0      1  \n",
      "9688  ...   45.0   77.0  24.0  252.0   15.0  19.0  255.0   59.0  28.0      1  \n",
      "9689  ...   56.0   77.0  21.0   28.0   13.0  18.0   98.0   65.0  28.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  5\n",
      "Accuracy: 0.5576195390436877\n",
      "F1 Score: 0.4186555600505352\n",
      "Precision: 0.9612976878531656\n",
      "Recall/Sensitivity/True Positive Rate: 0.5576195390436877\n",
      "Confusion Matrix:\n",
      " [[  37 1258]\n",
      " [  28 1584]]\n",
      "\n",
      "\n",
      "       2216   1948   1778    966    935   1063    963   956    830    374  \\\n",
      "0      75.0  132.0  125.0  135.0  228.0  139.0   88.0  78.0   92.0   68.0   \n",
      "1      76.0  119.0  166.0   92.0  197.0  107.0  165.0  83.0  108.0   79.0   \n",
      "2      82.0  115.0  141.0   94.0  204.0  126.0  140.0  79.0   85.0   89.0   \n",
      "3      77.0  110.0  155.0   80.0  179.0   93.0  159.0  76.0   76.0  101.0   \n",
      "4     106.0  107.0  180.0  161.0  236.0   98.0  166.0  76.0  110.0   76.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...   ...    ...    ...   \n",
      "9685   40.0   18.0   78.0  191.0  112.0  150.0  185.0  42.0  172.0  109.0   \n",
      "9686   29.0   17.0   76.0  227.0  107.0  211.0  228.0  40.0  244.0  217.0   \n",
      "9687   31.0   16.0   58.0  154.0  102.0  109.0  221.0  39.0  255.0  240.0   \n",
      "9688   33.0   15.0   40.0  255.0   98.0  255.0  255.0  35.0  148.0  160.0   \n",
      "9689   32.0   13.0  143.0   17.0   93.0  243.0   20.0  17.0  208.0   60.0   \n",
      "\n",
      "      ...    965   1433   1734     41    972   1049   1095   719    967  label  \n",
      "0     ...  129.0   88.0  119.0   85.0  104.0  102.0  106.0  75.0  128.0      1  \n",
      "1     ...   78.0   89.0  102.0  103.0  120.0   93.0  101.0  73.0  116.0      1  \n",
      "2     ...   73.0   84.0  110.0  104.0   98.0   84.0   96.0  70.0  120.0      1  \n",
      "3     ...   83.0   78.0   87.0   94.0   86.0   83.0  116.0  67.0  102.0      1  \n",
      "4     ...  160.0  106.0  177.0  103.0   98.0   91.0   99.0  65.0  162.0      1  \n",
      "...   ...    ...    ...    ...    ...    ...    ...    ...   ...    ...    ...  \n",
      "9685  ...  185.0   36.0   42.0   28.0  255.0   40.0   48.0  28.0  185.0      1  \n",
      "9686  ...  220.0   34.0   60.0  100.0  176.0   48.0   43.0  44.0  171.0      1  \n",
      "9687  ...  173.0   36.0   60.0  253.0  115.0   50.0   37.0  32.0  142.0      1  \n",
      "9688  ...  255.0   54.0   56.0  242.0  222.0  100.0   93.0  13.0  255.0      1  \n",
      "9689  ...   17.0   21.0   99.0   97.0   43.0   50.0   62.0  52.0   14.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  6\n",
      "Accuracy: 0.6487788097695218\n",
      "F1 Score: 0.5406714335178404\n",
      "Precision: 0.9499374305065909\n",
      "Recall/Sensitivity/True Positive Rate: 0.648778809769522\n",
      "Confusion Matrix:\n",
      " [[  72  989]\n",
      " [  32 1814]]\n",
      "\n",
      "\n",
      "       1382   1564   2290    314   2163   1948   1883   1013   1241   1835  \\\n",
      "0     107.0  230.0  105.0  188.0   92.0  132.0  104.0  125.0   91.0   99.0   \n",
      "1      95.0  235.0  142.0  177.0  103.0  119.0  127.0   83.0   95.0  125.0   \n",
      "2     104.0  235.0  144.0   98.0  112.0  115.0  120.0   76.0   88.0  117.0   \n",
      "3     104.0  233.0  114.0   77.0  106.0  110.0  139.0   90.0   80.0  136.0   \n",
      "4      73.0  164.0  108.0  196.0  143.0  107.0  145.0  108.0  106.0  149.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685   41.0   68.0  101.0  205.0   45.0   18.0   46.0  221.0   34.0   87.0   \n",
      "9686   40.0   61.0   98.0  191.0   36.0   17.0   80.0  229.0   39.0   89.0   \n",
      "9687   41.0   72.0   96.0   53.0   36.0   16.0   29.0  225.0   49.0  104.0   \n",
      "9688   35.0   76.0   90.0  253.0   38.0   15.0   32.0  255.0   99.0   89.0   \n",
      "9689   33.0   65.0   86.0  254.0   31.0   13.0   20.0   24.0   33.0   91.0   \n",
      "\n",
      "      ...  1535   1855   1806    531    213  1677    136    280    512  label  \n",
      "0     ...  90.0  134.0  143.0  139.0  212.0  80.0   98.0  111.0  118.0      1  \n",
      "1     ...  86.0  126.0  117.0  144.0  173.0  90.0   92.0   78.0  132.0      1  \n",
      "2     ...  84.0  123.0  116.0  149.0  213.0  90.0   89.0   70.0  120.0      1  \n",
      "3     ...  86.0  113.0  118.0  149.0  172.0  88.0   90.0   71.0  114.0      1  \n",
      "4     ...  80.0  131.0  166.0   97.0  190.0  79.0   84.0   68.0  100.0      1  \n",
      "...   ...   ...    ...    ...    ...    ...   ...    ...    ...    ...    ...  \n",
      "9685  ...  40.0   85.0   79.0  255.0  255.0  40.0  102.0  232.0  128.0      1  \n",
      "9686  ...  33.0  101.0   42.0  255.0   49.0  36.0   88.0   19.0  113.0      1  \n",
      "9687  ...  30.0   70.0   85.0  255.0  192.0  31.0  151.0  105.0   37.0      1  \n",
      "9688  ...  29.0   66.0   78.0  255.0  251.0  28.0  251.0   96.0  133.0      1  \n",
      "9689  ...  34.0   55.0   79.0  206.0   49.0  53.0   25.0  169.0   68.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  7\n",
      "Accuracy: 0.6171310629514963\n",
      "F1 Score: 0.49059398466163334\n",
      "Precision: 0.9646944606223494\n",
      "Recall/Sensitivity/True Positive Rate: 0.6171310629514963\n",
      "Confusion Matrix:\n",
      " [[  40 1088]\n",
      " [  25 1754]]\n",
      "\n",
      "\n",
      "        425    237   2084    129   1491    461   1322    218   2192    884  \\\n",
      "0      98.0   72.0   97.0  166.0  181.0   89.0  148.0  179.0  155.0  228.0   \n",
      "1     107.0   75.0  117.0  229.0  182.0   96.0  169.0  200.0  119.0  207.0   \n",
      "2      96.0   74.0  124.0  230.0  176.0  132.0  126.0  186.0  115.0  195.0   \n",
      "3      76.0   81.0  122.0  215.0  174.0  128.0  133.0  143.0   99.0  146.0   \n",
      "4      70.0   91.0  103.0  226.0  114.0   76.0  137.0  190.0  116.0  182.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  130.0  133.0  101.0   31.0   68.0  173.0   45.0  255.0  100.0   56.0   \n",
      "9686   69.0  225.0   64.0   30.0   79.0  239.0   36.0   20.0   71.0   91.0   \n",
      "9687   90.0  124.0   97.0  244.0   71.0   64.0   21.0  159.0   94.0   90.0   \n",
      "9688   27.0   25.0   96.0  255.0  116.0  124.0   17.0  255.0   89.0   84.0   \n",
      "9689   56.0   36.0   89.0  108.0  255.0  103.0   16.0  104.0   86.0   82.0   \n",
      "\n",
      "      ...    375    211    829    628    927    115  1389    338    450  label  \n",
      "0     ...   72.0  182.0  100.0  166.0  105.0  188.0  91.0   84.0   93.0      1  \n",
      "1     ...   78.0  208.0  117.0  182.0   80.0  227.0  84.0   73.0   94.0      1  \n",
      "2     ...   91.0  174.0   97.0  173.0  110.0  156.0  83.0   88.0  108.0      1  \n",
      "3     ...  102.0  176.0   81.0  175.0  135.0  147.0  78.0  100.0  124.0      1  \n",
      "4     ...   70.0  161.0  128.0  127.0   81.0  177.0  77.0   90.0   82.0      1  \n",
      "...   ...    ...    ...    ...    ...    ...    ...   ...    ...    ...    ...  \n",
      "9685  ...  101.0  255.0  208.0  255.0  161.0  227.0  35.0  255.0  179.0      1  \n",
      "9686  ...  137.0   36.0  217.0  255.0  104.0   92.0  34.0  255.0  255.0      1  \n",
      "9687  ...  249.0  255.0  251.0  255.0   75.0  254.0  30.0  204.0  135.0      1  \n",
      "9688  ...   81.0  255.0   99.0  192.0   86.0  254.0  30.0  255.0  251.0      1  \n",
      "9689  ...   86.0   58.0  102.0  255.0   70.0   88.0  67.0  238.0   79.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  8\n",
      "Accuracy: 0.8286893704850361\n",
      "F1 Score: 0.7977301904641446\n",
      "Precision: 0.8986401452810748\n",
      "Recall/Sensitivity/True Positive Rate: 0.8286893704850361\n",
      "Confusion Matrix:\n",
      " [[  52  372]\n",
      " [ 126 2357]]\n",
      "\n",
      "\n",
      "       1109    346     42    646    798   2256    492   1934   2170   1402  \\\n",
      "0     124.0  170.0   78.0   90.0   95.0   85.0   86.0  111.0   84.0  120.0   \n",
      "1      90.0  127.0   96.0   80.0  139.0   74.0  102.0  108.0   82.0  136.0   \n",
      "2      79.0  131.0   95.0   83.0  149.0   77.0  134.0   99.0   96.0  122.0   \n",
      "3      99.0   84.0   95.0  124.0  172.0   75.0  135.0  102.0   89.0  139.0   \n",
      "4     108.0  201.0   87.0  101.0   90.0  129.0   81.0   98.0  120.0  130.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  241.0  255.0   40.0   26.0   57.0   50.0  255.0   19.0   58.0  100.0   \n",
      "9686  169.0  254.0  104.0   62.0   80.0   43.0  255.0   19.0   53.0   87.0   \n",
      "9687  224.0   40.0  246.0   65.0   99.0   35.0  134.0   18.0   63.0   87.0   \n",
      "9688  255.0  254.0  189.0   71.0   61.0   33.0  214.0   16.0   58.0  130.0   \n",
      "9689  150.0  139.0   61.0   59.0   52.0   37.0  166.0   15.0   65.0   98.0   \n",
      "\n",
      "      ...     71   2176   1204    916    917   850  1679   2287   1855  label  \n",
      "0     ...  165.0   92.0  108.0  100.0  136.0  94.0  84.0  149.0  134.0      1  \n",
      "1     ...  192.0   94.0  123.0  118.0   87.0  78.0  80.0  104.0  126.0      1  \n",
      "2     ...  224.0  105.0  119.0  106.0   84.0  74.0  87.0   98.0  123.0      1  \n",
      "3     ...  236.0   93.0  111.0  122.0   78.0  79.0  88.0   95.0  113.0      1  \n",
      "4     ...  173.0  126.0  141.0  176.0  176.0  77.0  79.0   94.0  131.0      1  \n",
      "...   ...    ...    ...    ...    ...    ...   ...   ...    ...    ...    ...  \n",
      "9685  ...   27.0   84.0  153.0  184.0  157.0  50.0  39.0  100.0   85.0      0  \n",
      "9686  ...  247.0   36.0  189.0  254.0  247.0  67.0  34.0  100.0  101.0      0  \n",
      "9687  ...  217.0   89.0  210.0  190.0  163.0  54.0  27.0   94.0   70.0      0  \n",
      "9688  ...  204.0   83.0  255.0  255.0  255.0  10.0  37.0   89.0   66.0      0  \n",
      "9689  ...   48.0   88.0  255.0   78.0   43.0  66.0  23.0   85.0   55.0      0  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  9\n",
      "Accuracy: 0.9267285861713106\n",
      "F1 Score: 0.9144435925616496\n",
      "Precision: 0.9524633778175498\n",
      "Recall/Sensitivity/True Positive Rate: 0.9267285861713106\n",
      "Confusion Matrix:\n",
      " [[  12  148]\n",
      " [  65 2682]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in [5, 10, 20]:\n",
    "    for i in range(10):\n",
    "        strings=globals()[\"xy{}_{}\".format(i, x)]\n",
    "        print(strings)\n",
    "        print(\"The current Data frame is: \",i)\n",
    "        y_train=strings['label']\n",
    "        processed_df=strings.drop(columns=['label'])\n",
    "        naive_bayes_search(processed_df,y_train)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685    9\n",
      "9686    9\n",
      "9687    9\n",
      "9688    9\n",
      "9689    9\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685    9\n",
      "9686    9\n",
      "9687    9\n",
      "9688    9\n",
      "9689    9\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685    9\n",
      "9686    9\n",
      "9687    9\n",
      "9688    9\n",
      "9689    9\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "[-1  0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- 1016\n- 109\n- 1136\n- 1141\n- 1265\n- ...\nFeature names seen at fit time, yet now missing:\n- 1599\n- 595\n- 76\n- 908\n- 916\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\victo\\Documents\\year4\\F20DL\\labs\\DMML\\Coursework\\Part 1\\Feature_Selection.ipynb Cell 30\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/victo/Documents/year4/F20DL/labs/DMML/Coursework/Part%201/Feature_Selection.ipynb#X42sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m gnb \u001b[39min\u001b[39;00m gnbs:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/victo/Documents/year4/F20DL/labs/DMML/Coursework/Part%201/Feature_Selection.ipynb#X42sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mprint\u001b[39m(gnb\u001b[39m.\u001b[39mclasses_)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/victo/Documents/year4/F20DL/labs/DMML/Coursework/Part%201/Feature_Selection.ipynb#X42sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     predi \u001b[39m=\u001b[39m gnb\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/victo/Documents/year4/F20DL/labs/DMML/Coursework/Part%201/Feature_Selection.ipynb#X42sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     predis\u001b[39m.\u001b[39mappend(predi)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/victo/Documents/year4/F20DL/labs/DMML/Coursework/Part%201/Feature_Selection.ipynb#X42sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m y_pred_multilabel \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcolumn_stack(predis)\n",
      "File \u001b[1;32mc:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\naive_bayes.py:101\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[39mPerform classification on an array of test vectors X.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39m    Predicted target values for X.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    100\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 101\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_X(X)\n\u001b[0;32m    102\u001b[0m jll \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_joint_log_likelihood(X)\n\u001b[0;32m    103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_[np\u001b[39m.\u001b[39margmax(jll, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\naive_bayes.py:269\u001b[0m, in \u001b[0;36mGaussianNB._check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_X\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    268\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate X, used only in predict* methods.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:580\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_data\u001b[39m(\n\u001b[0;32m    510\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    511\u001b[0m     X\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_validation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params,\n\u001b[0;32m    517\u001b[0m ):\n\u001b[0;32m    518\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \n\u001b[0;32m    520\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[39m        validated.\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 580\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_feature_names(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    582\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    583\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    584\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m estimator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    585\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequires y to be passed, but the target y is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    586\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:507\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing_names \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    503\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    504\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n\u001b[1;32m--> 507\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- 1016\n- 109\n- 1136\n- 1141\n- 1265\n- ...\nFeature names seen at fit time, yet now missing:\n- 1599\n- 595\n- 76\n- 908\n- 916\n"
     ]
    }
   ],
   "source": [
    "gnbs = []\n",
    "\n",
    "# for x in [5, 10, 20]:\n",
    "for x in [5]:\n",
    "    for i in range(10):\n",
    "        strings=globals()[\"xy{}_{}\".format(i, x)]\n",
    "        # print(\"The current Data frame is: \",i)\n",
    "        y_train=strings['label']\n",
    "        y_train = y_train.replace({0: i, 1: -1})\n",
    "        print(y_train)\n",
    "        processed_df=strings.drop(columns=['label'])\n",
    "        # naive_bayes_search(processed_df,y_train)\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(processed_df, y_train, test_size=0.3,random_state=seed_value)\n",
    "        gnb = GaussianNB()\n",
    "        gnb.fit(X_train, Y_train)\n",
    "        gnbs.append(gnb)\n",
    "\n",
    "predis = []\n",
    "for gnb in gnbs:\n",
    "    gnb.classes_\n",
    "    predi = gnb.predict(X_test)\n",
    "    predis.append(predi)\n",
    "\n",
    "y_pred_multilabel = np.column_stack(predis)\n",
    "accuracy_score(Y_test, y_pred_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reduced_x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\anshu\\OneDrive\\Desktop\\Course\\F21DL\\DMML\\Coursework\\Part 1\\Feature_Selection_fixed.ipynb Cell 31\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m classifiers \u001b[39m=\u001b[39m [GaussianNB() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ovr \u001b[39m=\u001b[39m OneVsRestClassifier(GaussianNB(), n_jobs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_train, X_test, Y_train, Y_test \u001b[39m=\u001b[39m train_test_split(reduced_x_train, ytrainall, test_size\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m,random_state\u001b[39m=\u001b[39mseed_value)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m ovr\u001b[39m.\u001b[39mfit(X_train, Y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m predicted \u001b[39m=\u001b[39m ovr\u001b[39m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reduced_x_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "classifiers = [GaussianNB() for i in range(10)]\n",
    "ovr = OneVsRestClassifier(GaussianNB(), n_jobs=10)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(reduced_x_train, ytrainall, test_size=0.3,random_state=seed_value)\n",
    "\n",
    "ovr.fit(X_train, Y_train)\n",
    "predicted = ovr.predict(X_test)\n",
    "predicted_probs = ovr.predict_proba(X_test)\n",
    "\n",
    "# cross_val_scores = cross_val_score(gnb, X_train, Y_train, cv=5)  \n",
    "# print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "# print(\"Mean CV Score:\", cross_val_scores.mean())\n",
    "\n",
    "\n",
    "# train_sizes, train_scores, test_scores = learning_curve(gnb, X_train, Y_train, cv=5)\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Learning Curves\")\n",
    "# plt.xlabel(\"Training examples\")\n",
    "# plt.ylabel(\"Score\")\n",
    "# plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "# plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()\n",
    "\n",
    "accuracy = accuracy_score(Y_test,predicted )\n",
    "f1 = f1_score(predicted, Y_test, average=\"weighted\")\n",
    "conf_matrix = confusion_matrix(predicted, Y_test)\n",
    "precision = precision_score(Y_test, predicted, average=\"weighted\",zero_division=1)\n",
    "recall = recall_score(Y_test, predicted, average=\"weighted\")\n",
    "# roc = roc_auc_score(Y_test, predicted_probs, multi_class=\"ovr\", average=\"weighted\")\n",
    "# conf_matrices = multilabel_confusion_matrix(Y_test, predicted)\n",
    "# tp = conf_matrices[:,1,1]\n",
    "# fp = conf_matrices[:,0,1]\n",
    "# tn = conf_matrices[:,0,0]\n",
    "# fn = conf_matrices[:,1,0]\n",
    "# fpr = _nanaverage(fp/(tn + fp), tp + fn)\n",
    "# tnr = _nanaverage(tn/(tn + fp), tp + fn)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall/Sensitivity/True Positive Rate:\", recall)\n",
    "# print(\"Specificity:\", tnr)\n",
    "# print(\"False Positive Rate:\", fpr)\n",
    "# print(\"Area under ROC curve:\", roc)\n",
    "# print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xy3_4'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"xy{}_{}\".format(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
