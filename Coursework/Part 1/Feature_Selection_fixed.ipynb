{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix,multilabel_confusion_matrix,roc_auc_score,roc_curve,auc,ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import pandas as pd\n",
    "# from sklearn.metrics._classification import _nanaverage\n",
    "import seaborn as sns\n",
    "\n",
    "def naive_bayes_search_non_binary(df1, df2,seed_value=22):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(df1, df2, test_size=0.3,random_state=seed_value)\n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, Y_train)\n",
    "    \n",
    "    predicted = gnb.predict(X_test)\n",
    "    predicted_probs = gnb.predict_proba(X_test)\n",
    "    \n",
    "    # cross_val_scores = cross_val_score(gnb, X_train, Y_train, cv=5)  \n",
    "    # print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "    # print(\"Mean CV Score:\", cross_val_scores.mean())\n",
    "\n",
    "\n",
    "    # train_sizes, train_scores, test_scores = learning_curve(gnb, X_train, Y_train, cv=5)\n",
    "    # train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    # test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.title(\"Learning Curves\")\n",
    "    # plt.xlabel(\"Training examples\")\n",
    "    # plt.ylabel(\"Score\")\n",
    "    # plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    # plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    # plt.legend(loc=\"best\")\n",
    "    # plt.show()\n",
    "\n",
    "    accuracy = accuracy_score(Y_test,predicted )\n",
    "    f1 = f1_score(predicted, Y_test, average=\"weighted\")\n",
    "    conf_matrix = confusion_matrix(predicted, Y_test)\n",
    "    precision = precision_score(Y_test, predicted, average=\"weighted\",zero_division=1)\n",
    "    recall = recall_score(Y_test, predicted, average=\"weighted\")\n",
    "\n",
    "    Y_test_bin = label_binarize(Y_test, classes=[0, 1, 2,3,4,5,6,7,8,9])\n",
    "    roc = roc_auc_score(Y_test_bin, predicted_probs, multi_class=\"ovr\", average=\"weighted\")\n",
    "\n",
    "    conf_matrices = multilabel_confusion_matrix(Y_test, predicted)\n",
    "    tp = conf_matrices[:,1,1]\n",
    "    fp = conf_matrices[:,0,1]\n",
    "    tn = conf_matrices[:,0,0]\n",
    "    fn = conf_matrices[:,1,0]\n",
    "    # fpr = (fp/(tn + fp), tp + fn)\n",
    "    tnr = (tn/(tn + fp), tp + fn)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(Y_test_bin.ravel(), predicted_probs.ravel())\n",
    "\n",
    "\n",
    "    auc_val = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='AUC (area = %0.2f)' % auc_val)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    out=ConfusionMatrixDisplay(conf_matrix,display_labels=gnb.classes_)\n",
    "    out.plot()\n",
    "    plt.show()\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall/Sensitivity/True Positive Rate:\", recall)\n",
    "    print(\"Specificity:\", tnr)\n",
    "    print(\"False Positive Rate:\", fpr)\n",
    "    print(\"Area under ROC curve:\", roc)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "    return predicted\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix,multilabel_confusion_matrix,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "# from sklearn.metrics._classification import _nanaverage\n",
    "\n",
    "def naive_bayes_search(df1, df2,seed_value=22):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(df1, df2, test_size=0.3,random_state=seed_value)\n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, Y_train)\n",
    "    \n",
    "    predicted = gnb.predict(X_test)\n",
    "    predicted_probs = gnb.predict_proba(X_test)\n",
    "    \n",
    "    # cross_val_scores = cross_val_score(gnb, X_train, Y_train, cv=5)  \n",
    "    # print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "    # print(\"Mean CV Score:\", cross_val_scores.mean())\n",
    "\n",
    "\n",
    "    # train_sizes, train_scores, test_scores = learning_curve(gnb, X_train, Y_train, cv=5)\n",
    "    # train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    # test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.title(\"Learning Curves\")\n",
    "    # plt.xlabel(\"Training examples\")\n",
    "    # plt.ylabel(\"Score\")\n",
    "    # plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    # plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    # plt.legend(loc=\"best\")\n",
    "    # plt.show()\n",
    "\n",
    "    accuracy = accuracy_score(Y_test,predicted )\n",
    "    f1 = f1_score(predicted, Y_test, average=\"weighted\")\n",
    "    conf_matrix = confusion_matrix(predicted, Y_test)\n",
    "    precision = precision_score(Y_test, predicted, average=\"weighted\",zero_division=1)\n",
    "    recall = recall_score(Y_test, predicted, average=\"weighted\")\n",
    "    # roc = roc_auc_score(Y_test, predicted_probs, multi_class=\"ovr\", average=\"weighted\")\n",
    "    conf_matrices = multilabel_confusion_matrix(Y_test, predicted)\n",
    "    tp = conf_matrices[:,1,1]\n",
    "    fp = conf_matrices[:,0,1]\n",
    "    tn = conf_matrices[:,0,0]\n",
    "    fn = conf_matrices[:,1,0]\n",
    "    # fpr = _nanaverage(fp/(tn + fp), tp + fn)\n",
    "    # tnr = _nanaverage(tn/(tn + fp), tp + fn)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall/Sensitivity/True Positive Rate:\", recall)\n",
    "    # print(\"Specificity:\", tnr)\n",
    "    # print(\"False Positive Rate:\", fpr)\n",
    "    # print(\"Area under ROC curve:\", roc)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "    return predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "merged_data = pd.read_csv('processed_df.csv')\n",
    "# merged_data=pd.read_csv('Dataset/x_train_all.csv')\n",
    "ytrainall = pd.read_csv('Dataset/y_train_all.csv')\n",
    "merged_data = pd.concat([merged_data,ytrainall],axis = 1)\n",
    "merged_data=merged_data.rename(columns={merged_data.columns[-1]:'label'})\n",
    "merged_data=merged_data.rename(columns={merged_data.columns[0]:'labels'})\n",
    "merged_data=merged_data.drop(columns =['labels'])\n",
    "merged_data.columns.values[0] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2295</th>\n",
       "      <th>2296</th>\n",
       "      <th>2297</th>\n",
       "      <th>2298</th>\n",
       "      <th>2299</th>\n",
       "      <th>2300</th>\n",
       "      <th>2301</th>\n",
       "      <th>2302</th>\n",
       "      <th>2303</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>113</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>-114</td>\n",
       "      <td>-81</td>\n",
       "      <td>-104</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-121</td>\n",
       "      <td>83</td>\n",
       "      <td>104</td>\n",
       "      <td>124</td>\n",
       "      <td>-93</td>\n",
       "      <td>-74</td>\n",
       "      <td>-86</td>\n",
       "      <td>-107</td>\n",
       "      <td>-107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>-114</td>\n",
       "      <td>-93</td>\n",
       "      <td>-100</td>\n",
       "      <td>-124</td>\n",
       "      <td>111</td>\n",
       "      <td>-122</td>\n",
       "      <td>-86</td>\n",
       "      <td>-36</td>\n",
       "      <td>-51</td>\n",
       "      <td>...</td>\n",
       "      <td>-114</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>53</td>\n",
       "      <td>80</td>\n",
       "      <td>-120</td>\n",
       "      <td>-58</td>\n",
       "      <td>-51</td>\n",
       "      <td>-51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>106</td>\n",
       "      <td>120</td>\n",
       "      <td>113</td>\n",
       "      <td>118</td>\n",
       "      <td>-128</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>-114</td>\n",
       "      <td>124</td>\n",
       "      <td>102</td>\n",
       "      <td>78</td>\n",
       "      <td>73</td>\n",
       "      <td>104</td>\n",
       "      <td>-107</td>\n",
       "      <td>-72</td>\n",
       "      <td>-51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>78</td>\n",
       "      <td>99</td>\n",
       "      <td>106</td>\n",
       "      <td>-116</td>\n",
       "      <td>-93</td>\n",
       "      <td>-96</td>\n",
       "      <td>116</td>\n",
       "      <td>29</td>\n",
       "      <td>113</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>109</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "      <td>87</td>\n",
       "      <td>88</td>\n",
       "      <td>113</td>\n",
       "      <td>-86</td>\n",
       "      <td>-58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "      <td>106</td>\n",
       "      <td>123</td>\n",
       "      <td>-100</td>\n",
       "      <td>-93</td>\n",
       "      <td>77</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>113</td>\n",
       "      <td>-121</td>\n",
       "      <td>-95</td>\n",
       "      <td>-90</td>\n",
       "      <td>-110</td>\n",
       "      <td>-122</td>\n",
       "      <td>64</td>\n",
       "      <td>78</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  2295  2296  2297  \\\n",
       "0   78   71   71  113  125  125 -114  -81 -104 -100  ...  -121    83   104   \n",
       "1  120 -114  -93 -100 -124  111 -122  -86  -36  -51  ...  -114   120    90   \n",
       "2   85  106  120  113  118 -128 -100 -100   77   78  ...  -114   124   102   \n",
       "3   57   78   99  106 -116  -93  -96  116   29  113  ...   120   109    99   \n",
       "4   99   99   92   85  106  123 -100  -93   77   57  ...   113  -121   -95   \n",
       "\n",
       "   2298  2299  2300  2301  2302  2303  label  \n",
       "0   124   -93   -74   -86  -107  -107      0  \n",
       "1    53    80  -120   -58   -51   -51      0  \n",
       "2    78    73   104  -107   -72   -51      0  \n",
       "3   100    87    88   113   -86   -58      0  \n",
       "4   -90  -110  -122    64    78    99      0  \n",
       "\n",
       "[5 rows x 2305 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "x = merged_data.drop('label',axis=1)\n",
    "y = merged_data['label']\n",
    "\n",
    "svm = SVC(kernel='linear', decision_function_shape='ovr')\n",
    "\n",
    "svm.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_weights = svm.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([1599,   76,  595,  908,  916, 1859,  379, 1282,  839,  755,  211,\n",
      "        994, 1332, 1844,  869,  551, 1046, 1984, 2254, 1841], dtype=int64), 1: array([1468,  484,  562,  743,  750, 2131,  375, 1228,   62,  190, 1885,\n",
      "       1711, 2201,  647, 1866, 1783, 2249, 1369,   76,  656], dtype=int64), 2: array([ 619,  541, 1601,  495, 1760, 1119,  916,  721,  954, 1976, 1821,\n",
      "       1456, 1689,  538,  615, 1695,  690, 2083,  989, 1024], dtype=int64), 3: array([1746, 1214, 2169,  548,  238,  589,  992,   66, 1799,  310, 1244,\n",
      "       1327, 1664, 2112, 2216,  955,  351, 1691,  443,  193], dtype=int64), 4: array([ 391, 1677, 1922, 1820,  129,  204, 1421,  163,  739, 1683,  860,\n",
      "        357, 1737, 1988, 1467,  746,  875,   85, 1170, 1116], dtype=int64), 5: array([1652,  773, 1815,  182,  225, 1301, 1190, 1086,  271, 1367, 1444,\n",
      "       2047, 1632, 1831, 1028,  897,  134, 1688,  342,  489], dtype=int64), 6: array([ 607, 1650, 1643,  598, 1188, 1751,  290, 2091, 1160,  285, 1309,\n",
      "       1250,  180,  277,  814, 1339, 1258,  674, 1548, 1610], dtype=int64), 7: array([2255, 1770, 1594, 1323,  719,  252,   55,  179,  962,  117,  505,\n",
      "       1312, 2043, 1677, 1596, 2194,  356,   52, 1017, 1006], dtype=int64), 8: array([1318, 2157,  240, 1764,  765,  778,  485,  931,   87, 1213, 2057,\n",
      "       2301,  676, 1233, 1158, 1091, 2039, 2082, 1298, 2131], dtype=int64), 9: array([ 482,  588,  655,  227, 1141, 1434, 2270,  683, 1560,  181, 1822,\n",
      "       1136, 1016, 1333,  699, 1857,  109, 1912, 1265, 2116], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "k = 20\n",
    "selected_features_per_class = {}\n",
    "for class_label in range(10): \n",
    "    feature_ranking = np.argsort(np.abs(feature_weights[class_label]))\n",
    "    selected_features = feature_ranking[:k]\n",
    "    selected_features_per_class[class_label] = selected_features\n",
    "\n",
    "print(selected_features_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = pd.read_csv('processed_df.csv')\n",
    "# xtrain = pd.read_csv('Dataset/x_train_all.csv')\n",
    "xtrain = xtrain.rename(columns={xtrain.columns[0]:'labels'})\n",
    "xtrain = xtrain.drop(columns=['labels'])\n",
    "ytrain0 = pd.read_csv('y_train_0.csv')\n",
    "ytrain3 = pd.read_csv('y_train_3.csv')\n",
    "ytrain1 = pd.read_csv('y_train_1.csv')\n",
    "ytrain2 = pd.read_csv('y_train_2.csv')\n",
    "ytrain4 = pd.read_csv('y_train_4.csv')\n",
    "ytrain5 = pd.read_csv('y_train_5.csv')\n",
    "ytrain6 = pd.read_csv('y_train_6.csv')\n",
    "ytrain7 = pd.read_csv('y_train_7.csv')\n",
    "ytrain8 = pd.read_csv('y_train_8.csv')\n",
    "ytrain9 = pd.read_csv('y_train_9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2294</th>\n",
       "      <th>2295</th>\n",
       "      <th>2296</th>\n",
       "      <th>2297</th>\n",
       "      <th>2298</th>\n",
       "      <th>2299</th>\n",
       "      <th>2300</th>\n",
       "      <th>2301</th>\n",
       "      <th>2302</th>\n",
       "      <th>2303</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>113</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>-114</td>\n",
       "      <td>-81</td>\n",
       "      <td>-104</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>-115</td>\n",
       "      <td>-121</td>\n",
       "      <td>83</td>\n",
       "      <td>104</td>\n",
       "      <td>124</td>\n",
       "      <td>-93</td>\n",
       "      <td>-74</td>\n",
       "      <td>-86</td>\n",
       "      <td>-107</td>\n",
       "      <td>-107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>-114</td>\n",
       "      <td>-93</td>\n",
       "      <td>-100</td>\n",
       "      <td>-124</td>\n",
       "      <td>111</td>\n",
       "      <td>-122</td>\n",
       "      <td>-86</td>\n",
       "      <td>-36</td>\n",
       "      <td>-51</td>\n",
       "      <td>...</td>\n",
       "      <td>-118</td>\n",
       "      <td>-114</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>53</td>\n",
       "      <td>80</td>\n",
       "      <td>-120</td>\n",
       "      <td>-58</td>\n",
       "      <td>-51</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>106</td>\n",
       "      <td>120</td>\n",
       "      <td>113</td>\n",
       "      <td>118</td>\n",
       "      <td>-128</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>-108</td>\n",
       "      <td>-114</td>\n",
       "      <td>124</td>\n",
       "      <td>102</td>\n",
       "      <td>78</td>\n",
       "      <td>73</td>\n",
       "      <td>104</td>\n",
       "      <td>-107</td>\n",
       "      <td>-72</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>78</td>\n",
       "      <td>99</td>\n",
       "      <td>106</td>\n",
       "      <td>-116</td>\n",
       "      <td>-93</td>\n",
       "      <td>-96</td>\n",
       "      <td>116</td>\n",
       "      <td>29</td>\n",
       "      <td>113</td>\n",
       "      <td>...</td>\n",
       "      <td>-66</td>\n",
       "      <td>120</td>\n",
       "      <td>109</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "      <td>87</td>\n",
       "      <td>88</td>\n",
       "      <td>113</td>\n",
       "      <td>-86</td>\n",
       "      <td>-58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "      <td>106</td>\n",
       "      <td>123</td>\n",
       "      <td>-100</td>\n",
       "      <td>-93</td>\n",
       "      <td>77</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>-128</td>\n",
       "      <td>113</td>\n",
       "      <td>-121</td>\n",
       "      <td>-95</td>\n",
       "      <td>-90</td>\n",
       "      <td>-110</td>\n",
       "      <td>-122</td>\n",
       "      <td>64</td>\n",
       "      <td>78</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  2294  2295  2296  \\\n",
       "0   78   71   71  113  125  125 -114  -81 -104 -100  ...  -115  -121    83   \n",
       "1  120 -114  -93 -100 -124  111 -122  -86  -36  -51  ...  -118  -114   120   \n",
       "2   85  106  120  113  118 -128 -100 -100   77   78  ...  -108  -114   124   \n",
       "3   57   78   99  106 -116  -93  -96  116   29  113  ...   -66   120   109   \n",
       "4   99   99   92   85  106  123 -100  -93   77   57  ...  -128   113  -121   \n",
       "\n",
       "   2297  2298  2299  2300  2301  2302  2303  \n",
       "0   104   124   -93   -74   -86  -107  -107  \n",
       "1    90    53    80  -120   -58   -51   -51  \n",
       "2   102    78    73   104  -107   -72   -51  \n",
       "3    99   100    87    88   113   -86   -58  \n",
       "4   -95   -90  -110  -122    64    78    99  \n",
       "\n",
       "[5 rows x 2304 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1599  76  595  908  916  1859  379  1282  839  755  ...  994  1332  \\\n",
      "0       71  -8  -76  114   80   104 -113  -113  -10  -81  ...   84    96   \n",
      "1      106 -91  -51  124  108  -118  -47    -7   -7  -60  ... -100    88   \n",
      "2       78 -57  114  126   89  -122  -67   -12   -1  -74  ... -126    60   \n",
      "3       92 -37   56 -125  121   -77 -109  -100  -20  -86  ... -100    46   \n",
      "4       78 -53  -88 -111  -23   -48 -110   -38  -23  -81  ...  -98  -100   \n",
      "...    ...  ..  ...  ...  ...   ...  ...   ...  ...  ...  ...  ...   ...   \n",
      "9685    85  74 -125 -104  -24  -108  -64   111  -32  111  ...   87  -100   \n",
      "9686    85  -1   90  -99   -1   -92   66    74  -42  -81  ...   98   -96   \n",
      "9687   120  -1   84  -94  -20   127  -48    58  -42   59  ...  102   -76   \n",
      "9688    92 -17   77  101   -1   118   45    44  -42   62  ...  -71   -90   \n",
      "9689    78  84   70   52  -99   127  106    57  -57   57  ...   40   120   \n",
      "\n",
      "      1844  869  551  1046  1984  2254  1841  label  \n",
      "0      114  -88 -108   -90   -52   -65   -63      0  \n",
      "1      -90   92 -107   -74   -61   -51   -90      0  \n",
      "2     -113   93  108   -72   -76   -79   -70      0  \n",
      "3      -95   91   35   -85   -69   -93   -99      0  \n",
      "4       25  -15  -80   117    78    85   110      0  \n",
      "...    ...  ...  ...   ...   ...   ...   ...    ...  \n",
      "9685   -55  -42   25    80    41    99   -48      1  \n",
      "9686   -44   -1   56   123    43    92   -62      1  \n",
      "9687   -62   -1   43   -94    41  -121   -55      1  \n",
      "9688   -64   -1   70   127    37    85   -56      1  \n",
      "9689   -85   -1   43    98    41   -93   -72      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "      1468  484  562  743  750  2131  375  1228  62  190  ...  1711  2201  \\\n",
      "0     -109  -78  123  115   71   104   66    -9 -24 -114  ...  -115  -128   \n",
      "1     -112  -91 -110  -79   82  -108   87   121 -37   92  ...   -97    76   \n",
      "2      -98  -79 -128  -44  117   -93 -100   -61  -1   92  ...  -120    85   \n",
      "3      -13  -64  120  -15  -90  -118  -46   -26  -1  113  ...   -81   109   \n",
      "4       35   87  -91   90   57   116   73  -115 -19  120  ...   -57   127   \n",
      "...    ...  ...  ...  ...  ...   ...  ...   ...  ..  ...  ...   ...   ...   \n",
      "9685    39   -1  -86  -41  114   106 -122   -48  -1   57  ...  -109    63   \n",
      "9686    28   -1   -1  -51 -108   -80  -53   -66  -1   -1  ...   -99    97   \n",
      "9687    46   -1 -122  -46  -15   112   -1   -87  -1  -36  ...  -113    69   \n",
      "9688    46   -1   53  -46  -40   100 -107   -98  -1   50  ...  -119    73   \n",
      "9689    37  -80   67  -44 -128    59  -74   -84 -24   99  ...  -111    99   \n",
      "\n",
      "      647  1866  1783  2249  1369  76  656  label  \n",
      "0      71  -128   -53   116    95  -8 -107      1  \n",
      "1      37   -93    51    83   -78 -91  122      1  \n",
      "2      72   118    62    95  -120 -57  125      1  \n",
      "3    -107   112    75   104   -70 -37  123      1  \n",
      "4     123    60   -42  -117   -63 -53  -51      1  \n",
      "...   ...   ...   ...   ...   ...  ..  ...    ...  \n",
      "9685  125   -98   -76    63    99  74 -107      1  \n",
      "9686  -90   -92  -125    97   116  -1  -65      1  \n",
      "9687  -81   -75    88    83   -92  -1   82      1  \n",
      "9688  -79   -76   124    66   -50 -17  103      1  \n",
      "9689  -98   -64    89    99   -75  84  107      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "      619  541  1601  495  1760  1119  916  721  954  1976  ...  1456  1689  \\\n",
      "0      80 -116  -117   48  -122   -29   80  -15 -120   -27  ...   -79   123   \n",
      "1      91  -69    87 -109   -92  -119  108  -15 -117  -123  ...  -122   -97   \n",
      "2     103  -69   123  -89   -84   -34   89  -15  102   107  ...   -72   -79   \n",
      "3     109  -52    57  -15   -73   -39  121  -22  108    78  ...   -91   -93   \n",
      "4      85   83   -84   46  -120   -53  -23  -65 -105    54  ...   -27   -24   \n",
      "...   ...  ...   ...  ...   ...   ...  ...  ...  ...   ...  ...   ...   ...   \n",
      "9685  118   -1   -17   -1   -46    52  -24   -1   82    45  ...   -48    66   \n",
      "9686  105   -1   -20   -1   -87    40   -1   -1  -62    44  ...   -85    35   \n",
      "9687   32   -1   -41   -1   -49    37  -20   -1  -80    34  ...   120    47   \n",
      "9688  111  -33   -31   -1   -62    45   -1 -121  105    42  ...  -127    49   \n",
      "9689  -41  -30   -41   -1   -58    35  -99   -1   47    44  ...  -119    47   \n",
      "\n",
      "      538  615  1695  690  2083  989  1024  label  \n",
      "0    -117  102   -93   96  -105  113   -63      1  \n",
      "1     -66   88   120  112   -74  103   -73      1  \n",
      "2     -63   85  -112   45   -45 -128   -56      1  \n",
      "3     -69   96  -100   82   -67  -63   -29      1  \n",
      "4      76   99    59 -124    99 -128   -71      1  \n",
      "...   ...  ...   ...  ...   ...  ...   ...    ...  \n",
      "9685   -1  110  -119 -119   -58   40    57      1  \n",
      "9686   -1  117   108   79   126   37    46      1  \n",
      "9687   -1   74   111   88   -53   44    44      1  \n",
      "9688   -1  103   115   68   -66   55    50      1  \n",
      "9689   -1   71   104   78   -56   40    32      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "      1746  1214  2169  548  238  589  992   66  1799  310  ...  1327  1664  \\\n",
      "0       76   -76    85  -95  121  -85  -76  -40    55  -17  ...  -110    94   \n",
      "1      104    85   113  -63   86  -67 -106   -1    46 -106  ...   -88    88   \n",
      "2       73   -96   120 -114   85  -81  -65  -54    58  112  ...  -109    66   \n",
      "3      104   -71  -121   77  107  -64  -75 -100   113   51  ...    99  -128   \n",
      "4       52   -70    99 -101 -106 -119  -49  -44   -84  -29  ...   -44   -90   \n",
      "...    ...   ...   ...  ...  ...  ...  ...  ...   ...  ...  ...   ...   ...   \n",
      "9685   -62    52    78   91  -88   -1  -99  106   -23  -91  ...   121   106   \n",
      "9686   -34    39    92   55   -1   -1  -86   -1   -27   64  ...  -110    93   \n",
      "9687   -82    35    92   47  127   -1  -75   -1   -33   76  ...   -88    82   \n",
      "9688  -102    43  -114   58   46  -91  -68   -1   -39   65  ...   -74    76   \n",
      "9689   -93    36    78   46  -63  -38  -83   -1   -39   49  ...  -109    76   \n",
      "\n",
      "      2112  2216  955  351  1691  443  193  label  \n",
      "0      -52    62  106  -65    75 -103   88      1  \n",
      "1      -71    74 -114  -72  -117   80   82      1  \n",
      "2      -65    87  118   90   127  121   70      1  \n",
      "3      -66    73  118   62  -100  -77   77      1  \n",
      "4      -35   110 -103  -72   -58 -117   70      1  \n",
      "...    ...   ...  ...  ...   ...  ...  ...    ...  \n",
      "9685   -66    80   93   -1    33   -1   -1      1  \n",
      "9686    83    62  -73   -1    32   -1   -1      1  \n",
      "9687  -122    76 -121 -112    66  -49   -1      1  \n",
      "9688  -126    64  -66   -1    43   -1   -1      1  \n",
      "9689   124    84   60   -1    57   -1   -1      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "      391  1677  1922  1820  129  204  1421  163  739  1683  ...  357  1737  \\\n",
      "0      63   112   -92  -116 -121  -10   112  127   49  -122  ...  -84  -124   \n",
      "1      79   -78  -108  -116  -58  -38    74  -65   59  -119  ...   92  -108   \n",
      "2      41   -72   -39  -101  -36   -7    90  111  125   -86  ...   50   -72   \n",
      "3      45   -77    79   -95  -51  -28   -79  -86  -90  -100  ...   89  -108   \n",
      "4     125  -102  -126   122  -44   -7   -62 -121   62   -17  ...  -69   -40   \n",
      "...   ...   ...   ...   ...  ...  ...   ...  ...  ...   ...  ...  ...   ...   \n",
      "9685   -1  -119   107  -108   92   -1   -60   -1   45   -95  ...  -86    46   \n",
      "9686   -1    83   120   104   99   98   -91   71   45   -86  ...  118    39   \n",
      "9687   71    98   113   102   -1   -1   121   -1   45   113  ...  116    39   \n",
      "9688   -1   124   -99   125   -1   -1    92   -1   42   120  ...  106    39   \n",
      "9689   -1   -65    77  -109  -72  -62  -112  -29   45    -1  ...   85    57   \n",
      "\n",
      "      1988  1467  746  875   85  1170  1116  label  \n",
      "0      -42  -128   74  123  104   -26    45      1  \n",
      "1      -52  -118  -74  120   64   -13  -118      1  \n",
      "2      -72  -118  -51   90   66   -20    36      1  \n",
      "3      -74   -33  -45  117 -103   -10    54      1  \n",
      "4      -65    39   97 -106   57   -89    50      1  \n",
      "...    ...   ...  ...  ...  ...   ...   ...    ...  \n",
      "9685    37    74   35   -1   30   -79    -1      1  \n",
      "9686    31    71   46 -119   -1   -54   117      1  \n",
      "9687    44    46   44  -81 -126   -52   -35      1  \n",
      "9688    36    71   51   -1   -1   -54    -1      1  \n",
      "9689    46    50   36  -99   90   -52    -1      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "      1652  773  1815  182  225  1301  1190  1086  271  1367  ...  2047  1632  \\\n",
      "0      -53  -51  -107  -74  -60   106   -70   100  -10   -49  ...  -125   -32   \n",
      "1       92  -44    71 -111  -66    80   127   -54  -76   -77  ...  -124   -45   \n",
      "2     -115  -55    64  124 -122   106   -92   -81   82   -48  ...   -73   -20   \n",
      "3       88  -59    71   87  102   118   -96   -55   39   108  ...   -73   -46   \n",
      "4      -27  -48    94 -121  -18    73    73   120  -41   -62  ...    88   -44   \n",
      "...    ...  ...   ...  ...  ...   ...   ...   ...  ...   ...  ...   ...   ...   \n",
      "9685   -17   -1    52 -106   -1  -112    74    40  -35    92  ...   108   -39   \n",
      "9686   -37   -1    50  -99   57    -1   111    37 -109  -128  ...    44    83   \n",
      "9687   -41   -1    50   -1  -44   113    74    48  -16   -72  ...   104   -94   \n",
      "9688   -32   -1    45  119   -1    -1   -50    57   -1   -51  ...    98    70   \n",
      "9689   -48  -81    54  -88   -1    -1   -46    42   -1   -75  ...   118    -1   \n",
      "\n",
      "      1831  1028  897  134  1688  342  489  label  \n",
      "0      -50    50   57  -99   -79 -116   63      1  \n",
      "1       50    52 -111   79  -121  -87  101      1  \n",
      "2       56   -94 -108   81   -71   72  -81      1  \n",
      "3       62   -44  -82   93  -123   55  -47      1  \n",
      "4      -74    70   88   80   -21   88   85      1  \n",
      "...    ...   ...  ...  ...   ...  ...  ...    ...  \n",
      "9685   109   -45  114  104   -72   -1   -1      1  \n",
      "9686    78   -47   64   -1   121   -1   -1      1  \n",
      "9687    58   -54   78   -1    74  101   -1      1  \n",
      "9688    70   -54   32 -102   101   -1   -1      1  \n",
      "9689    61   -63   92   36    94   -1   -1      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "      607  1650  1643  598  1188  1751  290  2091  1160  285  ...  1250  180  \\\n",
      "0     -87   115    91 -107    76  -126   99   101   -42   99  ...   -92  120   \n",
      "1     -71    40  -125 -124   113    73   78   -86   -60   94  ...   -76 -100   \n",
      "2    -101    77  -126   66    80    78  100  -105   -27  102  ...   -72 -104   \n",
      "3     -92    75  -107   65    42    49  117   127   -47  127  ...   126  -96   \n",
      "4     -59   -84   -71  -62  -106   -28   99   108   126  -70  ...   -82  -93   \n",
      "...   ...   ...   ...  ...   ...   ...  ...   ...   ...  ...  ...   ...  ...   \n",
      "9685  112   -91    36   34   -53   -26   -1   -70   -32  -72  ...   -42   -1   \n",
      "9686  -21  -115    28  100   115   -26   -1   -93   -60  -95  ...    -1  102   \n",
      "9687  -36   -43    33  104   -95   -34 -110   -74    89  104  ...   -60  -76   \n",
      "9688  -81   -52    40   96  -120   -24   -1   -81    -1   90  ...    -1  103   \n",
      "9689 -127   -53    43   66   -56   -43   -1   -86    -1 -102  ...    -1  -18   \n",
      "\n",
      "      277  814  1339  1258  674  1548  1610  label  \n",
      "0      82  118   118  -109  -31   -98    -1      1  \n",
      "1     -84  118  -119   -95  -20  -127    -1      1  \n",
      "2      55  110   123   -71  -13  -114   -13      1  \n",
      "3      43  118   118   -95  -26   -94   -53      1  \n",
      "4     -53  113   118   -94  -57    90   -51      1  \n",
      "...   ...  ...   ...   ...  ...   ...   ...    ...  \n",
      "9685  -48  117   118   124   -1    30    35      1  \n",
      "9686  110  -56   111   -73   -1    29    42      1  \n",
      "9687  -99  127   109    51   -1    35    22      1  \n",
      "9688  -21  -58    26    -1   74    42    22      1  \n",
      "9689 -106   91    16   -40   -1    40    57      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "      2255  1770  1594  1323  719  252   55  179  962  117  ...  1312  2043  \\\n",
      "0      -93   124   100   -93 -118  -16  -67  111   93   64  ...   -18  -125   \n",
      "1      -44   -97   -92    64 -121  -20  -81  -88  -12   50  ...   -57  -118   \n",
      "2      -58  -128  -107   106  127  -18 -112  -83  -22  -93  ...   -39   -82   \n",
      "3      -65   108   -85    64  114  -60  104  -93  -66  -58  ...   -31  -114   \n",
      "4      120    80   -77    50   98   -6 -105  -86  -53   78  ...    -7    82   \n",
      "...    ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
      "9685   106    74    62   113   51   -1   -1   -1  -97   -8  ...  -108    96   \n",
      "9686    64  -109    40   113 -121   -1  -65   73   -1  -36  ...   -74    42   \n",
      "9687   -79   -96    35   120   98  -13   -1   -1  -14   -1  ...   -77    85   \n",
      "9688    92   126    36   113   45   -1   -1 -105   -1   -1  ...   -79    82   \n",
      "9689    42   -96    53   120  -64  -42  104  -22   68  106  ...   -64   102   \n",
      "\n",
      "      1677  1596  2194  356   52  1017  1006  label  \n",
      "0      112  -100   100  -97 -125   120  -104      1  \n",
      "1      -78   117   -15  106 -111   -72  -119      1  \n",
      "2      -72  -118   -46   61 -120   -36  -127      1  \n",
      "3      -77   -93   124   88 -102   -22  -112      1  \n",
      "4     -102  -114   -96  -82 -127   -65   113      1  \n",
      "...    ...   ...   ...  ...  ...   ...   ...    ...  \n",
      "9685  -119    32   -40   -8   -1    -1   102      1  \n",
      "9686    83    28   -94   -1   -1    -8    79      1  \n",
      "9687    98    57   -42  -74   -1   -44    99      1  \n",
      "9688   124    46   -35   -8   -1    -1    -7      1  \n",
      "9689   -65    60   -53  -63   -1   -44    98      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "      1318  2157  240  1764  765  778  485  931   87  1213  ...  2301  676  \\\n",
      "0      -93   -65   64    85  120   90   88  -39  -72   117  ...   -86  -54   \n",
      "1     -120  -114   68   112 -128   75  -80  -67   92    73  ...   -58  -18   \n",
      "2      -80   119   57   120 -128   70 -118 -110 -107    76  ...  -107  -23   \n",
      "3      -36   118   57   -95 -114  109  -51  106 -128    99  ...   113  -28   \n",
      "4       97    88   52  -111  106 -103   55  -49  113   123  ...    64  -70   \n",
      "...    ...   ...  ...   ...  ...  ...  ...  ...  ...   ...  ...   ...  ...   \n",
      "9685   -91    91   -1  -111 -128   -1   -1   62   28   109  ...    99   -1   \n",
      "9686   105    78   -1   124  -86   -1   -1  107  -79    66  ...    71   -1   \n",
      "9687    68    70   -1   -79  113   -1   -1  120  -79    50  ...    92   -1   \n",
      "9688    50    77   -1   -77   35  -50   -1  116  -29    79  ...    92  103   \n",
      "9689    87   110   -1   -66 -107   -1   -1  106  120    60  ...    99   -1   \n",
      "\n",
      "      1233  1158  1091  2039  2082  1298  2131  label  \n",
      "0      -46   -42    47   -33   -95   120   104      1  \n",
      "1      -91    76  -118   -33   -68   106  -108      1  \n",
      "2      -31    90  -127   -58   -41  -128   -93      1  \n",
      "3      -22    66   123   -20   -67  -107  -118      1  \n",
      "4      113    50   -96  -108   101  -107   116      1  \n",
      "...    ...   ...   ...   ...   ...   ...   ...    ...  \n",
      "9685    71   -68  -104    85   -60  -107   106      1  \n",
      "9686    40    -1   -85    40   120    -1   -80      1  \n",
      "9687    42   -70   -80    80   -60   -72   112      1  \n",
      "9688    42    -1   116    77   -65    -1   100      1  \n",
      "9689    47    -1   -67    99   -52    -1    59      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "      482  588  655  227  1141  1434  2270  683  1560  181  ...  1136  1016  \\\n",
      "0    -108  -90 -101 -107  -128  -117    65  106   -31 -110  ...   -14  -116   \n",
      "1    -105  -70  124  -79    56   122    86  117   -16 -110  ...   120   -45   \n",
      "2     -62  -82   90 -105    50  -126    68   99   -10  125  ...   -79   -32   \n",
      "3     -76  -83   83  111    81   108    51  127    -1 -124  ...   -97   -48   \n",
      "4     -35 -116  -73  -52    47  -120   -77  -98   101 -100  ...    78   -76   \n",
      "...   ...  ...  ...  ...   ...   ...   ...  ...   ...  ...  ...   ...   ...   \n",
      "9685   -1   -1   94   -1   -74  -109   -17  -27   -67  -65  ...    66   -34   \n",
      "9686   -1   -1  -48  112  -108    58   -36 -103   -65 -126  ...    46   -28   \n",
      "9687   -1   -1  -95 -103    96    97   -27   -1   -98   -1  ...    42   -30   \n",
      "9688   -1 -100  113   -1    91    86   -34   90   -90  -93  ...    41    -1   \n",
      "9689  -47   -1   72   -1  -113    51   -52   -1   -74  -77  ...    43   -32   \n",
      "\n",
      "      1333  699  1857  109  1912  1265  2116  label  \n",
      "0     -107   62  -101  -39   -85   -10  -111      1  \n",
      "1       64   86   -64  -34    94    -6   -89      1  \n",
      "2       61 -116   -53   -1    77    -5   -93      1  \n",
      "3      118  -96   -82   -1    90   -20   -94      1  \n",
      "4       75   54   110  -10    96    -6    84      1  \n",
      "...    ...  ...   ...  ...   ...   ...   ...    ...  \n",
      "9685   123   68  -101   -1    59   -71   114      0  \n",
      "9686   118   51   -68  -58    65   -54  -111      0  \n",
      "9687  -112   64  -128   -1    47   -63   119      0  \n",
      "9688   101   43   126   -1    41   -61   109      0  \n",
      "9689   -39   42  -124  -98    45   -48    79      0  \n",
      "\n",
      "[9690 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "xy0_20 = None\n",
    "for i in selected_features_per_class[0]:\n",
    "    xy0_20 = pd.concat([xy0_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy0_20 = pd.concat([xy0_20,ytrain0],axis=1)\n",
    "xy0_20 = xy0_20.rename(columns={xy0_20.columns[-1]:'label'})\n",
    "print(xy0_20)\n",
    "    \n",
    "xy1_20 = None\n",
    "for i in selected_features_per_class[1]:\n",
    "    xy1_20 = pd.concat([xy1_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy1_20 = pd.concat([xy1_20,ytrain1],axis=1)\n",
    "xy1_20 = xy1_20.rename(columns={xy1_20.columns[-1]:'label'})\n",
    "print(xy1_20)\n",
    "\n",
    "xy2_20 = None\n",
    "for i in selected_features_per_class[2]:\n",
    "    xy2_20 = pd.concat([xy2_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy2_20 = pd.concat([xy2_20,ytrain2],axis=1)\n",
    "xy2_20 = xy2_20.rename(columns={xy2_20.columns[-1]:'label'})\n",
    "print(xy2_20)\n",
    "\n",
    "xy3_20 = None\n",
    "for i in selected_features_per_class[3]:\n",
    "    xy3_20 = pd.concat([xy3_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy3_20 = pd.concat([xy3_20,ytrain3],axis=1)\n",
    "xy3_20 = xy3_20.rename(columns={xy3_20.columns[-1]:'label'})\n",
    "print(xy3_20)\n",
    "\n",
    "xy4_20 = None\n",
    "for i in selected_features_per_class[4]:\n",
    "    xy4_20 = pd.concat([xy4_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy4_20 = pd.concat([xy4_20,ytrain4],axis=1)\n",
    "xy4_20 = xy4_20.rename(columns={xy4_20.columns[-1]:'label'})\n",
    "print(xy4_20)\n",
    "\n",
    "xy5_20 = None\n",
    "for i in selected_features_per_class[5]:\n",
    "    xy5_20 = pd.concat([xy5_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy5_20 = pd.concat([xy5_20,ytrain5],axis=1)\n",
    "xy5_20 = xy5_20.rename(columns={xy5_20.columns[-1]:'label'})\n",
    "print(xy5_20)\n",
    "\n",
    "xy6_20 = None\n",
    "for i in selected_features_per_class[6]:\n",
    "    xy6_20 = pd.concat([xy6_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy6_20 = pd.concat([xy6_20,ytrain6],axis=1)\n",
    "xy6_20 = xy6_20.rename(columns={xy6_20.columns[-1]:'label'})\n",
    "print(xy6_20)\n",
    "\n",
    "xy7_20 = None\n",
    "for i in selected_features_per_class[7]:\n",
    "    xy7_20 = pd.concat([xy7_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy7_20 = pd.concat([xy7_20,ytrain7],axis=1)\n",
    "xy7_20 = xy7_20.rename(columns={xy7_20.columns[-1]:'label'})\n",
    "print(xy7_20)\n",
    "\n",
    "xy8_20 = None\n",
    "for i in selected_features_per_class[8]:\n",
    "    xy8_20 = pd.concat([xy8_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy8_20 = pd.concat([xy8_20,ytrain8],axis=1)\n",
    "xy8_20 = xy8_20.rename(columns={xy8_20.columns[-1]:'label'})\n",
    "print(xy8_20)\n",
    "\n",
    "xy9_20 = None\n",
    "for i in selected_features_per_class[9]:\n",
    "    xy9_20 = pd.concat([xy9_20,xtrain.iloc[:,int(i)]],axis=1)\n",
    "xy9_20 = pd.concat([xy9_20,ytrain9],axis=1)\n",
    "xy9_20 = xy9_20.rename(columns={xy9_20.columns[-1]:'label'})\n",
    "print(xy9_20)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1599  76  595  908  916  1859  379  1282  839  755  label\n",
      "0       71  -8  -76  114   80   104 -113  -113  -10  -81      0\n",
      "1      106 -91  -51  124  108  -118  -47    -7   -7  -60      0\n",
      "2       78 -57  114  126   89  -122  -67   -12   -1  -74      0\n",
      "3       92 -37   56 -125  121   -77 -109  -100  -20  -86      0\n",
      "4       78 -53  -88 -111  -23   -48 -110   -38  -23  -81      0\n",
      "...    ...  ..  ...  ...  ...   ...  ...   ...  ...  ...    ...\n",
      "9685    85  74 -125 -104  -24  -108  -64   111  -32  111      1\n",
      "9686    85  -1   90  -99   -1   -92   66    74  -42  -81      1\n",
      "9687   120  -1   84  -94  -20   127  -48    58  -42   59      1\n",
      "9688    92 -17   77  101   -1   118   45    44  -42   62      1\n",
      "9689    78  84   70   52  -99   127  106    57  -57   57      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "      1468  484  562  743  750  2131  375  1228  62  190  label\n",
      "0     -109  -78  123  115   71   104   66    -9 -24 -114      1\n",
      "1     -112  -91 -110  -79   82  -108   87   121 -37   92      1\n",
      "2      -98  -79 -128  -44  117   -93 -100   -61  -1   92      1\n",
      "3      -13  -64  120  -15  -90  -118  -46   -26  -1  113      1\n",
      "4       35   87  -91   90   57   116   73  -115 -19  120      1\n",
      "...    ...  ...  ...  ...  ...   ...  ...   ...  ..  ...    ...\n",
      "9685    39   -1  -86  -41  114   106 -122   -48  -1   57      1\n",
      "9686    28   -1   -1  -51 -108   -80  -53   -66  -1   -1      1\n",
      "9687    46   -1 -122  -46  -15   112   -1   -87  -1  -36      1\n",
      "9688    46   -1   53  -46  -40   100 -107   -98  -1   50      1\n",
      "9689    37  -80   67  -44 -128    59  -74   -84 -24   99      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "      619  541  1601  495  1760  1119  916  721  954  1976  label\n",
      "0      80 -116  -117   48  -122   -29   80  -15 -120   -27      1\n",
      "1      91  -69    87 -109   -92  -119  108  -15 -117  -123      1\n",
      "2     103  -69   123  -89   -84   -34   89  -15  102   107      1\n",
      "3     109  -52    57  -15   -73   -39  121  -22  108    78      1\n",
      "4      85   83   -84   46  -120   -53  -23  -65 -105    54      1\n",
      "...   ...  ...   ...  ...   ...   ...  ...  ...  ...   ...    ...\n",
      "9685  118   -1   -17   -1   -46    52  -24   -1   82    45      1\n",
      "9686  105   -1   -20   -1   -87    40   -1   -1  -62    44      1\n",
      "9687   32   -1   -41   -1   -49    37  -20   -1  -80    34      1\n",
      "9688  111  -33   -31   -1   -62    45   -1 -121  105    42      1\n",
      "9689  -41  -30   -41   -1   -58    35  -99   -1   47    44      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "      1746  1214  2169  548  238  589  992   66  1799  310  label\n",
      "0       76   -76    85  -95  121  -85  -76  -40    55  -17      1\n",
      "1      104    85   113  -63   86  -67 -106   -1    46 -106      1\n",
      "2       73   -96   120 -114   85  -81  -65  -54    58  112      1\n",
      "3      104   -71  -121   77  107  -64  -75 -100   113   51      1\n",
      "4       52   -70    99 -101 -106 -119  -49  -44   -84  -29      1\n",
      "...    ...   ...   ...  ...  ...  ...  ...  ...   ...  ...    ...\n",
      "9685   -62    52    78   91  -88   -1  -99  106   -23  -91      1\n",
      "9686   -34    39    92   55   -1   -1  -86   -1   -27   64      1\n",
      "9687   -82    35    92   47  127   -1  -75   -1   -33   76      1\n",
      "9688  -102    43  -114   58   46  -91  -68   -1   -39   65      1\n",
      "9689   -93    36    78   46  -63  -38  -83   -1   -39   49      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "      391  1677  1922  1820  129  204  1421  163  739  1683  label\n",
      "0      63   112   -92  -116 -121  -10   112  127   49  -122      1\n",
      "1      79   -78  -108  -116  -58  -38    74  -65   59  -119      1\n",
      "2      41   -72   -39  -101  -36   -7    90  111  125   -86      1\n",
      "3      45   -77    79   -95  -51  -28   -79  -86  -90  -100      1\n",
      "4     125  -102  -126   122  -44   -7   -62 -121   62   -17      1\n",
      "...   ...   ...   ...   ...  ...  ...   ...  ...  ...   ...    ...\n",
      "9685   -1  -119   107  -108   92   -1   -60   -1   45   -95      1\n",
      "9686   -1    83   120   104   99   98   -91   71   45   -86      1\n",
      "9687   71    98   113   102   -1   -1   121   -1   45   113      1\n",
      "9688   -1   124   -99   125   -1   -1    92   -1   42   120      1\n",
      "9689   -1   -65    77  -109  -72  -62  -112  -29   45    -1      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "      1652  773  1815  182  225  1301  1190  1086  271  1367  label\n",
      "0      -53  -51  -107  -74  -60   106   -70   100  -10   -49      1\n",
      "1       92  -44    71 -111  -66    80   127   -54  -76   -77      1\n",
      "2     -115  -55    64  124 -122   106   -92   -81   82   -48      1\n",
      "3       88  -59    71   87  102   118   -96   -55   39   108      1\n",
      "4      -27  -48    94 -121  -18    73    73   120  -41   -62      1\n",
      "...    ...  ...   ...  ...  ...   ...   ...   ...  ...   ...    ...\n",
      "9685   -17   -1    52 -106   -1  -112    74    40  -35    92      1\n",
      "9686   -37   -1    50  -99   57    -1   111    37 -109  -128      1\n",
      "9687   -41   -1    50   -1  -44   113    74    48  -16   -72      1\n",
      "9688   -32   -1    45  119   -1    -1   -50    57   -1   -51      1\n",
      "9689   -48  -81    54  -88   -1    -1   -46    42   -1   -75      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "      607  1650  1643  598  1188  1751  290  2091  1160  285  label\n",
      "0     -87   115    91 -107    76  -126   99   101   -42   99      1\n",
      "1     -71    40  -125 -124   113    73   78   -86   -60   94      1\n",
      "2    -101    77  -126   66    80    78  100  -105   -27  102      1\n",
      "3     -92    75  -107   65    42    49  117   127   -47  127      1\n",
      "4     -59   -84   -71  -62  -106   -28   99   108   126  -70      1\n",
      "...   ...   ...   ...  ...   ...   ...  ...   ...   ...  ...    ...\n",
      "9685  112   -91    36   34   -53   -26   -1   -70   -32  -72      1\n",
      "9686  -21  -115    28  100   115   -26   -1   -93   -60  -95      1\n",
      "9687  -36   -43    33  104   -95   -34 -110   -74    89  104      1\n",
      "9688  -81   -52    40   96  -120   -24   -1   -81    -1   90      1\n",
      "9689 -127   -53    43   66   -56   -43   -1   -86    -1 -102      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "      2255  1770  1594  1323  719  252   55  179  962  117  label\n",
      "0      -93   124   100   -93 -118  -16  -67  111   93   64      1\n",
      "1      -44   -97   -92    64 -121  -20  -81  -88  -12   50      1\n",
      "2      -58  -128  -107   106  127  -18 -112  -83  -22  -93      1\n",
      "3      -65   108   -85    64  114  -60  104  -93  -66  -58      1\n",
      "4      120    80   -77    50   98   -6 -105  -86  -53   78      1\n",
      "...    ...   ...   ...   ...  ...  ...  ...  ...  ...  ...    ...\n",
      "9685   106    74    62   113   51   -1   -1   -1  -97   -8      1\n",
      "9686    64  -109    40   113 -121   -1  -65   73   -1  -36      1\n",
      "9687   -79   -96    35   120   98  -13   -1   -1  -14   -1      1\n",
      "9688    92   126    36   113   45   -1   -1 -105   -1   -1      1\n",
      "9689    42   -96    53   120  -64  -42  104  -22   68  106      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "      1318  2157  240  1764  765  778  485  931   87  1213  label\n",
      "0      -93   -65   64    85  120   90   88  -39  -72   117      1\n",
      "1     -120  -114   68   112 -128   75  -80  -67   92    73      1\n",
      "2      -80   119   57   120 -128   70 -118 -110 -107    76      1\n",
      "3      -36   118   57   -95 -114  109  -51  106 -128    99      1\n",
      "4       97    88   52  -111  106 -103   55  -49  113   123      1\n",
      "...    ...   ...  ...   ...  ...  ...  ...  ...  ...   ...    ...\n",
      "9685   -91    91   -1  -111 -128   -1   -1   62   28   109      1\n",
      "9686   105    78   -1   124  -86   -1   -1  107  -79    66      1\n",
      "9687    68    70   -1   -79  113   -1   -1  120  -79    50      1\n",
      "9688    50    77   -1   -77   35  -50   -1  116  -29    79      1\n",
      "9689    87   110   -1   -66 -107   -1   -1  106  120    60      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "      482  588  655  227  1141  1434  2270  683  1560  181  label\n",
      "0    -108  -90 -101 -107  -128  -117    65  106   -31 -110      1\n",
      "1    -105  -70  124  -79    56   122    86  117   -16 -110      1\n",
      "2     -62  -82   90 -105    50  -126    68   99   -10  125      1\n",
      "3     -76  -83   83  111    81   108    51  127    -1 -124      1\n",
      "4     -35 -116  -73  -52    47  -120   -77  -98   101 -100      1\n",
      "...   ...  ...  ...  ...   ...   ...   ...  ...   ...  ...    ...\n",
      "9685   -1   -1   94   -1   -74  -109   -17  -27   -67  -65      0\n",
      "9686   -1   -1  -48  112  -108    58   -36 -103   -65 -126      0\n",
      "9687   -1   -1  -95 -103    96    97   -27   -1   -98   -1      0\n",
      "9688   -1 -100  113   -1    91    86   -34   90   -90  -93      0\n",
      "9689  -47   -1   72   -1  -113    51   -52   -1   -74  -77      0\n",
      "\n",
      "[9690 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "xy0_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[0]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy0_10 = pd.concat([xy0_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy0_10 = pd.concat([xy0_10,ytrain0],axis=1)\n",
    "xy0_10 = xy0_10.rename(columns={xy0_10.columns[-1]:'label'})\n",
    "print(xy0_10)\n",
    "    \n",
    "xy1_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[1]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy1_10 = pd.concat([xy1_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy1_10 = pd.concat([xy1_10,ytrain1],axis=1)\n",
    "xy1_10 = xy1_10.rename(columns={xy1_10.columns[-1]:'label'})\n",
    "print(xy1_10)\n",
    "\n",
    "xy2_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[2]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy2_10 = pd.concat([xy2_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy2_10 = pd.concat([xy2_10,ytrain2],axis=1)\n",
    "xy2_10 = xy2_10.rename(columns={xy2_10.columns[-1]:'label'})\n",
    "print(xy2_10)\n",
    "\n",
    "xy3_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[3]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy3_10 = pd.concat([xy3_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy3_10 = pd.concat([xy3_10,ytrain3],axis=1)\n",
    "xy3_10 = xy3_10.rename(columns={xy3_10.columns[-1]:'label'})\n",
    "print(xy3_10)\n",
    "\n",
    "xy4_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[4]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy4_10 = pd.concat([xy4_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy4_10 = pd.concat([xy4_10,ytrain4],axis=1)\n",
    "xy4_10 = xy4_10.rename(columns={xy4_10.columns[-1]:'label'})\n",
    "print(xy4_10)\n",
    "\n",
    "xy5_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[5]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy5_10 = pd.concat([xy5_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy5_10 = pd.concat([xy5_10,ytrain5],axis=1)\n",
    "xy5_10 = xy5_10.rename(columns={xy5_10.columns[-1]:'label'})\n",
    "print(xy5_10)\n",
    "\n",
    "xy6_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[6]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy6_10 = pd.concat([xy6_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy6_10 = pd.concat([xy6_10,ytrain6],axis=1)\n",
    "xy6_10 = xy6_10.rename(columns={xy6_10.columns[-1]:'label'})\n",
    "print(xy6_10)\n",
    "\n",
    "xy7_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[7]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy7_10 = pd.concat([xy7_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy7_10 = pd.concat([xy7_10,ytrain7],axis=1)\n",
    "xy7_10 = xy7_10.rename(columns={xy7_10.columns[-1]:'label'})\n",
    "print(xy7_10)\n",
    "\n",
    "xy8_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[8]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy8_10 = pd.concat([xy8_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy8_10 = pd.concat([xy8_10,ytrain8],axis=1)\n",
    "xy8_10 = xy8_10.rename(columns={xy8_10.columns[-1]:'label'})\n",
    "print(xy8_10)\n",
    "\n",
    "xy9_10 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[9]:\n",
    "    if y >= 10:\n",
    "        break\n",
    "    xy9_10 = pd.concat([xy9_10,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy9_10 = pd.concat([xy9_10,ytrain9],axis=1)\n",
    "xy9_10 = xy9_10.rename(columns={xy9_10.columns[-1]:'label'})\n",
    "print(xy9_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1599  76  595  908  916  label\n",
      "0       71  -8  -76  114   80      0\n",
      "1      106 -91  -51  124  108      0\n",
      "2       78 -57  114  126   89      0\n",
      "3       92 -37   56 -125  121      0\n",
      "4       78 -53  -88 -111  -23      0\n",
      "...    ...  ..  ...  ...  ...    ...\n",
      "9685    85  74 -125 -104  -24      1\n",
      "9686    85  -1   90  -99   -1      1\n",
      "9687   120  -1   84  -94  -20      1\n",
      "9688    92 -17   77  101   -1      1\n",
      "9689    78  84   70   52  -99      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "      1468  484  562  743  750  label\n",
      "0     -109  -78  123  115   71      1\n",
      "1     -112  -91 -110  -79   82      1\n",
      "2      -98  -79 -128  -44  117      1\n",
      "3      -13  -64  120  -15  -90      1\n",
      "4       35   87  -91   90   57      1\n",
      "...    ...  ...  ...  ...  ...    ...\n",
      "9685    39   -1  -86  -41  114      1\n",
      "9686    28   -1   -1  -51 -108      1\n",
      "9687    46   -1 -122  -46  -15      1\n",
      "9688    46   -1   53  -46  -40      1\n",
      "9689    37  -80   67  -44 -128      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "      619  541  1601  495  1760  label\n",
      "0      80 -116  -117   48  -122      1\n",
      "1      91  -69    87 -109   -92      1\n",
      "2     103  -69   123  -89   -84      1\n",
      "3     109  -52    57  -15   -73      1\n",
      "4      85   83   -84   46  -120      1\n",
      "...   ...  ...   ...  ...   ...    ...\n",
      "9685  118   -1   -17   -1   -46      1\n",
      "9686  105   -1   -20   -1   -87      1\n",
      "9687   32   -1   -41   -1   -49      1\n",
      "9688  111  -33   -31   -1   -62      1\n",
      "9689  -41  -30   -41   -1   -58      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "      1746  1214  2169  548  238  label\n",
      "0       76   -76    85  -95  121      1\n",
      "1      104    85   113  -63   86      1\n",
      "2       73   -96   120 -114   85      1\n",
      "3      104   -71  -121   77  107      1\n",
      "4       52   -70    99 -101 -106      1\n",
      "...    ...   ...   ...  ...  ...    ...\n",
      "9685   -62    52    78   91  -88      1\n",
      "9686   -34    39    92   55   -1      1\n",
      "9687   -82    35    92   47  127      1\n",
      "9688  -102    43  -114   58   46      1\n",
      "9689   -93    36    78   46  -63      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "      391  1677  1922  1820  129  label\n",
      "0      63   112   -92  -116 -121      1\n",
      "1      79   -78  -108  -116  -58      1\n",
      "2      41   -72   -39  -101  -36      1\n",
      "3      45   -77    79   -95  -51      1\n",
      "4     125  -102  -126   122  -44      1\n",
      "...   ...   ...   ...   ...  ...    ...\n",
      "9685   -1  -119   107  -108   92      1\n",
      "9686   -1    83   120   104   99      1\n",
      "9687   71    98   113   102   -1      1\n",
      "9688   -1   124   -99   125   -1      1\n",
      "9689   -1   -65    77  -109  -72      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "      1652  773  1815  182  225  label\n",
      "0      -53  -51  -107  -74  -60      1\n",
      "1       92  -44    71 -111  -66      1\n",
      "2     -115  -55    64  124 -122      1\n",
      "3       88  -59    71   87  102      1\n",
      "4      -27  -48    94 -121  -18      1\n",
      "...    ...  ...   ...  ...  ...    ...\n",
      "9685   -17   -1    52 -106   -1      1\n",
      "9686   -37   -1    50  -99   57      1\n",
      "9687   -41   -1    50   -1  -44      1\n",
      "9688   -32   -1    45  119   -1      1\n",
      "9689   -48  -81    54  -88   -1      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "      607  1650  1643  598  1188  label\n",
      "0     -87   115    91 -107    76      1\n",
      "1     -71    40  -125 -124   113      1\n",
      "2    -101    77  -126   66    80      1\n",
      "3     -92    75  -107   65    42      1\n",
      "4     -59   -84   -71  -62  -106      1\n",
      "...   ...   ...   ...  ...   ...    ...\n",
      "9685  112   -91    36   34   -53      1\n",
      "9686  -21  -115    28  100   115      1\n",
      "9687  -36   -43    33  104   -95      1\n",
      "9688  -81   -52    40   96  -120      1\n",
      "9689 -127   -53    43   66   -56      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "      2255  1770  1594  1323  719  label\n",
      "0      -93   124   100   -93 -118      1\n",
      "1      -44   -97   -92    64 -121      1\n",
      "2      -58  -128  -107   106  127      1\n",
      "3      -65   108   -85    64  114      1\n",
      "4      120    80   -77    50   98      1\n",
      "...    ...   ...   ...   ...  ...    ...\n",
      "9685   106    74    62   113   51      1\n",
      "9686    64  -109    40   113 -121      1\n",
      "9687   -79   -96    35   120   98      1\n",
      "9688    92   126    36   113   45      1\n",
      "9689    42   -96    53   120  -64      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "      1318  2157  240  1764  765  label\n",
      "0      -93   -65   64    85  120      1\n",
      "1     -120  -114   68   112 -128      1\n",
      "2      -80   119   57   120 -128      1\n",
      "3      -36   118   57   -95 -114      1\n",
      "4       97    88   52  -111  106      1\n",
      "...    ...   ...  ...   ...  ...    ...\n",
      "9685   -91    91   -1  -111 -128      1\n",
      "9686   105    78   -1   124  -86      1\n",
      "9687    68    70   -1   -79  113      1\n",
      "9688    50    77   -1   -77   35      1\n",
      "9689    87   110   -1   -66 -107      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "      482  588  655  227  1141  label\n",
      "0    -108  -90 -101 -107  -128      1\n",
      "1    -105  -70  124  -79    56      1\n",
      "2     -62  -82   90 -105    50      1\n",
      "3     -76  -83   83  111    81      1\n",
      "4     -35 -116  -73  -52    47      1\n",
      "...   ...  ...  ...  ...   ...    ...\n",
      "9685   -1   -1   94   -1   -74      0\n",
      "9686   -1   -1  -48  112  -108      0\n",
      "9687   -1   -1  -95 -103    96      0\n",
      "9688   -1 -100  113   -1    91      0\n",
      "9689  -47   -1   72   -1  -113      0\n",
      "\n",
      "[9690 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "xy0_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[0]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy0_5 = pd.concat([xy0_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy0_5 = pd.concat([xy0_5,ytrain0],axis=1)\n",
    "xy0_5 = xy0_5.rename(columns={xy0_5.columns[-1]:'label'})\n",
    "print(xy0_5)\n",
    "    \n",
    "xy1_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[1]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy1_5 = pd.concat([xy1_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy1_5 = pd.concat([xy1_5,ytrain1],axis=1)\n",
    "xy1_5 = xy1_5.rename(columns={xy1_5.columns[-1]:'label'})\n",
    "print(xy1_5)\n",
    "\n",
    "xy2_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[2]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy2_5 = pd.concat([xy2_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy2_5 = pd.concat([xy2_5,ytrain2],axis=1)\n",
    "xy2_5 = xy2_5.rename(columns={xy2_5.columns[-1]:'label'})\n",
    "print(xy2_5)\n",
    "\n",
    "xy3_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[3]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy3_5 = pd.concat([xy3_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy3_5 = pd.concat([xy3_5,ytrain3],axis=1)\n",
    "xy3_5 = xy3_5.rename(columns={xy3_5.columns[-1]:'label'})\n",
    "print(xy3_5)\n",
    "\n",
    "xy4_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[4]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy4_5 = pd.concat([xy4_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy4_5 = pd.concat([xy4_5,ytrain4],axis=1)\n",
    "xy4_5 = xy4_5.rename(columns={xy4_5.columns[-1]:'label'})\n",
    "print(xy4_5)\n",
    "\n",
    "xy5_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[5]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy5_5 = pd.concat([xy5_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy5_5 = pd.concat([xy5_5,ytrain5],axis=1)\n",
    "xy5_5 = xy5_5.rename(columns={xy5_5.columns[-1]:'label'})\n",
    "print(xy5_5)\n",
    "\n",
    "xy6_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[6]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy6_5 = pd.concat([xy6_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy6_5 = pd.concat([xy6_5,ytrain6],axis=1)\n",
    "xy6_5 = xy6_5.rename(columns={xy6_5.columns[-1]:'label'})\n",
    "print(xy6_5)\n",
    "\n",
    "xy7_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[7]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy7_5 = pd.concat([xy7_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy7_5 = pd.concat([xy7_5,ytrain7],axis=1)\n",
    "xy7_5 = xy7_5.rename(columns={xy7_5.columns[-1]:'label'})\n",
    "print(xy7_5)\n",
    "\n",
    "xy8_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[8]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy8_5 = pd.concat([xy8_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy8_5 = pd.concat([xy8_5,ytrain8],axis=1)\n",
    "xy8_5 = xy8_5.rename(columns={xy8_5.columns[-1]:'label'})\n",
    "print(xy8_5)\n",
    "\n",
    "xy9_5 = None\n",
    "y=0\n",
    "for i in selected_features_per_class[9]:\n",
    "    if y >= 5:\n",
    "        break\n",
    "    xy9_5 = pd.concat([xy9_5,xtrain.iloc[:,int(i)]],axis=1)\n",
    "    y+=1\n",
    "xy9_5 = pd.concat([xy9_5,ytrain9],axis=1)\n",
    "xy9_5 = xy9_5.rename(columns={xy9_5.columns[-1]:'label'})\n",
    "print(xy9_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9685    1\n",
       "9686    1\n",
       "9687    1\n",
       "9688    1\n",
       "9689    1\n",
       "Name: label, Length: 9690, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=xy0_5['label']\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1599</th>\n",
       "      <th>76</th>\n",
       "      <th>595</th>\n",
       "      <th>908</th>\n",
       "      <th>916</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>-8</td>\n",
       "      <td>-76</td>\n",
       "      <td>114</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>-91</td>\n",
       "      <td>-51</td>\n",
       "      <td>124</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>-57</td>\n",
       "      <td>114</td>\n",
       "      <td>126</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92</td>\n",
       "      <td>-37</td>\n",
       "      <td>56</td>\n",
       "      <td>-125</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>-53</td>\n",
       "      <td>-88</td>\n",
       "      <td>-111</td>\n",
       "      <td>-23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9685</th>\n",
       "      <td>85</td>\n",
       "      <td>74</td>\n",
       "      <td>-125</td>\n",
       "      <td>-104</td>\n",
       "      <td>-24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9686</th>\n",
       "      <td>85</td>\n",
       "      <td>-1</td>\n",
       "      <td>90</td>\n",
       "      <td>-99</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9687</th>\n",
       "      <td>120</td>\n",
       "      <td>-1</td>\n",
       "      <td>84</td>\n",
       "      <td>-94</td>\n",
       "      <td>-20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9688</th>\n",
       "      <td>92</td>\n",
       "      <td>-17</td>\n",
       "      <td>77</td>\n",
       "      <td>101</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9689</th>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>70</td>\n",
       "      <td>52</td>\n",
       "      <td>-99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9690 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1599  76  595  908  916  label\n",
       "0       71  -8  -76  114   80      0\n",
       "1      106 -91  -51  124  108      0\n",
       "2       78 -57  114  126   89      0\n",
       "3       92 -37   56 -125  121      0\n",
       "4       78 -53  -88 -111  -23      0\n",
       "...    ...  ..  ...  ...  ...    ...\n",
       "9685    85  74 -125 -104  -24      1\n",
       "9686    85  -1   90  -99   -1      1\n",
       "9687   120  -1   84  -94  -20      1\n",
       "9688    92 -17   77  101   -1      1\n",
       "9689    78  84   70   52  -99      1\n",
       "\n",
       "[9690 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy0_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "seed_value = 22\n",
    "processed_df = xy9_20.drop(columns=['label'])\n",
    "y_train = xy9_20['label']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(processed_df, y_train, test_size=0.3, random_state=seed_value)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train, Y_train)\n",
    "\n",
    "predicted = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95734434124527\n",
      "F1 Score: 0.9581863979121424\n",
      "Confusion Matrix:\n",
      " [[  12   59]\n",
      " [  65 2771]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(predicted, Y_test)\n",
    "f1 = f1_score(predicted, Y_test, average=\"weighted\")\n",
    "conf_matrix = confusion_matrix(predicted, Y_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=xy0_5['label']\n",
    "processed_df=xy0_5.drop(columns=['label'])\n",
    "naive_bayes_search(processed_df,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current Data frame is:  0\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "The current Data frame is:  1\n",
      "Accuracy: 0.7640178878568972\n",
      "F1 Score: 0.8662246489859594\n",
      "Precision: 0.8197054451084171\n",
      "Recall/Sensitivity/True Positive Rate: 0.7640178878568972\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [ 686 2221]]\n",
      "\n",
      "\n",
      "The current Data frame is:  2\n",
      "Accuracy: 0.7715858273133815\n",
      "F1 Score: 0.8710679611650485\n",
      "Precision: 0.8237588615974939\n",
      "Recall/Sensitivity/True Positive Rate: 0.7715858273133815\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [ 664 2243]]\n",
      "\n",
      "\n",
      "The current Data frame is:  3\n",
      "Accuracy: 0.8555211558307534\n",
      "F1 Score: 0.9221357063403782\n",
      "Precision: 0.8763952922432349\n",
      "Recall/Sensitivity/True Positive Rate: 0.8555211558307534\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [ 420 2487]]\n",
      "\n",
      "\n",
      "The current Data frame is:  4\n",
      "Accuracy: 0.7994496044031648\n",
      "F1 Score: 0.8885490346014147\n",
      "Precision: 0.839670065577212\n",
      "Recall/Sensitivity/True Positive Rate: 0.7994496044031648\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [ 583 2324]]\n",
      "\n",
      "\n",
      "The current Data frame is:  5\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "The current Data frame is:  6\n",
      "Accuracy: 0.9642242862057103\n",
      "F1 Score: 0.9817863397548159\n",
      "Precision: 0.9655041879032012\n",
      "Recall/Sensitivity/True Positive Rate: 0.9642242862057103\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [ 104 2803]]\n",
      "\n",
      "\n",
      "The current Data frame is:  7\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "The current Data frame is:  8\n",
      "Accuracy: 0.9387684898520812\n",
      "F1 Score: 0.9684173172462739\n",
      "Precision: 0.942517787687076\n",
      "Recall/Sensitivity/True Positive Rate: 0.9387684898520812\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [ 178 2729]]\n",
      "\n",
      "\n",
      "The current Data frame is:  9\n",
      "Accuracy: 0.9735122119023047\n",
      "F1 Score: 0.9865783510545582\n",
      "Precision: 0.9742138148206131\n",
      "Recall/Sensitivity/True Positive Rate: 0.9735122119023047\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  77 2830]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    strings=globals()[\"xy{}_5\".format(i)]\n",
    "    print(\"The current Data frame is: \",i)\n",
    "    y_train=strings['label']\n",
    "    processed_df=strings.drop(columns=['label'])\n",
    "    naive_bayes_search(processed_df,y_train)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current Data frame is:  0\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "The current Data frame is:  1\n",
      "Accuracy: 0.7619539043687651\n",
      "F1 Score: 0.8599517440367839\n",
      "Precision: 0.6577912907654885\n",
      "Recall/Sensitivity/True Positive Rate: 0.7619539043687651\n",
      "Confusion Matrix:\n",
      " [[   5   11]\n",
      " [ 681 2210]]\n",
      "\n",
      "\n",
      "The current Data frame is:  2\n",
      "Accuracy: 0.7715858273133815\n",
      "F1 Score: 0.8710679611650485\n",
      "Precision: 0.8237588615974939\n",
      "Recall/Sensitivity/True Positive Rate: 0.7715858273133815\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [ 664 2243]]\n",
      "\n",
      "\n",
      "The current Data frame is:  3\n",
      "Accuracy: 0.8555211558307534\n",
      "F1 Score: 0.9221357063403782\n",
      "Precision: 0.8763952922432349\n",
      "Recall/Sensitivity/True Positive Rate: 0.8555211558307534\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [ 420 2487]]\n",
      "\n",
      "\n",
      "The current Data frame is:  4\n",
      "Accuracy: 0.7997936016511867\n",
      "F1 Score: 0.8871228673554946\n",
      "Precision: 0.7600001137964707\n",
      "Recall/Sensitivity/True Positive Rate: 0.7997936016511867\n",
      "Confusion Matrix:\n",
      " [[   3    2]\n",
      " [ 580 2322]]\n",
      "\n",
      "\n",
      "The current Data frame is:  5\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "The current Data frame is:  6\n",
      "Accuracy: 0.9642242862057103\n",
      "F1 Score: 0.9817863397548159\n",
      "Precision: 0.9655041879032012\n",
      "Recall/Sensitivity/True Positive Rate: 0.9642242862057103\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [ 104 2803]]\n",
      "\n",
      "\n",
      "The current Data frame is:  7\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "The current Data frame is:  8\n",
      "Accuracy: 0.9387684898520812\n",
      "F1 Score: 0.9684173172462739\n",
      "Precision: 0.942517787687076\n",
      "Recall/Sensitivity/True Positive Rate: 0.9387684898520812\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [ 178 2729]]\n",
      "\n",
      "\n",
      "The current Data frame is:  9\n",
      "Accuracy: 0.95734434124527\n",
      "F1 Score: 0.9584828866365734\n",
      "Precision: 0.9550950838770101\n",
      "Recall/Sensitivity/True Positive Rate: 0.95734434124527\n",
      "Confusion Matrix:\n",
      " [[  11   58]\n",
      " [  66 2772]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    strings=globals()[\"xy{}_10\".format(i)]\n",
    "    print(\"The current Data frame is: \",i)\n",
    "    y_train=strings['label']\n",
    "    processed_df=strings.drop(columns=['label'])\n",
    "    naive_bayes_search(processed_df,y_train)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current Data frame is:  0\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "The current Data frame is:  1\n",
      "Accuracy: 0.7389060887512899\n",
      "F1 Score: 0.7640212232922994\n",
      "Precision: 0.7027997924669046\n",
      "Recall/Sensitivity/True Positive Rate: 0.7389060887512899\n",
      "Confusion Matrix:\n",
      " [[ 169  242]\n",
      " [ 517 1979]]\n",
      "\n",
      "\n",
      "The current Data frame is:  2\n",
      "Accuracy: 0.7715858273133815\n",
      "F1 Score: 0.8710679611650485\n",
      "Precision: 0.8237588615974939\n",
      "Recall/Sensitivity/True Positive Rate: 0.7715858273133815\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [ 664 2243]]\n",
      "\n",
      "\n",
      "The current Data frame is:  3\n",
      "Accuracy: 0.8531131750945993\n",
      "F1 Score: 0.893655098457527\n",
      "Precision: 0.8090299397771646\n",
      "Recall/Sensitivity/True Positive Rate: 0.8531131750945993\n",
      "Confusion Matrix:\n",
      " [[  47   54]\n",
      " [ 373 2433]]\n",
      "\n",
      "\n",
      "The current Data frame is:  4\n",
      "Accuracy: 0.8211214310285517\n",
      "F1 Score: 0.8481711220118504\n",
      "Precision: 0.7968709743426332\n",
      "Recall/Sensitivity/True Positive Rate: 0.8211214310285517\n",
      "Confusion Matrix:\n",
      " [[ 167  104]\n",
      " [ 416 2220]]\n",
      "\n",
      "\n",
      "The current Data frame is:  5\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "The current Data frame is:  6\n",
      "Accuracy: 0.9628482972136223\n",
      "F1 Score: 0.9790785417692177\n",
      "Precision: 0.9359521235515743\n",
      "Recall/Sensitivity/True Positive Rate: 0.9628482972136223\n",
      "Confusion Matrix:\n",
      " [[   1    5]\n",
      " [ 103 2798]]\n",
      "\n",
      "\n",
      "The current Data frame is:  7\n",
      "Accuracy: 0.9762641898864809\n",
      "F1 Score: 0.9866300933822293\n",
      "Precision: 0.9557501989863515\n",
      "Recall/Sensitivity/True Positive Rate: 0.9762641898864809\n",
      "Confusion Matrix:\n",
      " [[   0    4]\n",
      " [  65 2838]]\n",
      "\n",
      "\n",
      "The current Data frame is:  8\n",
      "Accuracy: 0.9387684898520812\n",
      "F1 Score: 0.9684173172462739\n",
      "Precision: 0.942517787687076\n",
      "Recall/Sensitivity/True Positive Rate: 0.9387684898520812\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [ 178 2729]]\n",
      "\n",
      "\n",
      "The current Data frame is:  9\n",
      "Accuracy: 0.95734434124527\n",
      "F1 Score: 0.9581863979121424\n",
      "Precision: 0.9556765057232569\n",
      "Recall/Sensitivity/True Positive Rate: 0.95734434124527\n",
      "Confusion Matrix:\n",
      " [[  12   59]\n",
      " [  65 2771]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    strings=globals()[\"xy{}_20\".format(i)]\n",
    "    print(\"The current Data frame is: \",i)\n",
    "    y_train=strings['label']\n",
    "    processed_df=strings.drop(columns=['label'])\n",
    "    naive_bayes_search(processed_df,y_train)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Victor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['52',\n",
       " '55',\n",
       " '62',\n",
       " '66',\n",
       " '76',\n",
       " '85',\n",
       " '87',\n",
       " '109',\n",
       " '117',\n",
       " '129',\n",
       " '134',\n",
       " '163',\n",
       " '179',\n",
       " '180',\n",
       " '181',\n",
       " '182',\n",
       " '190',\n",
       " '193',\n",
       " '204',\n",
       " '211',\n",
       " '225',\n",
       " '227',\n",
       " '238',\n",
       " '240',\n",
       " '252',\n",
       " '271',\n",
       " '277',\n",
       " '285',\n",
       " '290',\n",
       " '310',\n",
       " '342',\n",
       " '351',\n",
       " '356',\n",
       " '357',\n",
       " '375',\n",
       " '379',\n",
       " '391',\n",
       " '443',\n",
       " '482',\n",
       " '484',\n",
       " '485',\n",
       " '489',\n",
       " '495',\n",
       " '505',\n",
       " '538',\n",
       " '541',\n",
       " '548',\n",
       " '551',\n",
       " '562',\n",
       " '588',\n",
       " '589',\n",
       " '595',\n",
       " '598',\n",
       " '607',\n",
       " '615',\n",
       " '619',\n",
       " '647',\n",
       " '655',\n",
       " '656',\n",
       " '674',\n",
       " '676',\n",
       " '683',\n",
       " '690',\n",
       " '699',\n",
       " '719',\n",
       " '721',\n",
       " '739',\n",
       " '743',\n",
       " '746',\n",
       " '750',\n",
       " '755',\n",
       " '765',\n",
       " '773',\n",
       " '778',\n",
       " '814',\n",
       " '839',\n",
       " '860',\n",
       " '869',\n",
       " '875',\n",
       " '897',\n",
       " '908',\n",
       " '916',\n",
       " '931',\n",
       " '954',\n",
       " '955',\n",
       " '962',\n",
       " '989',\n",
       " '992',\n",
       " '994',\n",
       " '1006',\n",
       " '1016',\n",
       " '1017',\n",
       " '1024',\n",
       " '1028',\n",
       " '1046',\n",
       " '1086',\n",
       " '1091',\n",
       " '1116',\n",
       " '1119',\n",
       " '1136',\n",
       " '1141',\n",
       " '1158',\n",
       " '1160',\n",
       " '1170',\n",
       " '1188',\n",
       " '1190',\n",
       " '1213',\n",
       " '1214',\n",
       " '1228',\n",
       " '1233',\n",
       " '1244',\n",
       " '1250',\n",
       " '1258',\n",
       " '1265',\n",
       " '1282',\n",
       " '1298',\n",
       " '1301',\n",
       " '1309',\n",
       " '1312',\n",
       " '1318',\n",
       " '1323',\n",
       " '1327',\n",
       " '1332',\n",
       " '1333',\n",
       " '1339',\n",
       " '1367',\n",
       " '1369',\n",
       " '1421',\n",
       " '1434',\n",
       " '1444',\n",
       " '1456',\n",
       " '1467',\n",
       " '1468',\n",
       " '1548',\n",
       " '1560',\n",
       " '1594',\n",
       " '1596',\n",
       " '1599',\n",
       " '1601',\n",
       " '1610',\n",
       " '1632',\n",
       " '1643',\n",
       " '1650',\n",
       " '1652',\n",
       " '1664',\n",
       " '1677',\n",
       " '1683',\n",
       " '1688',\n",
       " '1689',\n",
       " '1691',\n",
       " '1695',\n",
       " '1711',\n",
       " '1737',\n",
       " '1746',\n",
       " '1751',\n",
       " '1760',\n",
       " '1764',\n",
       " '1770',\n",
       " '1783',\n",
       " '1799',\n",
       " '1815',\n",
       " '1820',\n",
       " '1821',\n",
       " '1822',\n",
       " '1831',\n",
       " '1841',\n",
       " '1844',\n",
       " '1857',\n",
       " '1859',\n",
       " '1866',\n",
       " '1885',\n",
       " '1912',\n",
       " '1922',\n",
       " '1976',\n",
       " '1984',\n",
       " '1988',\n",
       " '2039',\n",
       " '2043',\n",
       " '2047',\n",
       " '2057',\n",
       " '2082',\n",
       " '2083',\n",
       " '2091',\n",
       " '2112',\n",
       " '2116',\n",
       " '2131',\n",
       " '2157',\n",
       " '2169',\n",
       " '2194',\n",
       " '2201',\n",
       " '2216',\n",
       " '2249',\n",
       " '2254',\n",
       " '2255',\n",
       " '2270',\n",
       " '2301']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = []\n",
    "for i in range(len(selected_features_per_class)):\n",
    "    features.append(selected_features_per_class[i][0:20])\n",
    "features = np.concatenate(features)\n",
    "features = np.unique(features)\n",
    "features = features.tolist()\n",
    "for i in range(len(features)):\n",
    "    features[i] = str(features[i])\n",
    "features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2294</th>\n",
       "      <th>2295</th>\n",
       "      <th>2296</th>\n",
       "      <th>2297</th>\n",
       "      <th>2298</th>\n",
       "      <th>2299</th>\n",
       "      <th>2300</th>\n",
       "      <th>2301</th>\n",
       "      <th>2302</th>\n",
       "      <th>2303</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>112.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9685</th>\n",
       "      <td>247.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9686</th>\n",
       "      <td>151.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9687</th>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9688</th>\n",
       "      <td>255.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9689</th>\n",
       "      <td>252.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9690 rows × 2304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2      3      4      5      6      7      8      9  \\\n",
       "0      78.0   77.0   76.0   82.0   87.0   92.0  104.0  119.0  117.0  120.0   \n",
       "1      73.0   75.0   79.0   78.0   76.0   75.0   89.0  107.0  133.0  125.0   \n",
       "2      72.0   75.0   79.0   77.0   81.0   89.0  105.0  109.0   86.0   90.0   \n",
       "3      67.0   70.0   74.0   80.0   93.0  107.0  110.0   96.0   69.0  100.0   \n",
       "4      74.0   74.0   73.0   72.0   77.0   87.0  104.0  109.0   84.0   83.0   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "9685  247.0  220.0  254.0  213.0  129.0  208.0  254.0  255.0  255.0  255.0   \n",
       "9686  151.0  118.0  254.0  255.0  255.0  255.0  254.0  254.0  254.0  252.0   \n",
       "9687  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "9688  255.0  253.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0  255.0   \n",
       "9689  252.0  189.0  238.0  255.0  255.0  245.0  219.0  212.0  140.0   40.0   \n",
       "\n",
       "      ...   2294  2295  2296   2297  2298  2299  2300   2301   2302   2303  \n",
       "0     ...   87.0  79.0  72.0   76.0  83.0  95.0  99.0   98.0   95.0   94.0  \n",
       "1     ...   96.0  93.0  85.0   77.0  69.0  73.0  83.0  100.0  101.0  101.0  \n",
       "2     ...   98.0  95.0  88.0   80.0  73.0  71.0  74.0   80.0   89.0   95.0  \n",
       "3     ...  112.0  92.0  87.0   82.0  77.0  72.0  70.0   72.0   81.0   88.0  \n",
       "4     ...  100.0  98.0  99.0  100.0  99.0  89.0  78.0   66.0   68.0   72.0  \n",
       "...   ...    ...   ...   ...    ...   ...   ...   ...    ...    ...    ...  \n",
       "9685  ...   35.0  29.0  27.0   26.0  25.0  23.0  22.0   26.0   26.0   27.0  \n",
       "9686  ...   37.0  31.0  30.0   30.0  30.0  30.0  29.0   26.0   28.0   27.0  \n",
       "9687  ...   41.0  49.0  42.0   36.0  33.0  36.0  39.0   31.0   39.0   43.0  \n",
       "9688  ...   38.0  27.0  26.0   27.0  35.0  28.0  27.0   26.0   26.0   24.0  \n",
       "9689  ...   34.0  23.0  23.0   30.0  32.0  23.0  23.0   26.0   20.0   17.0  \n",
       "\n",
       "[9690 rows x 2304 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pd.read_csv('Dataset/x_train_all.csv')\n",
    "y_train = pd.read_csv('Dataset/y_train_all.csv')\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>52</th>\n",
       "      <th>55</th>\n",
       "      <th>62</th>\n",
       "      <th>66</th>\n",
       "      <th>76</th>\n",
       "      <th>85</th>\n",
       "      <th>87</th>\n",
       "      <th>109</th>\n",
       "      <th>117</th>\n",
       "      <th>129</th>\n",
       "      <th>...</th>\n",
       "      <th>2157</th>\n",
       "      <th>2169</th>\n",
       "      <th>2194</th>\n",
       "      <th>2201</th>\n",
       "      <th>2216</th>\n",
       "      <th>2249</th>\n",
       "      <th>2254</th>\n",
       "      <th>2255</th>\n",
       "      <th>2270</th>\n",
       "      <th>2301</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-125</td>\n",
       "      <td>-67</td>\n",
       "      <td>-24</td>\n",
       "      <td>-40</td>\n",
       "      <td>-8</td>\n",
       "      <td>104</td>\n",
       "      <td>-72</td>\n",
       "      <td>-39</td>\n",
       "      <td>64</td>\n",
       "      <td>-121</td>\n",
       "      <td>...</td>\n",
       "      <td>-65</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>-128</td>\n",
       "      <td>62</td>\n",
       "      <td>116</td>\n",
       "      <td>-65</td>\n",
       "      <td>-93</td>\n",
       "      <td>65</td>\n",
       "      <td>-86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-111</td>\n",
       "      <td>-81</td>\n",
       "      <td>-37</td>\n",
       "      <td>-1</td>\n",
       "      <td>-91</td>\n",
       "      <td>64</td>\n",
       "      <td>92</td>\n",
       "      <td>-34</td>\n",
       "      <td>50</td>\n",
       "      <td>-58</td>\n",
       "      <td>...</td>\n",
       "      <td>-114</td>\n",
       "      <td>113</td>\n",
       "      <td>-15</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "      <td>83</td>\n",
       "      <td>-51</td>\n",
       "      <td>-44</td>\n",
       "      <td>86</td>\n",
       "      <td>-58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-120</td>\n",
       "      <td>-112</td>\n",
       "      <td>-1</td>\n",
       "      <td>-54</td>\n",
       "      <td>-57</td>\n",
       "      <td>66</td>\n",
       "      <td>-107</td>\n",
       "      <td>-1</td>\n",
       "      <td>-93</td>\n",
       "      <td>-36</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>-46</td>\n",
       "      <td>85</td>\n",
       "      <td>87</td>\n",
       "      <td>95</td>\n",
       "      <td>-79</td>\n",
       "      <td>-58</td>\n",
       "      <td>68</td>\n",
       "      <td>-107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-102</td>\n",
       "      <td>104</td>\n",
       "      <td>-1</td>\n",
       "      <td>-100</td>\n",
       "      <td>-37</td>\n",
       "      <td>-103</td>\n",
       "      <td>-128</td>\n",
       "      <td>-1</td>\n",
       "      <td>-58</td>\n",
       "      <td>-51</td>\n",
       "      <td>...</td>\n",
       "      <td>118</td>\n",
       "      <td>-121</td>\n",
       "      <td>124</td>\n",
       "      <td>109</td>\n",
       "      <td>73</td>\n",
       "      <td>104</td>\n",
       "      <td>-93</td>\n",
       "      <td>-65</td>\n",
       "      <td>51</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-127</td>\n",
       "      <td>-105</td>\n",
       "      <td>-19</td>\n",
       "      <td>-44</td>\n",
       "      <td>-53</td>\n",
       "      <td>57</td>\n",
       "      <td>113</td>\n",
       "      <td>-10</td>\n",
       "      <td>78</td>\n",
       "      <td>-44</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>99</td>\n",
       "      <td>-96</td>\n",
       "      <td>127</td>\n",
       "      <td>110</td>\n",
       "      <td>-117</td>\n",
       "      <td>85</td>\n",
       "      <td>120</td>\n",
       "      <td>-77</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9685</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>106</td>\n",
       "      <td>74</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>-1</td>\n",
       "      <td>-8</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>78</td>\n",
       "      <td>-40</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>63</td>\n",
       "      <td>99</td>\n",
       "      <td>106</td>\n",
       "      <td>-17</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9686</th>\n",
       "      <td>-1</td>\n",
       "      <td>-65</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-79</td>\n",
       "      <td>-58</td>\n",
       "      <td>-36</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>92</td>\n",
       "      <td>-94</td>\n",
       "      <td>97</td>\n",
       "      <td>62</td>\n",
       "      <td>97</td>\n",
       "      <td>92</td>\n",
       "      <td>64</td>\n",
       "      <td>-36</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9687</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-126</td>\n",
       "      <td>-79</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>92</td>\n",
       "      <td>-42</td>\n",
       "      <td>69</td>\n",
       "      <td>76</td>\n",
       "      <td>83</td>\n",
       "      <td>-121</td>\n",
       "      <td>-79</td>\n",
       "      <td>-27</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9688</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-17</td>\n",
       "      <td>-1</td>\n",
       "      <td>-29</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>-114</td>\n",
       "      <td>-35</td>\n",
       "      <td>73</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>85</td>\n",
       "      <td>92</td>\n",
       "      <td>-34</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9689</th>\n",
       "      <td>-1</td>\n",
       "      <td>104</td>\n",
       "      <td>-24</td>\n",
       "      <td>-1</td>\n",
       "      <td>84</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>-98</td>\n",
       "      <td>106</td>\n",
       "      <td>-72</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>78</td>\n",
       "      <td>-53</td>\n",
       "      <td>99</td>\n",
       "      <td>84</td>\n",
       "      <td>99</td>\n",
       "      <td>-93</td>\n",
       "      <td>42</td>\n",
       "      <td>-52</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9690 rows × 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       52   55  62   66  76   85   87  109  117  129  ...  2157  2169  2194  \\\n",
       "0    -125  -67 -24  -40  -8  104  -72  -39   64 -121  ...   -65    85   100   \n",
       "1    -111  -81 -37   -1 -91   64   92  -34   50  -58  ...  -114   113   -15   \n",
       "2    -120 -112  -1  -54 -57   66 -107   -1  -93  -36  ...   119   120   -46   \n",
       "3    -102  104  -1 -100 -37 -103 -128   -1  -58  -51  ...   118  -121   124   \n",
       "4    -127 -105 -19  -44 -53   57  113  -10   78  -44  ...    88    99   -96   \n",
       "...   ...  ...  ..  ...  ..  ...  ...  ...  ...  ...  ...   ...   ...   ...   \n",
       "9685   -1   -1  -1  106  74   30   28   -1   -8   92  ...    91    78   -40   \n",
       "9686   -1  -65  -1   -1  -1   -1  -79  -58  -36   99  ...    78    92   -94   \n",
       "9687   -1   -1  -1   -1  -1 -126  -79   -1   -1   -1  ...    70    92   -42   \n",
       "9688   -1   -1  -1   -1 -17   -1  -29   -1   -1   -1  ...    77  -114   -35   \n",
       "9689   -1  104 -24   -1  84   90  120  -98  106  -72  ...   110    78   -53   \n",
       "\n",
       "      2201  2216  2249  2254  2255  2270  2301  \n",
       "0     -128    62   116   -65   -93    65   -86  \n",
       "1       76    74    83   -51   -44    86   -58  \n",
       "2       85    87    95   -79   -58    68  -107  \n",
       "3      109    73   104   -93   -65    51   113  \n",
       "4      127   110  -117    85   120   -77    64  \n",
       "...    ...   ...   ...   ...   ...   ...   ...  \n",
       "9685    63    80    63    99   106   -17    99  \n",
       "9686    97    62    97    92    64   -36    71  \n",
       "9687    69    76    83  -121   -79   -27    92  \n",
       "9688    73    64    66    85    92   -34    92  \n",
       "9689    99    84    99   -93    42   -52    99  \n",
       "\n",
       "[9690 rows x 196 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_x_train = xtrain[features]\n",
    "reduced_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anshu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4757481940144479\n",
      "F1 Score: 0.46517680193532784\n",
      "Precision: 0.5257300207272383\n",
      "Recall/Sensitivity/True Positive Rate: 0.4757481940144479\n",
      "Specificity: (array([0.9018297 , 0.84466457, 0.92287115, 0.91877764, 0.89931153,\n",
      "       0.986981  , 0.9764538 , 0.99014778, 0.98754122, 0.95547703]), array([ 65, 686, 664, 420, 583,  65, 104,  65, 178,  77], dtype=int64))\n",
      "False Positive Rate: [0.         0.         0.         ... 0.90524787 0.90524787 1.        ]\n",
      "Area under ROC curve: 0.8252797345785611\n",
      "Confusion Matrix:\n",
      " [[ 47 102  63  47  52   6   5   1   1   2]\n",
      " [ 10 329 199  43  93   0   0   0   0   0]\n",
      " [  2  85 220  21  59   0   1   1   3   1]\n",
      " [  2  41  59 229  67   4   7   0  14   8]\n",
      " [  3  88  95  43 283   1   2   0   1   1]\n",
      " [  0   0   2   0   0  41   4   2  19  10]\n",
      " [  0   6   9  15  15   3  51   2  14   2]\n",
      " [  0   2   0   0   1   2   5  47  17   1]\n",
      " [  1   4   3   3   0   6   4   6  91   7]\n",
      " [  0  29  14  19  13   2  25   6  18  45]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 4, 4, ..., 9, 6, 1], dtype=int64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes_search_non_binary(reduced_x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(reduced_x_train), columns=reduced_x_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    " \n",
    "def naive_bayes_search(df1, df2,seed_value=22):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(df1, df2, test_size=0.3,random_state=seed_value)\n",
    "    \n",
    "    gnb = CategoricalNB()\n",
    "    gnb.fit(X_train, Y_train)\n",
    "    \n",
    "    predicted = gnb.predict(X_test)\n",
    "    predicted_probs = gnb.predict_proba(X_test)\n",
    "    \n",
    "    # cross_val_scores = cross_val_score(gnb, X_train, Y_train, cv=5)  \n",
    "    # print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "    # print(\"Mean CV Score:\", cross_val_scores.mean())\n",
    "\n",
    "\n",
    "    # train_sizes, train_scores, test_scores = learning_curve(gnb, X_train, Y_train, cv=5)\n",
    "    # train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    # test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.title(\"Learning Curves\")\n",
    "    # plt.xlabel(\"Training examples\")\n",
    "    # plt.ylabel(\"Score\")\n",
    "    # plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    # plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    # plt.legend(loc=\"best\")\n",
    "    # plt.show()\n",
    "\n",
    "    accuracy = accuracy_score(Y_test,predicted )\n",
    "    f1 = f1_score(predicted, Y_test, average=\"weighted\")\n",
    "    conf_matrix = confusion_matrix(predicted, Y_test)\n",
    "    precision = precision_score(Y_test, predicted, average=\"weighted\",zero_division=1)\n",
    "    recall = recall_score(Y_test, predicted, average=\"weighted\")\n",
    "    # roc = roc_auc_score(Y_test, predicted_probs, multi_class=\"ovr\", average=\"weighted\")\n",
    "    conf_matrices = multilabel_confusion_matrix(Y_test, predicted)\n",
    "    tp = conf_matrices[:,1,1]\n",
    "    fp = conf_matrices[:,0,1]\n",
    "    tn = conf_matrices[:,0,0]\n",
    "    fn = conf_matrices[:,1,0]\n",
    "    # fpr = _nanaverage(fp/(tn + fp), tp + fn)\n",
    "    # tnr = _nanaverage(tn/(tn + fp), tp + fn)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall/Sensitivity/True Positive Rate:\", recall)\n",
    "    # print(\"Specificity:\", tnr)\n",
    "    # print(\"False Positive Rate:\", fpr)\n",
    "    # print(\"Area under ROC curve:\", roc)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anshu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\anshu\\OneDrive\\Desktop\\Course\\F21DL\\DMML\\Coursework\\Part 1\\Feature_Selection_fixed.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m naive_bayes_search(df_normalized, y_train)\n",
      "\u001b[1;32mc:\\Users\\anshu\\OneDrive\\Desktop\\Course\\F21DL\\DMML\\Coursework\\Part 1\\Feature_Selection_fixed.ipynb Cell 28\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X53sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m fpr \u001b[39m=\u001b[39m (fp\u001b[39m/\u001b[39m(tn \u001b[39m+\u001b[39m fp), tp \u001b[39m+\u001b[39m fn)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X53sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m tnr \u001b[39m=\u001b[39m (tn\u001b[39m/\u001b[39m(tn \u001b[39m+\u001b[39m fp), tp \u001b[39m+\u001b[39m fn)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X53sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m fpr, tpr, _ \u001b[39m=\u001b[39m roc_curve(Y_test,  predicted_probs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X53sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m auc \u001b[39m=\u001b[39m roc_auc_score(Y_test, predicted_probs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X53sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(fpr,tpr,label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata 1, auc=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(auc))\n",
      "File \u001b[1;32mc:\\Users\\anshu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:992\u001b[0m, in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mroc_curve\u001b[39m(\n\u001b[0;32m    905\u001b[0m     y_true, y_score, \u001b[39m*\u001b[39m, pos_label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, drop_intermediate\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    906\u001b[0m ):\n\u001b[0;32m    907\u001b[0m     \u001b[39m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[0;32m    908\u001b[0m \n\u001b[0;32m    909\u001b[0m \u001b[39m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[39m    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[0;32m    991\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 992\u001b[0m     fps, tps, thresholds \u001b[39m=\u001b[39m _binary_clf_curve(\n\u001b[0;32m    993\u001b[0m         y_true, y_score, pos_label\u001b[39m=\u001b[39;49mpos_label, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[0;32m    994\u001b[0m     )\n\u001b[0;32m    996\u001b[0m     \u001b[39m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[0;32m    997\u001b[0m     \u001b[39m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[0;32m    998\u001b[0m     \u001b[39m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1003\u001b[0m     \u001b[39m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m     \u001b[39m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m     \u001b[39mif\u001b[39;00m drop_intermediate \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(fps) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\anshu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:749\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    747\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    748\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m pos_label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)):\n\u001b[1;32m--> 749\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[0;32m    751\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[0;32m    752\u001b[0m y_true \u001b[39m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "naive_bayes_search(df_normalized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_image = reduced_x_train.iloc[0].values.reshape(14, 14)\n",
    "# plt.imshow(original_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d080205970>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_image = xtrain.iloc[0].values.reshape(48, 48)\n",
    "plt.imshow(original_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d08143bc40>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new = xy0_20.drop(columns=[\"label\"])\n",
    "\n",
    "original_image = new.iloc[0].values.reshape(4, 5)\n",
    "plt.imshow(original_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23976608187134502\n",
      "F1 Score: 0.19900257318936587\n",
      "Precision: 0.4054842109770383\n",
      "Recall/Sensitivity/True Positive Rate: 0.23976608187134502\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "classifiers = [GaussianNB() for i in range(10)]\n",
    "ovr = OneVsRestClassifier(GaussianNB())\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(reduced_x_train, ytrainall, test_size=0.3,random_state=seed_value)\n",
    "\n",
    "ovr.fit(X_train, Y_train)\n",
    "predicted = ovr.predict(X_test)\n",
    "predicted_probs = ovr.predict_proba(X_test)\n",
    "\n",
    "# cross_val_scores = cross_val_score(gnb, X_train, Y_train, cv=5)  \n",
    "# print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "# print(\"Mean CV Score:\", cross_val_scores.mean())\n",
    "\n",
    "\n",
    "# train_sizes, train_scores, test_scores = learning_curve(gnb, X_train, Y_train, cv=5)\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Learning Curves\")\n",
    "# plt.xlabel(\"Training examples\")\n",
    "# plt.ylabel(\"Score\")\n",
    "# plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "# plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()\n",
    "\n",
    "accuracy = accuracy_score(Y_test,predicted )\n",
    "f1 = f1_score(predicted, Y_test, average=\"weighted\")\n",
    "conf_matrix = confusion_matrix(predicted, Y_test)\n",
    "precision = precision_score(Y_test, predicted, average=\"weighted\",zero_division=1)\n",
    "recall = recall_score(Y_test, predicted, average=\"weighted\")\n",
    "# roc = roc_auc_score(Y_test, predicted_probs, multi_class=\"ovr\", average=\"weighted\")\n",
    "# conf_matrices = multilabel_confusion_matrix(Y_test, predicted)\n",
    "# tp = conf_matrices[:,1,1]\n",
    "# fp = conf_matrices[:,0,1]\n",
    "# tn = conf_matrices[:,0,0]\n",
    "# fn = conf_matrices[:,1,0]\n",
    "# fpr = _nanaverage(fp/(tn + fp), tp + fn)\n",
    "# tnr = _nanaverage(tn/(tn + fp), tp + fn)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall/Sensitivity/True Positive Rate:\", recall)\n",
    "# print(\"Specificity:\", tnr)\n",
    "# print(\"False Positive Rate:\", fpr)\n",
    "# print(\"Area under ROC curve:\", roc)\n",
    "# print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anshu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23598211214310286\n",
      "F1 Score: 0.2134281917582327\n",
      "Precision: 0.4017743659066427\n",
      "Recall/Sensitivity/True Positive Rate: 0.23598211214310286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "classifiers = [GaussianNB() for i in range(5)]\n",
    "ovr = OneVsOneClassifier(GaussianNB(), n_jobs=45)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(reduced_x_train, ytrainall, test_size=0.3,random_state=seed_value)\n",
    "\n",
    "ovr.fit(X_train, Y_train)\n",
    "predicted = ovr.predict(X_test)\n",
    "# predicted_probs = ovr.predict_proba(X_test)\n",
    "\n",
    "# cross_val_scores = cross_val_score(gnb, X_train, Y_train, cv=5)  \n",
    "# print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "# print(\"Mean CV Score:\", cross_val_scores.mean())\n",
    "\n",
    "\n",
    "# train_sizes, train_scores, test_scores = learning_curve(gnb, X_train, Y_train, cv=5)\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Learning Curves\")\n",
    "# plt.xlabel(\"Training examples\")\n",
    "# plt.ylabel(\"Score\")\n",
    "# plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "# plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()\n",
    "\n",
    "accuracy = accuracy_score(Y_test,predicted )\n",
    "f1 = f1_score(predicted, Y_test, average=\"weighted\")\n",
    "conf_matrix = confusion_matrix(predicted, Y_test)\n",
    "precision = precision_score(Y_test, predicted, average=\"weighted\",zero_division=1)\n",
    "recall = recall_score(Y_test, predicted, average=\"weighted\")\n",
    "# roc = roc_auc_score(Y_test, predicted_probs, multi_class=\"ovr\", average=\"weighted\")\n",
    "# conf_matrices = multilabel_confusion_matrix(Y_test, predicted)\n",
    "# tp = conf_matrices[:,1,1]\n",
    "# fp = conf_matrices[:,0,1]\n",
    "# tn = conf_matrices[:,0,0]\n",
    "# fn = conf_matrices[:,1,0]\n",
    "# fpr = _nanaverage(fp/(tn + fp), tp + fn)\n",
    "# tnr = _nanaverage(tn/(tn + fp), tp + fn)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall/Sensitivity/True Positive Rate:\", recall)\n",
    "# print(\"Specificity:\", tnr)\n",
    "# print(\"False Positive Rate:\", fpr)\n",
    "# print(\"Area under ROC curve:\", roc)\n",
    "# print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1605    490   1536    927    742  label\n",
      "0     219.0   83.0  184.0  105.0  103.0      0\n",
      "1     185.0   97.0  187.0   80.0  123.0      0\n",
      "2     204.0  129.0  182.0  110.0  196.0      0\n",
      "3     185.0  148.0  184.0  135.0  235.0      0\n",
      "4     175.0   80.0  107.0   81.0   78.0      0\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685   54.0  255.0  222.0  161.0   96.0      1\n",
      "9686   55.0  255.0   92.0  104.0  104.0      1\n",
      "9687   53.0  254.0  109.0   75.0  101.0      1\n",
      "9688   53.0  255.0  113.0   86.0   94.0      1\n",
      "9689   41.0  248.0  255.0   70.0   91.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  0\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "       1432     52   1733    637   1262  label\n",
      "0      89.0   89.0   94.0  115.0  176.0      1\n",
      "1      91.0   79.0  111.0  110.0  100.0      1\n",
      "2      87.0   88.0  120.0  119.0  153.0      1\n",
      "3      82.0   98.0  105.0  129.0  142.0      1\n",
      "4     116.0   84.0  179.0  131.0  158.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685   42.0  199.0   43.0  255.0   20.0      1\n",
      "9686   52.0  205.0   47.0  206.0   19.0      1\n",
      "9687   37.0  255.0   38.0  255.0   17.0      1\n",
      "9688   38.0  255.0   55.0   76.0   16.0      1\n",
      "9689   25.0  255.0   82.0  254.0   15.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  1\n",
      "Accuracy: 0.7206742346061231\n",
      "F1 Score: 0.7282272614049545\n",
      "Precision: 0.7071068742350334\n",
      "Recall/Sensitivity/True Positive Rate: 0.7206742346061231\n",
      "Confusion Matrix:\n",
      " [[ 232  358]\n",
      " [ 454 1863]]\n",
      "\n",
      "\n",
      "       1997    166   335   1765   1780  label\n",
      "0     126.0  215.0  85.0   81.0   74.0      1\n",
      "1     119.0  183.0  76.0   81.0  149.0      1\n",
      "2     116.0  221.0  70.0   82.0  134.0      1\n",
      "3     119.0  225.0  64.0   94.0  142.0      1\n",
      "4     126.0  214.0  91.0  121.0  177.0      1\n",
      "...     ...    ...   ...    ...    ...    ...\n",
      "9685   17.0  250.0  68.0   22.0   62.0      1\n",
      "9686   16.0   26.0  17.0   21.0   48.0      1\n",
      "9687   17.0  246.0  68.0   27.0   37.0      1\n",
      "9688   16.0  220.0  74.0   25.0   45.0      1\n",
      "9689   14.0   61.0  42.0   23.0   94.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  2\n",
      "Accuracy: 0.760921912624699\n",
      "F1 Score: 0.8204924612426809\n",
      "Precision: 0.696758798358478\n",
      "Recall/Sensitivity/True Positive Rate: 0.760921912624699\n",
      "Confusion Matrix:\n",
      " [[  68   99]\n",
      " [ 596 2144]]\n",
      "\n",
      "\n",
      "      1772    481   670   1212   2245  label\n",
      "0     80.0  112.0  72.0   74.0   91.0      1\n",
      "1     87.0  112.0  72.0  120.0  100.0      1\n",
      "2     85.0  125.0  71.0   81.0  103.0      1\n",
      "3     83.0  127.0  65.0   79.0  126.0      1\n",
      "4     77.0  109.0  65.0   79.0   97.0      1\n",
      "...    ...    ...   ...    ...    ...    ...\n",
      "9685  36.0  255.0  38.0  102.0   52.0      1\n",
      "9686  37.0  255.0  27.0   93.0   56.0      1\n",
      "9687  29.0  255.0  30.0   88.0   42.0      1\n",
      "9688  24.0  255.0  20.0  142.0   39.0      1\n",
      "9689  34.0  226.0  28.0   72.0   33.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  3\n",
      "Accuracy: 0.8582731338149295\n",
      "F1 Score: 0.8878519519945112\n",
      "Precision: 0.8259810945105907\n",
      "Recall/Sensitivity/True Positive Rate: 0.8582731338149295\n",
      "Confusion Matrix:\n",
      " [[  80   72]\n",
      " [ 340 2415]]\n",
      "\n",
      "\n",
      "      1676   2039   2051    581   2272  label\n",
      "0     83.0  135.0  108.0  143.0   95.0      1\n",
      "1     91.0  137.0  113.0  170.0   84.0      1\n",
      "2     88.0  123.0  112.0  164.0   82.0      1\n",
      "3     84.0  147.0   98.0  164.0   78.0      1\n",
      "4     76.0  114.0  126.0  116.0  125.0      1\n",
      "...    ...    ...    ...    ...    ...    ...\n",
      "9685  39.0   33.0   62.0  255.0  104.0      1\n",
      "9686  39.0   18.0   23.0  255.0  102.0      1\n",
      "9687  36.0   27.0   65.0  253.0  101.0      1\n",
      "9688  23.0   25.0   51.0  255.0   96.0      1\n",
      "9689  45.0   31.0   60.0  254.0   90.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  4\n",
      "Accuracy: 0.6130030959752322\n",
      "F1 Score: 0.5745084899556268\n",
      "Precision: 0.7621563059023773\n",
      "Recall/Sensitivity/True Positive Rate: 0.6130030959752322\n",
      "Confusion Matrix:\n",
      " [[ 392  934]\n",
      " [ 191 1390]]\n",
      "\n",
      "\n",
      "        464     74   1739   1361   1756  label\n",
      "0      89.0  208.0   91.0  198.0  149.0      1\n",
      "1     106.0  176.0  124.0  204.0  111.0      1\n",
      "2     123.0  162.0  114.0  197.0  122.0      1\n",
      "3     113.0  164.0  132.0  173.0   96.0      1\n",
      "4      82.0  144.0  154.0  226.0  200.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685  158.0   23.0   21.0  115.0   71.0      1\n",
      "9686  203.0  255.0   29.0  111.0   80.0      1\n",
      "9687   17.0  255.0   53.0  107.0   54.0      1\n",
      "9688  119.0  103.0   23.0   99.0   42.0      1\n",
      "9689  172.0   48.0   40.0   95.0   39.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  5\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "       2216   1948   1778    966    935  label\n",
      "0      75.0  132.0  125.0  135.0  228.0      1\n",
      "1      76.0  119.0  166.0   92.0  197.0      1\n",
      "2      82.0  115.0  141.0   94.0  204.0      1\n",
      "3      77.0  110.0  155.0   80.0  179.0      1\n",
      "4     106.0  107.0  180.0  161.0  236.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685   40.0   18.0   78.0  191.0  112.0      1\n",
      "9686   29.0   17.0   76.0  227.0  107.0      1\n",
      "9687   31.0   16.0   58.0  154.0  102.0      1\n",
      "9688   33.0   15.0   40.0  255.0   98.0      1\n",
      "9689   32.0   13.0  143.0   17.0   93.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  6\n",
      "Accuracy: 0.9642242862057103\n",
      "F1 Score: 0.9817863397548159\n",
      "Precision: 0.9655041879032012\n",
      "Recall/Sensitivity/True Positive Rate: 0.9642242862057103\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [ 104 2803]]\n",
      "\n",
      "\n",
      "       1382   1564   2290    314   2163  label\n",
      "0     107.0  230.0  105.0  188.0   92.0      1\n",
      "1      95.0  235.0  142.0  177.0  103.0      1\n",
      "2     104.0  235.0  144.0   98.0  112.0      1\n",
      "3     104.0  233.0  114.0   77.0  106.0      1\n",
      "4      73.0  164.0  108.0  196.0  143.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685   41.0   68.0  101.0  205.0   45.0      1\n",
      "9686   40.0   61.0   98.0  191.0   36.0      1\n",
      "9687   41.0   72.0   96.0   53.0   36.0      1\n",
      "9688   35.0   76.0   90.0  253.0   38.0      1\n",
      "9689   33.0   65.0   86.0  254.0   31.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  7\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "        425    237   2084    129   1491  label\n",
      "0      98.0   72.0   97.0  166.0  181.0      1\n",
      "1     107.0   75.0  117.0  229.0  182.0      1\n",
      "2      96.0   74.0  124.0  230.0  176.0      1\n",
      "3      76.0   81.0  122.0  215.0  174.0      1\n",
      "4      70.0   91.0  103.0  226.0  114.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685  130.0  133.0  101.0   31.0   68.0      1\n",
      "9686   69.0  225.0   64.0   30.0   79.0      1\n",
      "9687   90.0  124.0   97.0  244.0   71.0      1\n",
      "9688   27.0   25.0   96.0  255.0  116.0      1\n",
      "9689   56.0   36.0   89.0  108.0  255.0      1\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  8\n",
      "Accuracy: 0.9215686274509803\n",
      "F1 Score: 0.9411570087091911\n",
      "Precision: 0.8844252888808979\n",
      "Recall/Sensitivity/True Positive Rate: 0.9215686274509803\n",
      "Confusion Matrix:\n",
      " [[   3   53]\n",
      " [ 175 2676]]\n",
      "\n",
      "\n",
      "       1109    346     42    646    798  label\n",
      "0     124.0  170.0   78.0   90.0   95.0      1\n",
      "1      90.0  127.0   96.0   80.0  139.0      1\n",
      "2      79.0  131.0   95.0   83.0  149.0      1\n",
      "3      99.0   84.0   95.0  124.0  172.0      1\n",
      "4     108.0  201.0   87.0  101.0   90.0      1\n",
      "...     ...    ...    ...    ...    ...    ...\n",
      "9685  241.0  255.0   40.0   26.0   57.0      0\n",
      "9686  169.0  254.0  104.0   62.0   80.0      0\n",
      "9687  224.0   40.0  246.0   65.0   99.0      0\n",
      "9688  255.0  254.0  189.0   71.0   61.0      0\n",
      "9689  150.0  139.0   61.0   59.0   52.0      0\n",
      "\n",
      "[9690 rows x 6 columns]\n",
      "The current Data frame is:  9\n",
      "Accuracy: 0.9594083247334021\n",
      "F1 Score: 0.9638186016874735\n",
      "Precision: 0.9508087030375234\n",
      "Recall/Sensitivity/True Positive Rate: 0.9594083247334021\n",
      "Confusion Matrix:\n",
      " [[   4   45]\n",
      " [  73 2785]]\n",
      "\n",
      "\n",
      "       1605    490   1536    927    742  1966   2066   2235    239  1869  \\\n",
      "0     219.0   83.0  184.0  105.0  103.0  82.0  126.0   98.0   77.0  79.0   \n",
      "1     185.0   97.0  187.0   80.0  123.0  80.0  136.0  125.0   71.0  79.0   \n",
      "2     204.0  129.0  182.0  110.0  196.0  76.0  124.0  109.0   68.0  79.0   \n",
      "3     185.0  148.0  184.0  135.0  235.0  77.0  128.0  111.0   64.0  80.0   \n",
      "4     175.0   80.0  107.0   81.0   78.0  77.0  153.0  119.0   83.0  75.0   \n",
      "...     ...    ...    ...    ...    ...   ...    ...    ...    ...   ...   \n",
      "9685   54.0  255.0  222.0  161.0   96.0  29.0   60.0   92.0   36.0  30.0   \n",
      "9686   55.0  255.0   92.0  104.0  104.0  29.0   38.0  100.0  122.0  36.0   \n",
      "9687   53.0  254.0  109.0   75.0  101.0  31.0   41.0   93.0   60.0  32.0   \n",
      "9688   53.0  255.0  113.0   86.0   94.0  23.0   38.0   91.0   33.0  27.0   \n",
      "9689   41.0  248.0  255.0   70.0   91.0  36.0   34.0   82.0  214.0  28.0   \n",
      "\n",
      "      label  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  0\n",
      "Accuracy: 0.8885448916408669\n",
      "F1 Score: 0.8546058025000232\n",
      "Precision: 0.9648222903099499\n",
      "Recall/Sensitivity/True Positive Rate: 0.8885448916408669\n",
      "Confusion Matrix:\n",
      " [[  26  285]\n",
      " [  39 2557]]\n",
      "\n",
      "\n",
      "       1432     52   1733    637   1262    829  1388    280    635   1423  \\\n",
      "0      89.0   89.0   94.0  115.0  176.0  100.0  89.0  111.0  115.0  178.0   \n",
      "1      91.0   79.0  111.0  110.0  100.0  117.0  85.0   78.0  119.0  147.0   \n",
      "2      87.0   88.0  120.0  119.0  153.0   97.0  83.0   70.0  115.0  152.0   \n",
      "3      82.0   98.0  105.0  129.0  142.0   81.0  78.0   71.0  122.0  197.0   \n",
      "4     116.0   84.0  179.0  131.0  158.0  128.0  76.0   68.0  127.0  157.0   \n",
      "...     ...    ...    ...    ...    ...    ...   ...    ...    ...    ...   \n",
      "9685   42.0  199.0   43.0  255.0   20.0  208.0  38.0  232.0  201.0  102.0   \n",
      "9686   52.0  205.0   47.0  206.0   19.0  217.0  37.0   19.0  170.0   95.0   \n",
      "9687   37.0  255.0   38.0  255.0   17.0  251.0  31.0  105.0  255.0   87.0   \n",
      "9688   38.0  255.0   55.0   76.0   16.0   99.0  26.0   96.0  221.0   80.0   \n",
      "9689   25.0  255.0   82.0  254.0   15.0  102.0  85.0  169.0  255.0   80.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  1\n",
      "Accuracy: 0.6917784657722739\n",
      "F1 Score: 0.6820846329363506\n",
      "Precision: 0.7144587872674384\n",
      "Recall/Sensitivity/True Positive Rate: 0.6917784657722739\n",
      "Confusion Matrix:\n",
      " [[ 312  522]\n",
      " [ 374 1699]]\n",
      "\n",
      "\n",
      "       1997    166   335   1765   1780    845    281    638   1561    148  \\\n",
      "0     126.0  215.0  85.0   81.0   74.0  141.0  103.0  120.0  225.0   96.0   \n",
      "1     119.0  183.0  76.0   81.0  149.0  191.0   89.0  110.0  231.0   83.0   \n",
      "2     116.0  221.0  70.0   82.0  134.0  169.0   81.0  127.0  234.0  108.0   \n",
      "3     119.0  225.0  64.0   94.0  142.0  139.0   77.0  132.0  237.0  109.0   \n",
      "4     126.0  214.0  91.0  121.0  177.0  148.0   73.0  132.0  152.0  107.0   \n",
      "...     ...    ...   ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685   17.0  250.0  68.0   22.0   62.0   39.0  255.0  253.0   50.0  255.0   \n",
      "9686   16.0   26.0  17.0   21.0   48.0   24.0   21.0  153.0   41.0  255.0   \n",
      "9687   17.0  246.0  68.0   27.0   37.0   23.0  189.0  255.0   48.0  255.0   \n",
      "9688   16.0  220.0  74.0   25.0   45.0   18.0   80.0   31.0   36.0  255.0   \n",
      "9689   14.0   61.0  42.0   23.0   94.0   19.0  189.0  217.0   36.0   19.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  2\n",
      "Accuracy: 0.7351221190230478\n",
      "F1 Score: 0.7448278768406621\n",
      "Precision: 0.7182343362243369\n",
      "Recall/Sensitivity/True Positive Rate: 0.7351221190230478\n",
      "Confusion Matrix:\n",
      " [[ 219  325]\n",
      " [ 445 1918]]\n",
      "\n",
      "\n",
      "      1772    481   670   1212   2245   1465   2023   2246  1389    274  label\n",
      "0     80.0  112.0  72.0   74.0   91.0  172.0  132.0   83.0  91.0  204.0      1\n",
      "1     87.0  112.0  72.0  120.0  100.0  168.0  100.0   95.0  84.0  166.0      1\n",
      "2     85.0  125.0  71.0   81.0  103.0  171.0   93.0   97.0  83.0   88.0      1\n",
      "3     83.0  127.0  65.0   79.0  126.0  190.0   90.0  109.0  78.0   64.0      1\n",
      "4     77.0  109.0  65.0   79.0   97.0  176.0   85.0   96.0  77.0  208.0      1\n",
      "...    ...    ...   ...    ...    ...    ...    ...    ...   ...    ...    ...\n",
      "9685  36.0  255.0  38.0  102.0   52.0   85.0   19.0   37.0  35.0  226.0      1\n",
      "9686  37.0  255.0  27.0   93.0   56.0   69.0   18.0   36.0  34.0  215.0      1\n",
      "9687  29.0  255.0  30.0   88.0   42.0   59.0   18.0   41.0  30.0  133.0      1\n",
      "9688  24.0  255.0  20.0  142.0   39.0   64.0   17.0   39.0  30.0  238.0      1\n",
      "9689  34.0  226.0  28.0   72.0   33.0   52.0   17.0   34.0  67.0  239.0      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  3\n",
      "Accuracy: 0.7925696594427245\n",
      "F1 Score: 0.7808256892588054\n",
      "Precision: 0.8195796333773478\n",
      "Recall/Sensitivity/True Positive Rate: 0.7925696594427245\n",
      "Confusion Matrix:\n",
      " [[ 188  371]\n",
      " [ 232 2116]]\n",
      "\n",
      "\n",
      "      1676   2039   2051    581   2272    491  1677  1674   1921   1148  label\n",
      "0     83.0  135.0  108.0  143.0   95.0   84.0  80.0  89.0  125.0   85.0      1\n",
      "1     91.0  137.0  113.0  170.0   84.0   99.0  90.0  86.0  142.0   93.0      1\n",
      "2     88.0  123.0  112.0  164.0   82.0  133.0  90.0  80.0  146.0  101.0      1\n",
      "3     84.0  147.0   98.0  164.0   78.0  151.0  88.0  76.0  143.0   92.0      1\n",
      "4     76.0  114.0  126.0  116.0  125.0   81.0  79.0  75.0  144.0   76.0      1\n",
      "...    ...    ...    ...    ...    ...    ...   ...   ...    ...    ...    ...\n",
      "9685  39.0   33.0   62.0  255.0  104.0  255.0  40.0  33.0  101.0   32.0      1\n",
      "9686  39.0   18.0   23.0  255.0  102.0  255.0  36.0  47.0   41.0   41.0      1\n",
      "9687  36.0   27.0   65.0  253.0  101.0  168.0  31.0  36.0   54.0   36.0      1\n",
      "9688  23.0   25.0   51.0  255.0   96.0  255.0  28.0  26.0   45.0   94.0      1\n",
      "9689  45.0   31.0   60.0  254.0   90.0  224.0  53.0  43.0   56.0   35.0      1\n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  4\n",
      "Accuracy: 0.5366357069143447\n",
      "F1 Score: 0.49532723738210094\n",
      "Precision: 0.7675844066171659\n",
      "Recall/Sensitivity/True Positive Rate: 0.5366357069143447\n",
      "Confusion Matrix:\n",
      " [[ 449 1213]\n",
      " [ 134 1111]]\n",
      "\n",
      "\n",
      "        464     74   1739   1361   1756    445   1874   1928    774     58  \\\n",
      "0      89.0  208.0   91.0  198.0  149.0  109.0  152.0  144.0  153.0  113.0   \n",
      "1     106.0  176.0  124.0  204.0  111.0   89.0  150.0  100.0  165.0   92.0   \n",
      "2     123.0  162.0  114.0  197.0  122.0  103.0  177.0  105.0  165.0  121.0   \n",
      "3     113.0  164.0  132.0  173.0   96.0  111.0  137.0   70.0  169.0  162.0   \n",
      "4      82.0  144.0  154.0  226.0  200.0   98.0  122.0   83.0  161.0  103.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  158.0   23.0   21.0  115.0   71.0  255.0   67.0   19.0  227.0  255.0   \n",
      "9686  203.0  255.0   29.0  111.0   80.0  255.0   58.0   18.0  228.0  134.0   \n",
      "9687   17.0  255.0   53.0  107.0   54.0   83.0   42.0   18.0  255.0  255.0   \n",
      "9688  119.0  103.0   23.0   99.0   42.0  253.0   47.0   16.0  253.0  236.0   \n",
      "9689  172.0   48.0   40.0   95.0   39.0  198.0   60.0   16.0  124.0   15.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  5\n",
      "Accuracy: 0.977640178878569\n",
      "F1 Score: 0.9886936858584103\n",
      "Precision: 0.9781401404791514\n",
      "Recall/Sensitivity/True Positive Rate: 0.977640178878569\n",
      "Confusion Matrix:\n",
      " [[   0    0]\n",
      " [  65 2842]]\n",
      "\n",
      "\n",
      "       2216   1948   1778    966    935   1063    963   956    830    374  \\\n",
      "0      75.0  132.0  125.0  135.0  228.0  139.0   88.0  78.0   92.0   68.0   \n",
      "1      76.0  119.0  166.0   92.0  197.0  107.0  165.0  83.0  108.0   79.0   \n",
      "2      82.0  115.0  141.0   94.0  204.0  126.0  140.0  79.0   85.0   89.0   \n",
      "3      77.0  110.0  155.0   80.0  179.0   93.0  159.0  76.0   76.0  101.0   \n",
      "4     106.0  107.0  180.0  161.0  236.0   98.0  166.0  76.0  110.0   76.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...   ...    ...    ...   \n",
      "9685   40.0   18.0   78.0  191.0  112.0  150.0  185.0  42.0  172.0  109.0   \n",
      "9686   29.0   17.0   76.0  227.0  107.0  211.0  228.0  40.0  244.0  217.0   \n",
      "9687   31.0   16.0   58.0  154.0  102.0  109.0  221.0  39.0  255.0  240.0   \n",
      "9688   33.0   15.0   40.0  255.0   98.0  255.0  255.0  35.0  148.0  160.0   \n",
      "9689   32.0   13.0  143.0   17.0   93.0  243.0   20.0  17.0  208.0   60.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  6\n",
      "Accuracy: 0.7616099071207431\n",
      "F1 Score: 0.6874428655278926\n",
      "Precision: 0.9456411632248648\n",
      "Recall/Sensitivity/True Positive Rate: 0.7616099071207431\n",
      "Confusion Matrix:\n",
      " [[  55  644]\n",
      " [  49 2159]]\n",
      "\n",
      "\n",
      "       1382   1564   2290    314   2163   1948   1883   1013   1241   1835  \\\n",
      "0     107.0  230.0  105.0  188.0   92.0  132.0  104.0  125.0   91.0   99.0   \n",
      "1      95.0  235.0  142.0  177.0  103.0  119.0  127.0   83.0   95.0  125.0   \n",
      "2     104.0  235.0  144.0   98.0  112.0  115.0  120.0   76.0   88.0  117.0   \n",
      "3     104.0  233.0  114.0   77.0  106.0  110.0  139.0   90.0   80.0  136.0   \n",
      "4      73.0  164.0  108.0  196.0  143.0  107.0  145.0  108.0  106.0  149.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685   41.0   68.0  101.0  205.0   45.0   18.0   46.0  221.0   34.0   87.0   \n",
      "9686   40.0   61.0   98.0  191.0   36.0   17.0   80.0  229.0   39.0   89.0   \n",
      "9687   41.0   72.0   96.0   53.0   36.0   16.0   29.0  225.0   49.0  104.0   \n",
      "9688   35.0   76.0   90.0  253.0   38.0   15.0   32.0  255.0   99.0   89.0   \n",
      "9689   33.0   65.0   86.0  254.0   31.0   13.0   20.0   24.0   33.0   91.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  7\n",
      "Accuracy: 0.9656002751977985\n",
      "F1 Score: 0.9698219226855641\n",
      "Precision: 0.9573114767940992\n",
      "Recall/Sensitivity/True Positive Rate: 0.9656002751977985\n",
      "Confusion Matrix:\n",
      " [[   2   37]\n",
      " [  63 2805]]\n",
      "\n",
      "\n",
      "        425    237   2084    129   1491    461   1322    218   2192    884  \\\n",
      "0      98.0   72.0   97.0  166.0  181.0   89.0  148.0  179.0  155.0  228.0   \n",
      "1     107.0   75.0  117.0  229.0  182.0   96.0  169.0  200.0  119.0  207.0   \n",
      "2      96.0   74.0  124.0  230.0  176.0  132.0  126.0  186.0  115.0  195.0   \n",
      "3      76.0   81.0  122.0  215.0  174.0  128.0  133.0  143.0   99.0  146.0   \n",
      "4      70.0   91.0  103.0  226.0  114.0   76.0  137.0  190.0  116.0  182.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  130.0  133.0  101.0   31.0   68.0  173.0   45.0  255.0  100.0   56.0   \n",
      "9686   69.0  225.0   64.0   30.0   79.0  239.0   36.0   20.0   71.0   91.0   \n",
      "9687   90.0  124.0   97.0  244.0   71.0   64.0   21.0  159.0   94.0   90.0   \n",
      "9688   27.0   25.0   96.0  255.0  116.0  124.0   17.0  255.0   89.0   84.0   \n",
      "9689   56.0   36.0   89.0  108.0  255.0  103.0   16.0  104.0   86.0   82.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      1  \n",
      "9686      1  \n",
      "9687      1  \n",
      "9688      1  \n",
      "9689      1  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  8\n",
      "Accuracy: 0.8964568283453732\n",
      "F1 Score: 0.8921566765829845\n",
      "Precision: 0.9053586927829773\n",
      "Recall/Sensitivity/True Positive Rate: 0.8964568283453732\n",
      "Confusion Matrix:\n",
      " [[  45  168]\n",
      " [ 133 2561]]\n",
      "\n",
      "\n",
      "       1109    346     42    646    798   2256    492   1934   2170   1402  \\\n",
      "0     124.0  170.0   78.0   90.0   95.0   85.0   86.0  111.0   84.0  120.0   \n",
      "1      90.0  127.0   96.0   80.0  139.0   74.0  102.0  108.0   82.0  136.0   \n",
      "2      79.0  131.0   95.0   83.0  149.0   77.0  134.0   99.0   96.0  122.0   \n",
      "3      99.0   84.0   95.0  124.0  172.0   75.0  135.0  102.0   89.0  139.0   \n",
      "4     108.0  201.0   87.0  101.0   90.0  129.0   81.0   98.0  120.0  130.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  241.0  255.0   40.0   26.0   57.0   50.0  255.0   19.0   58.0  100.0   \n",
      "9686  169.0  254.0  104.0   62.0   80.0   43.0  255.0   19.0   53.0   87.0   \n",
      "9687  224.0   40.0  246.0   65.0   99.0   35.0  134.0   18.0   63.0   87.0   \n",
      "9688  255.0  254.0  189.0   71.0   61.0   33.0  214.0   16.0   58.0  130.0   \n",
      "9689  150.0  139.0   61.0   59.0   52.0   37.0  166.0   15.0   65.0   98.0   \n",
      "\n",
      "      label  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "9685      0  \n",
      "9686      0  \n",
      "9687      0  \n",
      "9688      0  \n",
      "9689      0  \n",
      "\n",
      "[9690 rows x 11 columns]\n",
      "The current Data frame is:  9\n",
      "Accuracy: 0.9484004127966976\n",
      "F1 Score: 0.9460453359604873\n",
      "Precision: 0.9531814989719715\n",
      "Recall/Sensitivity/True Positive Rate: 0.9484004127966976\n",
      "Confusion Matrix:\n",
      " [[  10   83]\n",
      " [  67 2747]]\n",
      "\n",
      "\n",
      "       1605    490   1536    927    742  1966   2066   2235    239  1869  ...  \\\n",
      "0     219.0   83.0  184.0  105.0  103.0  82.0  126.0   98.0   77.0  79.0  ...   \n",
      "1     185.0   97.0  187.0   80.0  123.0  80.0  136.0  125.0   71.0  79.0  ...   \n",
      "2     204.0  129.0  182.0  110.0  196.0  76.0  124.0  109.0   68.0  79.0  ...   \n",
      "3     185.0  148.0  184.0  135.0  235.0  77.0  128.0  111.0   64.0  80.0  ...   \n",
      "4     175.0   80.0  107.0   81.0   78.0  77.0  153.0  119.0   83.0  75.0  ...   \n",
      "...     ...    ...    ...    ...    ...   ...    ...    ...    ...   ...  ...   \n",
      "9685   54.0  255.0  222.0  161.0   96.0  29.0   60.0   92.0   36.0  30.0  ...   \n",
      "9686   55.0  255.0   92.0  104.0  104.0  29.0   38.0  100.0  122.0  36.0  ...   \n",
      "9687   53.0  254.0  109.0   75.0  101.0  31.0   41.0   93.0   60.0  32.0  ...   \n",
      "9688   53.0  255.0  113.0   86.0   94.0  23.0   38.0   91.0   33.0  27.0  ...   \n",
      "9689   41.0  248.0  255.0   70.0   91.0  36.0   34.0   82.0  214.0  28.0  ...   \n",
      "\n",
      "       1264   2090  1815   1766    661   2122    409   1497    628  label  \n",
      "0     234.0  119.0  87.0   81.0   85.0  102.0   95.0  132.0  166.0      0  \n",
      "1     194.0  137.0  75.0   77.0   88.0  111.0   83.0  167.0  182.0      0  \n",
      "2     227.0  128.0  72.0   75.0   87.0  131.0  102.0  167.0  173.0      0  \n",
      "3     225.0  123.0  72.0   82.0   85.0  118.0  135.0  165.0  175.0      0  \n",
      "4     224.0  116.0  85.0  105.0   75.0  118.0   79.0  126.0  127.0      0  \n",
      "...     ...    ...   ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "9685   38.0   97.0  18.0   17.0   57.0   53.0  104.0   76.0  255.0      1  \n",
      "9686   60.0   81.0  17.0   17.0  119.0   77.0   98.0  109.0  255.0      1  \n",
      "9687   80.0   92.0  16.0   17.0   83.0   52.0   63.0   87.0  255.0      1  \n",
      "9688   58.0   89.0  15.0   15.0   22.0   47.0   83.0  118.0  192.0      1  \n",
      "9689   66.0   83.0  14.0   13.0   29.0   45.0  134.0  144.0  255.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  0\n",
      "Accuracy: 0.8796009631922944\n",
      "F1 Score: 0.840835167070912\n",
      "Precision: 0.9713255757983613\n",
      "Recall/Sensitivity/True Positive Rate: 0.8796009631922944\n",
      "Confusion Matrix:\n",
      " [[  42  327]\n",
      " [  23 2515]]\n",
      "\n",
      "\n",
      "       1432     52   1733    637   1262    829  1388    280    635   1423  \\\n",
      "0      89.0   89.0   94.0  115.0  176.0  100.0  89.0  111.0  115.0  178.0   \n",
      "1      91.0   79.0  111.0  110.0  100.0  117.0  85.0   78.0  119.0  147.0   \n",
      "2      87.0   88.0  120.0  119.0  153.0   97.0  83.0   70.0  115.0  152.0   \n",
      "3      82.0   98.0  105.0  129.0  142.0   81.0  78.0   71.0  122.0  197.0   \n",
      "4     116.0   84.0  179.0  131.0  158.0  128.0  76.0   68.0  127.0  157.0   \n",
      "...     ...    ...    ...    ...    ...    ...   ...    ...    ...    ...   \n",
      "9685   42.0  199.0   43.0  255.0   20.0  208.0  38.0  232.0  201.0  102.0   \n",
      "9686   52.0  205.0   47.0  206.0   19.0  217.0  37.0   19.0  170.0   95.0   \n",
      "9687   37.0  255.0   38.0  255.0   17.0  251.0  31.0  105.0  255.0   87.0   \n",
      "9688   38.0  255.0   55.0   76.0   16.0   99.0  26.0   96.0  221.0   80.0   \n",
      "9689   25.0  255.0   82.0  254.0   15.0  102.0  85.0  169.0  255.0   80.0   \n",
      "\n",
      "      ...   2221  1773  1868    739    828   2022   1876   1609   1377  label  \n",
      "0     ...   88.0  77.0  80.0   83.0  109.0  117.0   83.0  234.0  151.0      1  \n",
      "1     ...   93.0  83.0  83.0   80.0  112.0  111.0  131.0  236.0  158.0      1  \n",
      "2     ...   88.0  81.0  85.0  115.0  112.0  104.0  118.0  234.0  153.0      1  \n",
      "3     ...   73.0  84.0  84.0  154.0  100.0   95.0  178.0  221.0  180.0      1  \n",
      "4     ...  139.0  77.0  72.0   77.0  131.0  114.0  121.0  209.0  132.0      1  \n",
      "...   ...    ...   ...   ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "9685  ...  104.0  35.0  37.0   19.0  226.0   30.0   57.0   37.0   19.0      1  \n",
      "9686  ...   99.0  40.0  39.0   18.0  165.0   21.0   57.0   46.0   20.0      1  \n",
      "9687  ...  101.0  33.0  30.0   17.0  212.0   20.0   32.0   38.0   21.0      1  \n",
      "9688  ...   95.0  37.0  34.0   16.0  226.0   22.0   37.0   26.0   20.0      1  \n",
      "9689  ...   91.0  23.0  39.0   15.0   81.0   21.0   59.0   40.0   17.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  1\n",
      "Accuracy: 0.6824905400756794\n",
      "F1 Score: 0.6659160189027782\n",
      "Precision: 0.7279689983916663\n",
      "Recall/Sensitivity/True Positive Rate: 0.6824905400756794\n",
      "Confusion Matrix:\n",
      " [[ 369  606]\n",
      " [ 317 1615]]\n",
      "\n",
      "\n",
      "       1997    166   335   1765   1780    845    281    638   1561    148  \\\n",
      "0     126.0  215.0  85.0   81.0   74.0  141.0  103.0  120.0  225.0   96.0   \n",
      "1     119.0  183.0  76.0   81.0  149.0  191.0   89.0  110.0  231.0   83.0   \n",
      "2     116.0  221.0  70.0   82.0  134.0  169.0   81.0  127.0  234.0  108.0   \n",
      "3     119.0  225.0  64.0   94.0  142.0  139.0   77.0  132.0  237.0  109.0   \n",
      "4     126.0  214.0  91.0  121.0  177.0  148.0   73.0  132.0  152.0  107.0   \n",
      "...     ...    ...   ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685   17.0  250.0  68.0   22.0   62.0   39.0  255.0  253.0   50.0  255.0   \n",
      "9686   16.0   26.0  17.0   21.0   48.0   24.0   21.0  153.0   41.0  255.0   \n",
      "9687   17.0  246.0  68.0   27.0   37.0   23.0  189.0  255.0   48.0  255.0   \n",
      "9688   16.0  220.0  74.0   25.0   45.0   18.0   80.0   31.0   36.0  255.0   \n",
      "9689   14.0   61.0  42.0   23.0   94.0   19.0  189.0  217.0   36.0   19.0   \n",
      "\n",
      "      ...    487    537   2293   1699   1023    136   284   1185    391  label  \n",
      "0     ...   80.0  109.0   94.0  101.0  153.0   98.0  71.0  168.0   81.0      1  \n",
      "1     ...  120.0  144.0   99.0   85.0   97.0   92.0  91.0  162.0   81.0      1  \n",
      "2     ...  118.0  143.0  103.0   95.0  156.0   89.0  90.0  175.0   73.0      1  \n",
      "3     ...  145.0  143.0  133.0   97.0  176.0   90.0  84.0  191.0   72.0      1  \n",
      "4     ...   75.0   81.0  103.0  164.0  110.0   84.0  97.0  144.0   92.0      1  \n",
      "...   ...    ...    ...    ...    ...    ...    ...   ...    ...    ...    ...  \n",
      "9685  ...  255.0  255.0   52.0  112.0   61.0  102.0  67.0   40.0  255.0      1  \n",
      "9686  ...  255.0  255.0   55.0  110.0   23.0   88.0  41.0   31.0  255.0      1  \n",
      "9687  ...  255.0  255.0   41.0  106.0   21.0  151.0  65.0   21.0   28.0      1  \n",
      "9688  ...  255.0  255.0   37.0   98.0   21.0  251.0  34.0   17.0  255.0      1  \n",
      "9689  ...  255.0  255.0   32.0   93.0   18.0   25.0  29.0   17.0  255.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  2\n",
      "Accuracy: 0.7003783969728242\n",
      "F1 Score: 0.68695212853178\n",
      "Precision: 0.7344234619779695\n",
      "Recall/Sensitivity/True Positive Rate: 0.7003783969728242\n",
      "Confusion Matrix:\n",
      " [[ 337  544]\n",
      " [ 327 1699]]\n",
      "\n",
      "\n",
      "      1772    481   670   1212   2245   1465   2023   2246  1389    274  ...  \\\n",
      "0     80.0  112.0  72.0   74.0   91.0  172.0  132.0   83.0  91.0  204.0  ...   \n",
      "1     87.0  112.0  72.0  120.0  100.0  168.0  100.0   95.0  84.0  166.0  ...   \n",
      "2     85.0  125.0  71.0   81.0  103.0  171.0   93.0   97.0  83.0   88.0  ...   \n",
      "3     83.0  127.0  65.0   79.0  126.0  190.0   90.0  109.0  78.0   64.0  ...   \n",
      "4     77.0  109.0  65.0   79.0   97.0  176.0   85.0   96.0  77.0  208.0  ...   \n",
      "...    ...    ...   ...    ...    ...    ...    ...    ...   ...    ...  ...   \n",
      "9685  36.0  255.0  38.0  102.0   52.0   85.0   19.0   37.0  35.0  226.0  ...   \n",
      "9686  37.0  255.0  27.0   93.0   56.0   69.0   18.0   36.0  34.0  215.0  ...   \n",
      "9687  29.0  255.0  30.0   88.0   42.0   59.0   18.0   41.0  30.0  133.0  ...   \n",
      "9688  24.0  255.0  20.0  142.0   39.0   64.0   17.0   39.0  30.0  238.0  ...   \n",
      "9689  34.0  226.0  28.0   72.0   33.0   52.0   17.0   34.0  67.0  239.0  ...   \n",
      "\n",
      "      1243    777   2204  2156    684  1677    314  2011    541  label  \n",
      "0     87.0  107.0  103.0  97.0  105.0  80.0  188.0  79.0  121.0      1  \n",
      "1     90.0  137.0   84.0  80.0  107.0  90.0  177.0  79.0  145.0      1  \n",
      "2     89.0  126.0   75.0  75.0  117.0  90.0   98.0  79.0  139.0      1  \n",
      "3     86.0  140.0   68.0  71.0  128.0  88.0   77.0  76.0  141.0      1  \n",
      "4     79.0  145.0   71.0  70.0  133.0  79.0  196.0  71.0   89.0      1  \n",
      "...    ...    ...    ...   ...    ...   ...    ...   ...    ...    ...  \n",
      "9685  34.0  255.0   26.0  29.0  238.0  40.0  205.0  50.0  255.0      1  \n",
      "9686  39.0  202.0   29.0  30.0  204.0  36.0  191.0  54.0  255.0      1  \n",
      "9687  38.0  255.0   34.0  30.0  255.0  31.0   53.0  65.0  255.0      1  \n",
      "9688  47.0   58.0   23.0  24.0   24.0  28.0  253.0  65.0  164.0      1  \n",
      "9689  68.0  251.0   35.0  29.0  255.0  53.0  254.0  65.0  158.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  3\n",
      "Accuracy: 0.7296181630546955\n",
      "F1 Score: 0.6925545518773143\n",
      "Precision: 0.8519568209571109\n",
      "Recall/Sensitivity/True Positive Rate: 0.7296181630546955\n",
      "Confusion Matrix:\n",
      " [[ 310  676]\n",
      " [ 110 1811]]\n",
      "\n",
      "\n",
      "      1676   2039   2051    581   2272    491  1677  1674   1921   1148  ...  \\\n",
      "0     83.0  135.0  108.0  143.0   95.0   84.0  80.0  89.0  125.0   85.0  ...   \n",
      "1     91.0  137.0  113.0  170.0   84.0   99.0  90.0  86.0  142.0   93.0  ...   \n",
      "2     88.0  123.0  112.0  164.0   82.0  133.0  90.0  80.0  146.0  101.0  ...   \n",
      "3     84.0  147.0   98.0  164.0   78.0  151.0  88.0  76.0  143.0   92.0  ...   \n",
      "4     76.0  114.0  126.0  116.0  125.0   81.0  79.0  75.0  144.0   76.0  ...   \n",
      "...    ...    ...    ...    ...    ...    ...   ...   ...    ...    ...  ...   \n",
      "9685  39.0   33.0   62.0  255.0  104.0  255.0  40.0  33.0  101.0   32.0  ...   \n",
      "9686  39.0   18.0   23.0  255.0  102.0  255.0  36.0  47.0   41.0   41.0  ...   \n",
      "9687  36.0   27.0   65.0  253.0  101.0  168.0  31.0  36.0   54.0   36.0  ...   \n",
      "9688  23.0   25.0   51.0  255.0   96.0  255.0  28.0  26.0   45.0   94.0  ...   \n",
      "9689  45.0   31.0   60.0  254.0   90.0  224.0  53.0  43.0   56.0   35.0  ...   \n",
      "\n",
      "        348   910   2182    470   1474   1103    921   2066      7  label  \n",
      "0     225.0  82.0   90.0   95.0   90.0   94.0  109.0  126.0  119.0      1  \n",
      "1     168.0  73.0   84.0   97.0  141.0   80.0  137.0  136.0  107.0      1  \n",
      "2     106.0  72.0  103.0   94.0  104.0   84.0  137.0  124.0  109.0      1  \n",
      "3      86.0  73.0   96.0   76.0   84.0   87.0  147.0  128.0   96.0      1  \n",
      "4     212.0  69.0  134.0   97.0  193.0   73.0  157.0  153.0  109.0      1  \n",
      "...     ...   ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "9685  255.0  48.0   96.0  103.0   20.0   36.0  252.0   60.0  255.0      1  \n",
      "9686  255.0  47.0   49.0  170.0   20.0   49.0  207.0   38.0  254.0      1  \n",
      "9687   40.0  39.0   92.0  199.0   23.0   33.0  107.0   41.0  255.0      1  \n",
      "9688  255.0  35.0   88.0   35.0   21.0   70.0  255.0   38.0  255.0      1  \n",
      "9689  155.0  17.0   85.0   33.0   18.0  137.0   26.0   34.0  212.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  4\n",
      "Accuracy: 0.52046783625731\n",
      "F1 Score: 0.48000633242161717\n",
      "Precision: 0.7679480647713061\n",
      "Recall/Sensitivity/True Positive Rate: 0.52046783625731\n",
      "Confusion Matrix:\n",
      " [[ 458 1269]\n",
      " [ 125 1055]]\n",
      "\n",
      "\n",
      "        464     74   1739   1361   1756    445   1874   1928    774     58  \\\n",
      "0      89.0  208.0   91.0  198.0  149.0  109.0  152.0  144.0  153.0  113.0   \n",
      "1     106.0  176.0  124.0  204.0  111.0   89.0  150.0  100.0  165.0   92.0   \n",
      "2     123.0  162.0  114.0  197.0  122.0  103.0  177.0  105.0  165.0  121.0   \n",
      "3     113.0  164.0  132.0  173.0   96.0  111.0  137.0   70.0  169.0  162.0   \n",
      "4      82.0  144.0  154.0  226.0  200.0   98.0  122.0   83.0  161.0  103.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  158.0   23.0   21.0  115.0   71.0  255.0   67.0   19.0  227.0  255.0   \n",
      "9686  203.0  255.0   29.0  111.0   80.0  255.0   58.0   18.0  228.0  134.0   \n",
      "9687   17.0  255.0   53.0  107.0   54.0   83.0   42.0   18.0  255.0  255.0   \n",
      "9688  119.0  103.0   23.0   99.0   42.0  253.0   47.0   16.0  253.0  236.0   \n",
      "9689  172.0   48.0   40.0   95.0   39.0  198.0   60.0   16.0  124.0   15.0   \n",
      "\n",
      "      ...   1921   1617  1865   1018   1909   811   1056   2054   615  label  \n",
      "0     ...  125.0  105.0  85.0  124.0   77.0  75.0  171.0   74.0  79.0      1  \n",
      "1     ...  142.0  106.0  84.0  114.0   91.0  77.0  118.0   94.0  78.0      1  \n",
      "2     ...  146.0   95.0  76.0  131.0   95.0  76.0  138.0   94.0  73.0      1  \n",
      "3     ...  143.0   95.0  73.0  139.0   99.0  76.0  136.0   95.0  76.0      1  \n",
      "4     ...  144.0  158.0  72.0  144.0  115.0  70.0  122.0  109.0  73.0      1  \n",
      "...   ...    ...    ...   ...    ...    ...   ...    ...    ...   ...    ...  \n",
      "9685  ...  101.0   93.0  55.0  246.0   16.0  46.0  108.0   67.0  60.0      1  \n",
      "9686  ...   41.0   89.0  58.0  144.0   16.0  44.0  255.0   26.0  57.0      1  \n",
      "9687  ...   54.0   84.0  26.0  113.0   16.0  21.0  202.0   77.0  27.0      1  \n",
      "9688  ...   45.0   77.0  24.0  252.0   15.0  19.0  255.0   59.0  28.0      1  \n",
      "9689  ...   56.0   77.0  21.0   28.0   13.0  18.0   98.0   65.0  28.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  5\n",
      "Accuracy: 0.5576195390436877\n",
      "F1 Score: 0.4186555600505352\n",
      "Precision: 0.9612976878531656\n",
      "Recall/Sensitivity/True Positive Rate: 0.5576195390436877\n",
      "Confusion Matrix:\n",
      " [[  37 1258]\n",
      " [  28 1584]]\n",
      "\n",
      "\n",
      "       2216   1948   1778    966    935   1063    963   956    830    374  \\\n",
      "0      75.0  132.0  125.0  135.0  228.0  139.0   88.0  78.0   92.0   68.0   \n",
      "1      76.0  119.0  166.0   92.0  197.0  107.0  165.0  83.0  108.0   79.0   \n",
      "2      82.0  115.0  141.0   94.0  204.0  126.0  140.0  79.0   85.0   89.0   \n",
      "3      77.0  110.0  155.0   80.0  179.0   93.0  159.0  76.0   76.0  101.0   \n",
      "4     106.0  107.0  180.0  161.0  236.0   98.0  166.0  76.0  110.0   76.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...   ...    ...    ...   \n",
      "9685   40.0   18.0   78.0  191.0  112.0  150.0  185.0  42.0  172.0  109.0   \n",
      "9686   29.0   17.0   76.0  227.0  107.0  211.0  228.0  40.0  244.0  217.0   \n",
      "9687   31.0   16.0   58.0  154.0  102.0  109.0  221.0  39.0  255.0  240.0   \n",
      "9688   33.0   15.0   40.0  255.0   98.0  255.0  255.0  35.0  148.0  160.0   \n",
      "9689   32.0   13.0  143.0   17.0   93.0  243.0   20.0  17.0  208.0   60.0   \n",
      "\n",
      "      ...    965   1433   1734     41    972   1049   1095   719    967  label  \n",
      "0     ...  129.0   88.0  119.0   85.0  104.0  102.0  106.0  75.0  128.0      1  \n",
      "1     ...   78.0   89.0  102.0  103.0  120.0   93.0  101.0  73.0  116.0      1  \n",
      "2     ...   73.0   84.0  110.0  104.0   98.0   84.0   96.0  70.0  120.0      1  \n",
      "3     ...   83.0   78.0   87.0   94.0   86.0   83.0  116.0  67.0  102.0      1  \n",
      "4     ...  160.0  106.0  177.0  103.0   98.0   91.0   99.0  65.0  162.0      1  \n",
      "...   ...    ...    ...    ...    ...    ...    ...    ...   ...    ...    ...  \n",
      "9685  ...  185.0   36.0   42.0   28.0  255.0   40.0   48.0  28.0  185.0      1  \n",
      "9686  ...  220.0   34.0   60.0  100.0  176.0   48.0   43.0  44.0  171.0      1  \n",
      "9687  ...  173.0   36.0   60.0  253.0  115.0   50.0   37.0  32.0  142.0      1  \n",
      "9688  ...  255.0   54.0   56.0  242.0  222.0  100.0   93.0  13.0  255.0      1  \n",
      "9689  ...   17.0   21.0   99.0   97.0   43.0   50.0   62.0  52.0   14.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  6\n",
      "Accuracy: 0.6487788097695218\n",
      "F1 Score: 0.5406714335178404\n",
      "Precision: 0.9499374305065909\n",
      "Recall/Sensitivity/True Positive Rate: 0.648778809769522\n",
      "Confusion Matrix:\n",
      " [[  72  989]\n",
      " [  32 1814]]\n",
      "\n",
      "\n",
      "       1382   1564   2290    314   2163   1948   1883   1013   1241   1835  \\\n",
      "0     107.0  230.0  105.0  188.0   92.0  132.0  104.0  125.0   91.0   99.0   \n",
      "1      95.0  235.0  142.0  177.0  103.0  119.0  127.0   83.0   95.0  125.0   \n",
      "2     104.0  235.0  144.0   98.0  112.0  115.0  120.0   76.0   88.0  117.0   \n",
      "3     104.0  233.0  114.0   77.0  106.0  110.0  139.0   90.0   80.0  136.0   \n",
      "4      73.0  164.0  108.0  196.0  143.0  107.0  145.0  108.0  106.0  149.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685   41.0   68.0  101.0  205.0   45.0   18.0   46.0  221.0   34.0   87.0   \n",
      "9686   40.0   61.0   98.0  191.0   36.0   17.0   80.0  229.0   39.0   89.0   \n",
      "9687   41.0   72.0   96.0   53.0   36.0   16.0   29.0  225.0   49.0  104.0   \n",
      "9688   35.0   76.0   90.0  253.0   38.0   15.0   32.0  255.0   99.0   89.0   \n",
      "9689   33.0   65.0   86.0  254.0   31.0   13.0   20.0   24.0   33.0   91.0   \n",
      "\n",
      "      ...  1535   1855   1806    531    213  1677    136    280    512  label  \n",
      "0     ...  90.0  134.0  143.0  139.0  212.0  80.0   98.0  111.0  118.0      1  \n",
      "1     ...  86.0  126.0  117.0  144.0  173.0  90.0   92.0   78.0  132.0      1  \n",
      "2     ...  84.0  123.0  116.0  149.0  213.0  90.0   89.0   70.0  120.0      1  \n",
      "3     ...  86.0  113.0  118.0  149.0  172.0  88.0   90.0   71.0  114.0      1  \n",
      "4     ...  80.0  131.0  166.0   97.0  190.0  79.0   84.0   68.0  100.0      1  \n",
      "...   ...   ...    ...    ...    ...    ...   ...    ...    ...    ...    ...  \n",
      "9685  ...  40.0   85.0   79.0  255.0  255.0  40.0  102.0  232.0  128.0      1  \n",
      "9686  ...  33.0  101.0   42.0  255.0   49.0  36.0   88.0   19.0  113.0      1  \n",
      "9687  ...  30.0   70.0   85.0  255.0  192.0  31.0  151.0  105.0   37.0      1  \n",
      "9688  ...  29.0   66.0   78.0  255.0  251.0  28.0  251.0   96.0  133.0      1  \n",
      "9689  ...  34.0   55.0   79.0  206.0   49.0  53.0   25.0  169.0   68.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  7\n",
      "Accuracy: 0.6171310629514963\n",
      "F1 Score: 0.49059398466163334\n",
      "Precision: 0.9646944606223494\n",
      "Recall/Sensitivity/True Positive Rate: 0.6171310629514963\n",
      "Confusion Matrix:\n",
      " [[  40 1088]\n",
      " [  25 1754]]\n",
      "\n",
      "\n",
      "        425    237   2084    129   1491    461   1322    218   2192    884  \\\n",
      "0      98.0   72.0   97.0  166.0  181.0   89.0  148.0  179.0  155.0  228.0   \n",
      "1     107.0   75.0  117.0  229.0  182.0   96.0  169.0  200.0  119.0  207.0   \n",
      "2      96.0   74.0  124.0  230.0  176.0  132.0  126.0  186.0  115.0  195.0   \n",
      "3      76.0   81.0  122.0  215.0  174.0  128.0  133.0  143.0   99.0  146.0   \n",
      "4      70.0   91.0  103.0  226.0  114.0   76.0  137.0  190.0  116.0  182.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  130.0  133.0  101.0   31.0   68.0  173.0   45.0  255.0  100.0   56.0   \n",
      "9686   69.0  225.0   64.0   30.0   79.0  239.0   36.0   20.0   71.0   91.0   \n",
      "9687   90.0  124.0   97.0  244.0   71.0   64.0   21.0  159.0   94.0   90.0   \n",
      "9688   27.0   25.0   96.0  255.0  116.0  124.0   17.0  255.0   89.0   84.0   \n",
      "9689   56.0   36.0   89.0  108.0  255.0  103.0   16.0  104.0   86.0   82.0   \n",
      "\n",
      "      ...    375    211    829    628    927    115  1389    338    450  label  \n",
      "0     ...   72.0  182.0  100.0  166.0  105.0  188.0  91.0   84.0   93.0      1  \n",
      "1     ...   78.0  208.0  117.0  182.0   80.0  227.0  84.0   73.0   94.0      1  \n",
      "2     ...   91.0  174.0   97.0  173.0  110.0  156.0  83.0   88.0  108.0      1  \n",
      "3     ...  102.0  176.0   81.0  175.0  135.0  147.0  78.0  100.0  124.0      1  \n",
      "4     ...   70.0  161.0  128.0  127.0   81.0  177.0  77.0   90.0   82.0      1  \n",
      "...   ...    ...    ...    ...    ...    ...    ...   ...    ...    ...    ...  \n",
      "9685  ...  101.0  255.0  208.0  255.0  161.0  227.0  35.0  255.0  179.0      1  \n",
      "9686  ...  137.0   36.0  217.0  255.0  104.0   92.0  34.0  255.0  255.0      1  \n",
      "9687  ...  249.0  255.0  251.0  255.0   75.0  254.0  30.0  204.0  135.0      1  \n",
      "9688  ...   81.0  255.0   99.0  192.0   86.0  254.0  30.0  255.0  251.0      1  \n",
      "9689  ...   86.0   58.0  102.0  255.0   70.0   88.0  67.0  238.0   79.0      1  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  8\n",
      "Accuracy: 0.8286893704850361\n",
      "F1 Score: 0.7977301904641446\n",
      "Precision: 0.8986401452810748\n",
      "Recall/Sensitivity/True Positive Rate: 0.8286893704850361\n",
      "Confusion Matrix:\n",
      " [[  52  372]\n",
      " [ 126 2357]]\n",
      "\n",
      "\n",
      "       1109    346     42    646    798   2256    492   1934   2170   1402  \\\n",
      "0     124.0  170.0   78.0   90.0   95.0   85.0   86.0  111.0   84.0  120.0   \n",
      "1      90.0  127.0   96.0   80.0  139.0   74.0  102.0  108.0   82.0  136.0   \n",
      "2      79.0  131.0   95.0   83.0  149.0   77.0  134.0   99.0   96.0  122.0   \n",
      "3      99.0   84.0   95.0  124.0  172.0   75.0  135.0  102.0   89.0  139.0   \n",
      "4     108.0  201.0   87.0  101.0   90.0  129.0   81.0   98.0  120.0  130.0   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "9685  241.0  255.0   40.0   26.0   57.0   50.0  255.0   19.0   58.0  100.0   \n",
      "9686  169.0  254.0  104.0   62.0   80.0   43.0  255.0   19.0   53.0   87.0   \n",
      "9687  224.0   40.0  246.0   65.0   99.0   35.0  134.0   18.0   63.0   87.0   \n",
      "9688  255.0  254.0  189.0   71.0   61.0   33.0  214.0   16.0   58.0  130.0   \n",
      "9689  150.0  139.0   61.0   59.0   52.0   37.0  166.0   15.0   65.0   98.0   \n",
      "\n",
      "      ...     71   2176   1204    916    917   850  1679   2287   1855  label  \n",
      "0     ...  165.0   92.0  108.0  100.0  136.0  94.0  84.0  149.0  134.0      1  \n",
      "1     ...  192.0   94.0  123.0  118.0   87.0  78.0  80.0  104.0  126.0      1  \n",
      "2     ...  224.0  105.0  119.0  106.0   84.0  74.0  87.0   98.0  123.0      1  \n",
      "3     ...  236.0   93.0  111.0  122.0   78.0  79.0  88.0   95.0  113.0      1  \n",
      "4     ...  173.0  126.0  141.0  176.0  176.0  77.0  79.0   94.0  131.0      1  \n",
      "...   ...    ...    ...    ...    ...    ...   ...   ...    ...    ...    ...  \n",
      "9685  ...   27.0   84.0  153.0  184.0  157.0  50.0  39.0  100.0   85.0      0  \n",
      "9686  ...  247.0   36.0  189.0  254.0  247.0  67.0  34.0  100.0  101.0      0  \n",
      "9687  ...  217.0   89.0  210.0  190.0  163.0  54.0  27.0   94.0   70.0      0  \n",
      "9688  ...  204.0   83.0  255.0  255.0  255.0  10.0  37.0   89.0   66.0      0  \n",
      "9689  ...   48.0   88.0  255.0   78.0   43.0  66.0  23.0   85.0   55.0      0  \n",
      "\n",
      "[9690 rows x 21 columns]\n",
      "The current Data frame is:  9\n",
      "Accuracy: 0.9267285861713106\n",
      "F1 Score: 0.9144435925616496\n",
      "Precision: 0.9524633778175498\n",
      "Recall/Sensitivity/True Positive Rate: 0.9267285861713106\n",
      "Confusion Matrix:\n",
      " [[  12  148]\n",
      " [  65 2682]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in [5, 10, 20]:\n",
    "    for i in range(10):\n",
    "        strings=globals()[\"xy{}_{}\".format(i, x)]\n",
    "        print(strings)\n",
    "        print(\"The current Data frame is: \",i)\n",
    "        y_train=strings['label']\n",
    "        processed_df=strings.drop(columns=['label'])\n",
    "        naive_bayes_search(processed_df,y_train)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685    9\n",
      "9686    9\n",
      "9687    9\n",
      "9688    9\n",
      "9689    9\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685    9\n",
      "9686    9\n",
      "9687    9\n",
      "9688    9\n",
      "9689    9\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685   -1\n",
      "9686   -1\n",
      "9687   -1\n",
      "9688   -1\n",
      "9689   -1\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "0      -1\n",
      "1      -1\n",
      "2      -1\n",
      "3      -1\n",
      "4      -1\n",
      "       ..\n",
      "9685    9\n",
      "9686    9\n",
      "9687    9\n",
      "9688    9\n",
      "9689    9\n",
      "Name: label, Length: 9690, dtype: int64\n",
      "[-1  0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- 1016\n- 109\n- 1136\n- 1141\n- 1265\n- ...\nFeature names seen at fit time, yet now missing:\n- 1599\n- 595\n- 76\n- 908\n- 916\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\victo\\Documents\\year4\\F20DL\\labs\\DMML\\Coursework\\Part 1\\Feature_Selection.ipynb Cell 30\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/victo/Documents/year4/F20DL/labs/DMML/Coursework/Part%201/Feature_Selection.ipynb#X42sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m gnb \u001b[39min\u001b[39;00m gnbs:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/victo/Documents/year4/F20DL/labs/DMML/Coursework/Part%201/Feature_Selection.ipynb#X42sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mprint\u001b[39m(gnb\u001b[39m.\u001b[39mclasses_)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/victo/Documents/year4/F20DL/labs/DMML/Coursework/Part%201/Feature_Selection.ipynb#X42sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     predi \u001b[39m=\u001b[39m gnb\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/victo/Documents/year4/F20DL/labs/DMML/Coursework/Part%201/Feature_Selection.ipynb#X42sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     predis\u001b[39m.\u001b[39mappend(predi)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/victo/Documents/year4/F20DL/labs/DMML/Coursework/Part%201/Feature_Selection.ipynb#X42sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m y_pred_multilabel \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcolumn_stack(predis)\n",
      "File \u001b[1;32mc:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\naive_bayes.py:101\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[39mPerform classification on an array of test vectors X.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39m    Predicted target values for X.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    100\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 101\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_X(X)\n\u001b[0;32m    102\u001b[0m jll \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_joint_log_likelihood(X)\n\u001b[0;32m    103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_[np\u001b[39m.\u001b[39margmax(jll, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\naive_bayes.py:269\u001b[0m, in \u001b[0;36mGaussianNB._check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_X\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    268\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate X, used only in predict* methods.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:580\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_data\u001b[39m(\n\u001b[0;32m    510\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    511\u001b[0m     X\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_validation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params,\n\u001b[0;32m    517\u001b[0m ):\n\u001b[0;32m    518\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \n\u001b[0;32m    520\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[39m        validated.\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 580\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_feature_names(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    582\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    583\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    584\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m estimator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    585\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequires y to be passed, but the target y is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    586\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:507\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing_names \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    503\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    504\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n\u001b[1;32m--> 507\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- 1016\n- 109\n- 1136\n- 1141\n- 1265\n- ...\nFeature names seen at fit time, yet now missing:\n- 1599\n- 595\n- 76\n- 908\n- 916\n"
     ]
    }
   ],
   "source": [
    "gnbs = []\n",
    "\n",
    "# for x in [5, 10, 20]:\n",
    "for x in [5]:\n",
    "    for i in range(10):\n",
    "        strings=globals()[\"xy{}_{}\".format(i, x)]\n",
    "        # print(\"The current Data frame is: \",i)\n",
    "        y_train=strings['label']\n",
    "        y_train = y_train.replace({0: i, 1: -1})\n",
    "        print(y_train)\n",
    "        processed_df=strings.drop(columns=['label'])\n",
    "        # naive_bayes_search(processed_df,y_train)\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(processed_df, y_train, test_size=0.3,random_state=seed_value)\n",
    "        gnb = GaussianNB()\n",
    "        gnb.fit(X_train, Y_train)\n",
    "        gnbs.append(gnb)\n",
    "\n",
    "predis = []\n",
    "for gnb in gnbs:\n",
    "    gnb.classes_\n",
    "    predi = gnb.predict(X_test)\n",
    "    predis.append(predi)\n",
    "\n",
    "y_pred_multilabel = np.column_stack(predis)\n",
    "accuracy_score(Y_test, y_pred_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reduced_x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\anshu\\OneDrive\\Desktop\\Course\\F21DL\\DMML\\Coursework\\Part 1\\Feature_Selection_fixed.ipynb Cell 31\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m classifiers \u001b[39m=\u001b[39m [GaussianNB() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ovr \u001b[39m=\u001b[39m OneVsRestClassifier(GaussianNB(), n_jobs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_train, X_test, Y_train, Y_test \u001b[39m=\u001b[39m train_test_split(reduced_x_train, ytrainall, test_size\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m,random_state\u001b[39m=\u001b[39mseed_value)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m ovr\u001b[39m.\u001b[39mfit(X_train, Y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/anshu/OneDrive/Desktop/Course/F21DL/DMML/Coursework/Part%201/Feature_Selection_fixed.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m predicted \u001b[39m=\u001b[39m ovr\u001b[39m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reduced_x_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "classifiers = [GaussianNB() for i in range(10)]\n",
    "ovr = OneVsRestClassifier(GaussianNB(), n_jobs=10)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(reduced_x_train, ytrainall, test_size=0.3,random_state=seed_value)\n",
    "\n",
    "ovr.fit(X_train, Y_train)\n",
    "predicted = ovr.predict(X_test)\n",
    "predicted_probs = ovr.predict_proba(X_test)\n",
    "\n",
    "# cross_val_scores = cross_val_score(gnb, X_train, Y_train, cv=5)  \n",
    "# print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "# print(\"Mean CV Score:\", cross_val_scores.mean())\n",
    "\n",
    "\n",
    "# train_sizes, train_scores, test_scores = learning_curve(gnb, X_train, Y_train, cv=5)\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Learning Curves\")\n",
    "# plt.xlabel(\"Training examples\")\n",
    "# plt.ylabel(\"Score\")\n",
    "# plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "# plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()\n",
    "\n",
    "accuracy = accuracy_score(Y_test,predicted )\n",
    "f1 = f1_score(predicted, Y_test, average=\"weighted\")\n",
    "conf_matrix = confusion_matrix(predicted, Y_test)\n",
    "precision = precision_score(Y_test, predicted, average=\"weighted\",zero_division=1)\n",
    "recall = recall_score(Y_test, predicted, average=\"weighted\")\n",
    "# roc = roc_auc_score(Y_test, predicted_probs, multi_class=\"ovr\", average=\"weighted\")\n",
    "# conf_matrices = multilabel_confusion_matrix(Y_test, predicted)\n",
    "# tp = conf_matrices[:,1,1]\n",
    "# fp = conf_matrices[:,0,1]\n",
    "# tn = conf_matrices[:,0,0]\n",
    "# fn = conf_matrices[:,1,0]\n",
    "# fpr = _nanaverage(fp/(tn + fp), tp + fn)\n",
    "# tnr = _nanaverage(tn/(tn + fp), tp + fn)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall/Sensitivity/True Positive Rate:\", recall)\n",
    "# print(\"Specificity:\", tnr)\n",
    "# print(\"False Positive Rate:\", fpr)\n",
    "# print(\"Area under ROC curve:\", roc)\n",
    "# print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xy3_4'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"xy{}_{}\".format(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
