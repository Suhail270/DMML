{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# <center> Lab 3 <center>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "printmd(\"# <center> Lab 3 <center>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "df_init = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "\n",
    "df = df_init.copy()\n",
    "\n",
    "# 0 -> setosa\n",
    "# 1 -> versicolor\n",
    "# 2 -> virginica\n",
    "\n",
    "# data.target, data.target_names\n",
    "\n",
    "species = []\n",
    "\n",
    "for i in data.target:\n",
    "    if i==0:\n",
    "        species.append(\"Iris-setosa\")\n",
    "    elif i==1:\n",
    "        species.append('Iris-versicolor')\n",
    "    elif i==2:\n",
    "        species.append('Iris-virginica')\n",
    "\n",
    "df['Species'] = species\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=\"Species\")\n",
    "Y = df[\"Species\"]\n",
    "\n",
    "feature_names = X.columns\n",
    "\n",
    "labels = Y.unique()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Set 2:\n",
      "Top 2 features for setosa: petal width (cm), petal length (cm)\n",
      "Top 2 features for versicolor: petal width (cm), petal length (cm)\n",
      "Top 2 features for virginica: petal width (cm), petal length (cm)\n",
      "\n",
      "Data Set 3:\n",
      "Top 3 features for setosa: petal width (cm), petal length (cm), sepal length (cm)\n",
      "Top 3 features for versicolor: petal width (cm), petal length (cm), sepal length (cm)\n",
      "Top 3 features for virginica: petal width (cm), petal length (cm), sepal length (cm)\n",
      "\n",
      "Data Set 4:\n",
      "Top 4 features for setosa: petal width (cm), petal length (cm), sepal length (cm), sepal width (cm)\n",
      "Top 4 features for versicolor: petal width (cm), petal length (cm), sepal length (cm), sepal width (cm)\n",
      "Top 4 features for virginica: petal width (cm), petal length (cm), sepal length (cm), sepal width (cm)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['species'] = iris.target_names[iris.target]\n",
    "\n",
    "# Calculate the correlation between features and classes\n",
    "correlations = iris_df.iloc[:, :-1].apply(lambda x: x.corr(iris_df['species'].astype('category').cat.codes))\n",
    "\n",
    "# Select top correlating features for each class\n",
    "top_features_per_class = {\n",
    "    'setosa': correlations.abs().nlargest(10).index,\n",
    "    'versicolor': correlations.abs().nlargest(10).index,\n",
    "    'virginica': correlations.abs().nlargest(10).index\n",
    "}\n",
    "\n",
    "# Create Data Sets\n",
    "data_sets = {}\n",
    "n=1\n",
    "for num_features in [2, 3, 4]:\n",
    "    data_sets[num_features] = {\n",
    "        species: iris_df[top_features_per_class[species][:num_features]]\n",
    "        for species in top_features_per_class.keys()\n",
    "    }\n",
    "\n",
    "# Print the selected top features for each data set\n",
    "for num_features, feature_set in data_sets.items():\n",
    "    print(f\"\\nData Set {num_features}:\")\n",
    "    for species, features in feature_set.items():\n",
    "        print(f\"Top {num_features} features for {species}: {', '.join(features.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Set 2:\n",
      "Top 2 features for setosa: sepal width (cm), sepal length (cm)\n",
      "Top 2 features for versicolor: sepal length (cm), sepal width (cm)\n",
      "Top 2 features for virginica: sepal length (cm), sepal width (cm)\n",
      "\n",
      "Data Set 3:\n",
      "Top 3 features for setosa: sepal width (cm), sepal length (cm), petal length (cm)\n",
      "Top 3 features for versicolor: sepal length (cm), sepal width (cm), petal length (cm)\n",
      "Top 3 features for virginica: sepal length (cm), sepal width (cm), petal length (cm)\n",
      "\n",
      "Data Set 4:\n",
      "Top 4 features for setosa: sepal width (cm), sepal length (cm), petal length (cm), petal width (cm)\n",
      "Top 4 features for versicolor: sepal length (cm), sepal width (cm), petal length (cm), petal width (cm)\n",
      "Top 4 features for virginica: sepal length (cm), sepal width (cm), petal length (cm), petal width (cm)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['species'] = iris.target_names[iris.target]\n",
    "\n",
    "# Apply PCA to the feature matrix\n",
    "pca = PCA()\n",
    "X_transformed = pca.fit_transform(iris_df.iloc[:, :-1])\n",
    "\n",
    "# Extract the top features for each class based on PCA\n",
    "top_features_per_class = {}\n",
    "for class_label, class_name in enumerate(iris.target_names):\n",
    "    class_samples = X_transformed[iris.target == class_label]\n",
    "    class_variance = class_samples.var(axis=0)\n",
    "    top_feature_index = class_variance.argsort()[::-1][:10]  # Select top 10 components\n",
    "    top_features_per_class[class_name] = [iris.feature_names[i] for i in top_feature_index]\n",
    "\n",
    "# Create Data Sets\n",
    "data_sets = {}\n",
    "for num_features in [2, 3, 4]:\n",
    "    data_sets[num_features] = {\n",
    "        species: iris_df[top_features_per_class[species][:num_features]]\n",
    "        for species in top_features_per_class.keys()\n",
    "    }\n",
    "\n",
    "# Print the selected top features for each data set\n",
    "for num_features, feature_set in data_sets.items():\n",
    "    print(f\"\\nData Set {num_features}:\")\n",
    "    for species, features in feature_set.items():\n",
    "        print(f\"Top {num_features} features for {species}: {', '.join(features.columns)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
